{"AI-and-WebDev":{"slug":"AI-and-WebDev","filePath":"AI and WebDev.md","title":"AI and WebDev","links":["/","Web-Dev/","ML/"],"tags":[],"content":"Home\nindex\nindex|\nML+¬†web¬†dev (learning):\nm.youtube.com/playlist\n\nNarrow AI : trained to do specific thing like or even better than humans.\n\n\nMachine Learning : An approach to AI where system learns from patterns.\n\n\nDeep Learning : A technique to implement Machine Learning.\n\n\nReinforcement Learning : try to take actions to maximize its reward.\n\n\nTransfer Learning : retrain existing models with new data.\n\nHow to train ML model :\n\nFeatures and Attributes (color shape size weight position etc.)\nVisualizing features\nChoose an algorithm\n\nTensoFlow.js :\nTensorflow.js is high level Layers API (like Keras(high level layers API for python)) which was build after deeplearn.js which was a low level mathematical Ops API which required more knowledge of ML and Math to run a model on browser.\n\nBoth Python and JavaScript code for Tensorflow.js are simply build on top of C++ core with the help of C/C++ bindings.\n\nModels in Tensorflow.js can run on both client and server side.\nClient side our hardware have many options and execution time of ML model is based on hardware of client.\nWhile on server side hardware is fix and mostly of better quality and better scalability options\n\nClient Side hardware options :\n\n\n\nCourses\n\nA Google&#039;s developer course :\n\n\nMachine Learning for Web Developers (Web ML)\n\n\n\nTools\n\nVercel - v0 (generates react code on prompt)\n\n"},"Arch-Linux":{"slug":"Arch-Linux","filePath":"Arch Linux.md","title":"Arch Linux","links":["/"],"tags":[],"content":"index\nCleanup Routine Commands:\npacman, yay\nsudo pacman -Rns $(pacman -Qdtq)   # remove repo orphans\nyay -Rns $(yay -Qdtq)              # remove AUR orphans\nsudo paccache -r                   # trim repo package cache\nyay -Sc                            # trim yay build cache\ncargo:\ncargo cache\ncargo cache -a\nuv:\nuv cache clean"},"Blogs/Philosophy/Birthdaysss-üòà":{"slug":"Blogs/Philosophy/Birthdaysss-üòà","filePath":"Blogs/Philosophy/Birthdaysss üòà.md","title":"Birthdaysss üòà","links":["Blogs/Philosophy/"],"tags":[],"content":"I just literally can‚Äôt make any sense why one should celebrates his/her birthday, it‚Äôs literally a countdown to death.\nI believe that true kinda checkpoints of life which needs to be celebrated are rather when one‚Äôs attains mental / physical / emotional maturity or find new ways of contentment in one‚Äôs life.\nindex"},"Blogs/Philosophy/Outsider-for-their-thoughts":{"slug":"Blogs/Philosophy/Outsider-for-their-thoughts","filePath":"Blogs/Philosophy/Outsider for their thoughts.md","title":"Outsider for their thoughts","links":["Blogs/Philosophy/"],"tags":[],"content":"When you stand next to strong person, you don‚Äôt feel weak, you just admire their strength. When you meet someone rich you don‚Äôt feel personally attacked, you just admire their progress and aspire to achieve something  similar. In both cases we feel a bit envy but it‚Äôs not personal, not like they are imposing there superiority.\nBut when you meet a deep thinker, ‚ÄúMirror Effect‚Äù occur where they not only introduces new ideas, perspectives, but also reflect the limitations of those around them. The mere presence of a deep thinker makes you feel inadequate.\nStrength, Wealth, Beauty are external we recognize them but they don‚Äôt necessarily challenge our core self-perception.\nUnlike Physical Strength or material wealth, Intelligence is tied to a persons identity, self-perception.\nWhen we meet someone that questions what we take for granted or don‚Äôt dare to question, we feel a direct attack to our self-perception, our identity.\nPresence of deep thinkers forces others to confront their own limitations.\nPeople tend to resist such people because of the mirror effect therefore society is more influenced by charismatic but simplistic thinkers than deep thinkers who speak with nuance.\nIn one-one conversation with an intellect, people feel less insecure but in group conversation people are worried about there social status, they try to exclude the deep thinker to protect their social standing.\n‚ÄúThe Dunning-Kruger Effect‚Äù ‚Üí people with low-ability often overestimate their intelligence, while highly intelligent people tend to doubt themselves.\n‚ÄúArthur Schopenhauer‚Äù ‚Üí Intelligence is not a gift but a curse.\nMost people live their lives controlled by their will to live meaning they seek pleasure, comfort and survival above all else. However, highly intelligent people, instead of following their instincts develop the will to truth, a desire to understand reality even if comes with discomfort.\nWhile most people find meaning in relationships, entertainment and routine pleasures, deep tinkers often see them as distractions from the deeper truth.\nSo instead of seeking validation from society, deep thinkers should embrace solitude and isolation and consider it a privilege.\nPeople who can deliver more simpler, emotional and instant content without any depth gets more attention which kind of chambers a person into beliefs and perspectives of the content they consume.\n‚ÄúSocrates‚Äù ‚Üí The unexamined life is not worth living.\nindex"},"Blogs/Philosophy/Why-being-me-not-sucks":{"slug":"Blogs/Philosophy/Why-being-me-not-sucks","filePath":"Blogs/Philosophy/Why being me not sucks.md","title":"Why being me not sucks","links":["Blogs/Philosophy/"],"tags":[],"content":"Okay title kinda suggest that I thought why it might suck but these were my thought after hearing about 2025 Chinese GaoKao and some of my friends achieving what I wished for.\nThe Universal engine has a lot of heated parts running at max one of the them being the Rat Races, in all forms. Saw a recent IIT‚Äôs freshers intro where a student asked question why choose engineering which he replied confused that his goal was to crack IIT.\nThe making out game:\nCapitalist wants more profit ‚áí need to exploit work force.\nworker want to maintain a healthy life and earning ‚áí work not to max so less profit for company\nWe see a conflict in interest so what‚Äôs the solution ?\ncapitalist establish a simple rule that if a person generate less that a limit he will receive a base pay and every unit generated by an individual over that limit will give him/her bonus.\nyeah yeah, divide and rule kinda situation,\nso now by rewarding individual labor instead of collective labor, capitalist generated competition.\nAll worker start working extra hard and now as everyone is working hard capitalist keep pushing limit.\nso capitalist simply started a rat race. If everyone works hard the plain evens again, but the profits skyrocketed\nI‚Äôm not that against the rat races, I think they kindof helps people to break their limits and are good until the only goal left is beating the system.\nidk if I got that point to you so here‚Äôs another proper example:\nYou see, all students me are preparing from same sheets(of DSA) trying to learn all ‚Äústandard‚Äù questions\nAt interview time, all of them instead of being themselves will try to figure out what answer or method the recruiter is thinking about.\nThey just want to land a high paying job but as one said, journey is important than destination, I‚Äôm not a people pleaser.\nI just want to understand and explore programming as much as possible and obviously like worker want to a healthy life.\nSo, while all my friends are achieving something, I don‚Äôt feel the need of rush to achieve something fast.\nI will simply polish my skills till my talent blooms.\nAnd a great player said, ‚ÄúBelieve that one day your talent will bloom, till then polish your instincts, in next 5, 10, 30 years or even later, believe it will bloom as if you won‚Äôt believe then it probably won‚Äôt‚Äù\nbasically don‚Äôt give up cause future successful you is relying on present you\nor whateverrrr the way you interpret.\nSo, from the past few weeks I have been practicing a simple rule You do it right &amp; you do it everyday\nBeing successful like my friends would have been good but being me don‚Äôt sucks either.\nindex"},"Blogs/Philosophy/index":{"slug":"Blogs/Philosophy/index","filePath":"Blogs/Philosophy/index.md","title":"index","links":[],"tags":[],"content":""},"College-Courses/index":{"slug":"College-Courses/index","filePath":"College Courses/index.md","title":"College Courses","links":["/"],"tags":[],"content":"Home"},"DSA_CP/CP-in-Rust":{"slug":"DSA_CP/CP-in-Rust","filePath":"DSA_CP/CP in Rust.md","title":"CP in Rust","links":["DSA_CP/"],"tags":[],"content":"index\nResources:\nrustp.org/basic-programs/input-single-number/\ncodeforces.com/blog/entry/111573\nMy template:\nuse std::io;\nuse std::collections::*;\nuse std::i32::{MIN, MAX};\n \npub fn take_usize() -&gt; usize {\n    let mut input = String::new();\n    io::stdin().read_line(&amp;mut input).unwrap();\n \n    return input.trim().parse().unwrap();\n}\n \npub fn take_int() -&gt; i32 {\n    let mut input = String::new();\n    io::stdin().read_line(&amp;mut input).unwrap();\n \n    return input.trim().parse().unwrap();\n}\n \npub fn take_vector_usize() -&gt; Vec&lt;usize&gt; {\n    let mut input = String::new();\n    io::stdin().read_line(&amp;mut input).unwrap();\n    \n    let arr:Vec&lt;usize&gt; = input\n        .trim()\n        .split_whitespace()\n        .map(|x| x.parse().unwrap())\n        .collect();\n \n    return arr;\n}\n \npub fn take_vector_int() -&gt; Vec&lt;i32&gt; {\n    let mut input = String::new();\n    io::stdin().read_line(&amp;mut input).unwrap();\n    \n    let arr:Vec&lt;i32&gt; = input\n        .trim()\n        .split_whitespace()\n        .map(|x| x.parse().unwrap())\n        .collect();\n \n    return arr;\n}\n \npub fn take_string_as_vec() -&gt; Vec&lt;char&gt;{\n    let mut input = String::new();\n    io::stdin().read_line(&amp;mut input).unwrap();\n \n    let arr:Vec&lt;char&gt; = input\n        .trim()\n        .chars()\n        .collect();\n \n    return arr;\n}\n \npub fn vec_to_string(input:Vec&lt;char&gt;) -&gt; String{\n    return input.iter().collect::&lt;String&gt;();\n}\n \npub fn cnt_digits(input:usize) -&gt; usize{\n    return ((input as f32).log10() as usize)+1;\n}\n \npub fn reverse_num(mut input:usize) -&gt; usize{\n    let mut rev = 0;\n    while input&gt;0 {\n        rev = rev*10 + input%10;\n        input /= 10;\n    }\n    rev\n}\n \npub fn gcd(mut a:usize, mut b:usize) -&gt; usize{\n    // Euclidean Algorithm\n    while a&gt;0 &amp;&amp; b&gt;0 {\n        if a&gt;b {\n            a=a%b;\n        }\n        else {\n            b=b%a;\n        }\n    }\n    if a==0 {\n        return b;\n    }\n    a\n}\n \npub fn factors(input:usize) -&gt; Vec&lt;usize&gt; {\n    let mut factors1 = Vec::&lt;usize&gt;::new();\n    let mut factors2 = Vec::&lt;usize&gt;::new();\n    let mid = (input as f32).sqrt() as usize;\n    \n    for i in 1..(mid+1) {\n        if input%i == 0{\n            factors1.push(i);\n            if i != input / i {\n                factors2.insert(0,input / i);\n            }\n        }\n    }\n \n    factors1.append(&amp;mut factors2);\n    factors1\n}\n \npub fn is_prime(input: usize) -&gt; bool {\n    if input &lt;= 1 {\n        return false;\n    }\n    if input == 2 {\n        return true;\n    }\n    if input &amp; 1 == 0 {\n        return false;\n    }\n \n    let sqrt = (input as f64).sqrt() as usize;\n    for i in (3..=sqrt).step_by(2) {\n        if input % i == 0 {\n            return false;\n        }\n    }\n \n    true\n}\n \npub fn factorial(input: usize) -&gt; usize {\n    (1..=input).product()\n}\n \npub fn xor_upto(input: usize) -&gt; usize {\n    match input % 4 {\n        0 =&gt; input,\n        1 =&gt; 1,\n        2 =&gt; input + 1,\n        _ =&gt; 0,\n    }\n}\n \npub fn ncr(n: usize, r: usize) -&gt; usize {\n    let numerator: usize = ((n-r+1)..=n).product();\n    let denominator: usize = (1..=r).product();\n    return numerator / denominator\n} \n \n// add binary search algorithms"},"DSA_CP/CP-31-Sheet-in-C++":{"slug":"DSA_CP/CP-31-Sheet-in-C++","filePath":"DSA_CP/CP-31 Sheet in C++.md","title":"CP-31 Sheet in C++","links":["DSA_CP/"],"tags":[],"content":"index\n800 Rating\nJagged Swaps\nDetermine whether it is possible to sort the permutation after a finite number of operations, where an operations means:\nSelect an index¬†i¬†from¬†2¬†to¬†n‚àí1¬†such that¬†(a[i]‚àí1 &lt; a[i])¬†&amp;&amp;¬†(a[i] &gt; a[i]+1), then Swap¬†a[i]¬†and¬†a[i]+1\nSol: as all number except a[0] can be rearranged\nif (a[0] == 1) cout &lt;&lt; &quot;YES&quot; &lt;&lt; endl;\nelse cout &lt;&lt; &quot;NO&quot; &lt;&lt; endl;\nDoremy‚Äôs Paint 3\nAn array b1,b2,‚Ä¶,bn of positive integers is good if there exists a k such that b1+b2 = b2+b3 = ‚Ä¶ = bn‚àí1+bn = k\nSol: We need ‚áê 2 different numbers as we need to make every even number equal and same for odd number\nvoid jagged_swaps() {\n    int n;\n    cin &gt;&gt; n;\n    map&lt;int, int&gt; mp;\n    \n    // Input\n    int a[n];\n    for (int i=0; i&lt;n; ++i) {\n        cin &gt;&gt; a[i];\n        mp[a[i]]++;\n    }\n    \n    // If more than 3 different numbers \n    // can&#039;t divide them correctly so that sum is equal\n    if (mp.size() &gt;= 3) {\n        cout &lt;&lt; &quot;No&quot; &lt;&lt; endl;\n        return;\n    }\n    \n    auto [num1, temp1] = *mp.begin();\n    auto [num2, temp2] = *mp.rbegin();\n    \n    // can differ by one for odd length array \n    if (abs(temp1-temp2) &lt;= 1) {\n        cout &lt;&lt; &quot;Yes&quot; &lt;&lt; endl;\n    } else {\n        cout &lt;&lt; &quot;No&quot; &lt;&lt; endl;\n    }\n    \n    return;\n}\nAleksa and Stack\ngenerate an array for a given length n where 3 * a[i+2]¬†is not divisible by¬†a[i] + a[i+1]¬†for each¬†i¬†(1 ‚â§ i ‚â§ n‚àí2)\nSol: odd numbers from 1 to n\nodd + odd = even\nand 3 * odd = odd\nso  if we write n odd numbers then the conditions hold\nVasilije in Cacak\ngiven three positive integers:¬†n,¬†k, and¬†x, determine if you can choose¬†k¬†distinct integers between¬†1¬†and¬†n, such that their sum is equal to¬†x.\nminimum sum of k numbers = sum of 1 to k numbers\nmaximum sum of k numbers = sum of last k number i.e. n-k to n\nvoid solve() {\n    int n, x, k;\n    cin &gt;&gt; n &gt;&gt; k &gt;&gt; x;\n    \n    int total = (n*(n+1))/2;\n    \n    int k_upper = total - ((n-k)*(n-k+1))/2;\n    int k_lower = (k*(k+1))/2;\n    \n    if(x &gt;= k_lower &amp;&amp; x &lt;= k_upper) cout &lt;&lt; &quot;Yes&quot; &lt;&lt; endl;\n    else cout &lt;&lt; &quot;No&quot; &lt;&lt; endl;\n    return;\n}"},"DSA_CP/DSA-in-C++":{"slug":"DSA_CP/DSA-in-C++","filePath":"DSA_CP/DSA in C++.md","title":"DSA in C++","links":["DSA_CP/"],"tags":[],"content":"index\nArrays\nLongest subarray with sum k\n\nusing hashing:\n\nint getLongestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n    int n = nums.size();\n    unordered_map&lt;int, int&gt; mp;\n    int prefixsum = 0, res = 0;\n    \n    for (int i=0; i&lt;n; ++i) {\n        prefixsum += nums[i];\n        \n        if (prefixsum == k) {\n            res = max(res, i+1);\n        }\n        \n        if (mp.find(prefixsum-k) != mp.end()) {\n            res = max(res, i-mp[prefixsum-k]+1);\n        }\n        \n        if (mp.find(prefixsum) == mp.end()) {\n            mp[prefixsum] = i;\n        }\n    }\n    \n    return res;\n}\n\noptimal 2 pointers:\n\nint getLongestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n    int n = nums.size();\n    int res = 0, ptr1 = 0, ptr2 = 0;\n    int sum = 0;\n    \n    while (ptr2&lt;n) {\n        sum += nums[ptr2];\n        \n        while (sum &gt; k &amp;&amp; ptr1 &lt; ptr2) {\n            sum -= nums[ptr1];\n            ++ptr1;\n        }\n        \n        if (sum == k) {\n            res = max(res, ptr2-ptr1+1);\n        }\n        \n        ++ptr2;\n    }\n    \n    return res;\n}\n2 sum\n\nusing hashing:\n\nvector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n\tint n = nums.size();\n\tunordered_map&lt;int, int&gt; mp;\n\tfor (int i=0; i&lt;n; ++i) {\n\t\tmp[nums[i]] = i;\n\t}\n\t\n\tvector&lt;int&gt; res;\n\tfor (int i=0; i&lt;n; ++i) {\n\t\tif (mp.find(target-nums[i]) != mp.end()) {\n\t\t\tif (mp[target-nums[i]] != i) {\n\t\t\t\tres.push_back(mp[target-nums[i]]);\n\t\t\t\tres.push_back(i);\n\t\t\t\treturn res;\n\t\t\t} \n\t\t}\n\t}\n\t\n\treturn res;\n}\n\noptimal 2 pointers:\n\nvector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n\tint n = nums.size();\n\tsort(nums.begin(), nums.end());\n\tvector&lt;int&gt; res;\n\tint ptr1 = 0, ptr2 = n-1;\n\t\n\twhile (ptr1&lt;ptr2) {\n\t\tint sum = nums[ptr1]+nums[ptr2];\n\t\tif (sum == target) {\n\t\t\tres.push_back(nums[ptr1]);\n\t\t\tres.push_back(nums[ptr2]);\n\t\t\treturn res;\n\t\t}\n\t\t\n\t\tif (sum &gt; target) --ptr2;\n\t\telse ++ptr1;\n\t}\n\t\n\treturn res;\n}\nLongest Consecutive Subsequence\nint longest_consecutive_subseqeunce(vector&lt;int&gt;&amp; nums) {\n    int n = nums.size();\n    int res = 0;\n    unordered_set&lt;int&gt; st;\n    \n    for (auto num: nums) {\n        st.insert(num);\n    }\n    \n    for (auto num: st) {\n        if (st.find(num-1) == st.end()) {\n            int start = num+1, cnt = 1;\n            while (st.find(start) != st.end()) {\n                ++cnt;\n                ++start;\n            }\n            res = max(res, cnt);\n        }\n    }\n    \n    return res;\n}\nMerge Intervals\nvector&lt;vector&lt;int&gt;&gt; merge(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) {\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tsort(intervals.begin(), intervals.end());\n\t\n\tint start = intervals[0][0];\n\tint end = intervals[0][1];\n\tfor (int i = 1; i&lt;intervals.size(); i++) {\n\t\tint s = intervals[i][0], e = intervals[i][1];\n\t\tif (s &lt;= end) {\n\t\t\tend = max(end, e);\t\n\t\t} \n\t\tif (s &gt; end) {\n\t\t\tres.push_back({start, end});\n\t\t\tstart = s;\n\t\t\tend = e;\n\t\t}\n\t}\n\tres.push_back({start, end});\n\t\n\treturn res;\n}\nMerge two Sorted Arrays Without Extra Space\nvoid merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) {\n\tint i = m+n-1;\n\tint p2 = m-1;\n\tint p3 = n-1;\n\twhile (p2 &gt;= 0 &amp;&amp; p3 &gt;= 0) {\n\t\tif (nums1[p2] &gt; nums2[p3]) {\n\t\t\tnums1[i] = nums1[p2];\n\t\t\tp2--;\n\t\t} else {\n\t\t\tnums1[i] = nums2[p3];\n\t\t\tp3--;\n\t\t}\n\t\ti--;\n\t}\n \n\twhile (p3 &gt;= 0) {\n\t\tnums1[i] = nums2[p3];\n\t\tp3--;\n\t\ti--;\n\t}\n}\nFind All Duplicates in an Array (Negative marking)\nbecause we are given that elements of array are in the range [0 .. n] we can uses elements as indexes\nfor every element in array mark it‚Äôs absolute index -1 representing that element has been taken\nvector&lt;int&gt; findDuplicates(vector&lt;int&gt;&amp; nums) {\n\tif(nums.size()==1) return {};\n\t// Negative marking\n\t// Whenever we meet the element we mark the value - 1 as negative\n\tvector&lt;int&gt; ans;\n\tfor(int i = 0; i&lt;nums.size(); i++) {\n\t\tif(nums[abs(nums[i])-1]&gt;0)\n\t\t\tnums[abs(nums[i])-1] *=-1; // Mark it with negative\n\t\telse\n\t\t\tans.push_back(abs(nums[i]));\n\t}\n\treturn ans;\n}\nCount Inversion\nReverse Pairs\n \nBinary Search\nThink how you can eliminate any half\nvoid merge(vector&lt;int&gt;&amp; arr, int low, int mid, int high) {\n\tvector&lt;int&gt; temp;\n\tint a = low;\n\tint b = mid+1;\n\t\n\twhile (a &lt;= mid &amp;&amp; b &lt;= high) {\n\t\tif (arr[a] &lt; arr[b]) {\n\t\t\ttemp.push_back(arr[a]);\n\t\t\ta++;\n\t\t} else {\n\t\t\ttemp.push_back(arr[b]);\n\t\t\tb++;\n\t\t}\n\t}\n\t\n\twhile (a &lt;= mid) {\n\t\ttemp.push_back(arr[a]);\n\t\ta++;\n\t}\n    while (b &lt;= high) {\n\t\ttemp.push_back(arr[b]);\n\t\tb++;\n\t}\n\t\n\tfor (int i = 0; i &lt; temp.size(); ++i) {\n        arr[low + i] = temp[i];\n    }\n}\n \nvoid merge_sort(vector&lt;int&gt;&amp; arr, int low, int high) {\n\tif (low&gt;=high) {\n\t\treturn;\n\t}\n\t\n\tint mid = (low+high)/2;\n\tmerge_sort(arr, low, mid);\n\tmerge_sort(arr, mid+1, high);\n\tmerge(arr, low, mid, high);\n}\n \nint binary_search(vector&lt;int&gt;&amp; arr, int x) {\n\tint pos = -1;\n\tint low = 0;\n\tint high = arr.size()-1;\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (x&lt;arr[mid]) {\n\t\t\thigh = mid-1;\n\t\t} else if (x&gt;arr[mid]) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\tpos = mid;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn pos;\n}\n \nint main()\n{\n\tvector&lt;int&gt; nums = take_vec_int();\t\n\tint x;\n\tcin &gt;&gt; x;\n\tmerge_sort(nums, 0, nums.size()-1);\n\tfor (auto i: nums) {\n\t\tcout &lt;&lt; i &lt;&lt; &quot; &quot;;\n\t}\n\tcout &lt;&lt; endl;\n\tcout &lt;&lt; binary_search(nums, x) &lt;&lt; endl;\n\t\n\treturn 0;\n}\nUpper Lower Bounds\nint lower_bound(vector&lt;int&gt;&amp; arr, int x) {\n\tint pos = arr.size();\n\tint low = 0;\n\tint high = arr.size()-1;\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (arr[mid]&gt;=x) {\n\t\t\tpos = mid;\n\t\t\thigh = mid-1;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t}\n\treturn pos;\n}\n \nint upper_bound(vector&lt;int&gt;&amp; arr, int x) {\n\tint pos = arr.size();\n\tint low = 0;\n\tint high = arr.size()-1;\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (arr[mid] &gt; x) {\n\t\t\tpos = mid;\n\t\t\thigh = mid - 1;\n\t\t} else {\n\t\t\tlow = mid + 1;\n\t\t}\n\t}\n\treturn pos;\n}\nSearch in Rotated Sorted Array\nint search(vector&lt;int&gt;&amp; nums, int target) {\n\tint l = nums.size()-1;\n\tint low = 0;\n\tint high = l;\n \n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (nums[mid] == target) {\n\t\t\treturn mid;\n\t\t} \n\t\tif (nums[low]&lt;=nums[mid]) {\n\t\t\tif (target&lt;=nums[mid] &amp;&amp; target&gt;=nums[low]) {\n\t\t\t\thigh = mid-1;\n\t\t\t} else {\n\t\t\t\tlow = mid+1;\n\t\t\t}\n\t\t} else {\n\t\t\tif (target&gt;=nums[mid] &amp;&amp; target&lt;=nums[high]) {\n\t\t\t\tlow = mid+1;\n\t\t\t} else {\n\t\t\t\thigh = mid-1;\n\t\t\t}\n\t\t}\n\t\t\n\t}\n\treturn -1;\n}\nFind Minimum element in Rotated Sorted Array (position of minimum = number of times it‚Äôs rotated)\nint findMin(vector&lt;int&gt;&amp; nums) {\n\tint pos = -1;\n\tint low = 0;\n\tint high = nums.size()-1;\n\tint min = INT_MAX;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (nums[low] &lt;= nums[mid]) {\n\t\t\tif (nums[low] &lt; min) {\n\t\t\t\tpos = low;\n\t\t\t\tmin = nums[low];\n\t\t\t}\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\tif (nums[mid] &lt; min) {\n\t\t\t\tpos = mid;\n\t\t\t\tmin = nums[mid];\n\t\t\t}\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\t\n\treturn min;\n}\nSorted Array with all elements twice except one element\nint singleNonDuplicate(vector&lt;int&gt;&amp; arr) {\n\tint n = arr.size();\n\t\n\t//Edge cases:\n\tif (n == 1) return arr[0];\n\tif (arr[0] != arr[1]) return arr[0];\n\tif (arr[n - 1] != arr[n - 2]) return arr[n - 1];\n\t\n\tint low = 1, high = n - 2;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\t\n\t\tif (arr[mid] != arr[mid + 1] &amp;&amp; arr[mid] != arr[mid - 1]) {\n\t\t\treturn arr[mid];\n\t\t}\n\t\t\n\t\tif ((mid % 2 == 1 &amp;&amp; arr[mid] == arr[mid - 1])\n\t\t\t|| (mid % 2 == 0 &amp;&amp; arr[mid] == arr[mid + 1])) {\n\t\t\tlow = mid + 1;\n\t\t}\n\t\telse {\n\t\t\thigh = mid - 1;\n\t\t}\n\t}\n\t\n\treturn -1;\n}\nFind any peak element in an array\nint findPeakElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tif (n == 1) return 0;\n\tif (n == 2) {\n\t\tif (nums[0]&gt;nums[1]) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn 1;\n\t\t}\n\t};\n\t\n\tint low = 0;\n\tint high = n-1;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (mid == 0) {\n\t\t\tif (nums[0]&gt;nums[1]) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t\tif (mid == n-1) {\n\t\t\tif (nums[n-1]&gt;nums[n-2]) {\n\t\t\t\treturn n-1;\n\t\t\t} else {\n\t\t\t\treturn n-2;\n\t\t\t}\n\t\t}\n\t\tif (nums[mid]&gt;nums[mid-1] &amp;&amp; nums[mid]&gt;nums[mid+1]) {\n\t\t\treturn mid;\n\t\t} \n\t\tif (nums[mid]&lt;nums[mid-1]) {\n\t\t\thigh = mid-1;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t\t// cout &lt;&lt; low &lt;&lt; &quot; &quot; &lt;&lt; mid &lt;&lt; &quot; &quot; &lt;&lt; high &lt;&lt; endl;\n\t}\n\treturn -1;\n}\nBinary Search on Answers find min or  max\nwhen you can find a range in which answer lies and can eliminate some segments based on condition and can find min or max using the low high pointers.\ncondition is always like after some elements all further elements are either possible or not possible.\nKoko Eating Bananas\nint timeReq(vector&lt;int&gt;&amp; piles, int k){\n\tint time = 0;\n\tfor (auto i: piles) {\n\t\ttime += ceil((double)i/(double)k);\n\t}\n \n\treturn time;\n}\n \nint minEatingSpeed(vector&lt;int&gt;&amp; piles, int h) {\n\tint n = piles.size();\n\tif (n==1) return ceil((double)piles[0]/(double)h);\n\tint max = *max_element(piles.begin(), piles.end());\n\tint low = 1;\n\tint high = max;\n\tint ans = -1;\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tint time_req = timeReq(piles, mid);\n\t\tif (time_req &lt;= h) {\n\t\t\thigh = mid-1;\n\t\t\tans =  mid;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t}\n\treturn ans;\n}\nMinimum days to make M bouquets:\nint adjacentKcount(vector&lt;int&gt; bloomDay, int k) {\n\tint cnt = 0;\n\tint curr_cnt = 0;\n\tint i = 0;\n\twhile (i&lt;=(bloomDay.size()-1)) {\n\t\tif (bloomDay[i]==0) {\n\t\t\tcurr_cnt = 0;\n\t\t\twhile (i&lt;=(bloomDay.size()-1) &amp;&amp; bloomDay[i] == 0) {\n\t\t\t\tcurr_cnt += 1;\n\t\t\t\ti++;\n\t\t\t\tif (curr_cnt == k) break;\n\t\t\t}\n\t\t\tif (curr_cnt==k) cnt+=1;\n\t\t\tcout &lt;&lt; i &lt;&lt; &quot; &quot;&lt;&lt; curr_cnt &lt;&lt; &quot; &quot; &lt;&lt; cnt &lt;&lt; endl;\n\t\t} else {\n\t\t\ti++;\n\t\t\tcout &lt;&lt; i &lt;&lt; endl;\n\t\t}\n\t}\n\t\n\treturn cnt;\n}\n \nint minDays(vector&lt;int&gt;&amp; bloomDay, int m, int k) {\n\tif (bloomDay.size() &lt; m*k) return -1;\n\t\n\tint low = *min_element(bloomDay.begin(), bloomDay.end());\n\tint high = *max_element(bloomDay.begin(), bloomDay.end());\n\t\n\tcout &lt;&lt; low &lt;&lt; &quot; &quot; &lt;&lt; high &lt;&lt; endl;\n\t\n\tint min = -1;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tvector&lt;int&gt; temp;\n\t\tfor (auto i: bloomDay){\n\t\t\ttemp.push_back(max(i-mid, 0 ));\n\t\t}\n\t\tfor (auto i: temp){\n\t\t\tcout &lt;&lt; i &lt;&lt; &quot; &quot;;\n\t\t}\n\t\tcout &lt;&lt; endl;\n\t\tif (adjacentKcount(temp, k) &gt;= m) {\n\t\t\tmin = mid;\n\t\t\tcout &lt;&lt; min &lt;&lt; endl;\n\t\t\thigh = mid-1;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t}\t\n\t\n\treturn min;\n}\nFind the Smallest Divisor Given a Threshold\nint smallestDivisor(vector&lt;int&gt;&amp; nums, int threshold) {\n\tint low = 1;\n\tint high = *max_element(nums.begin(), nums.end());\n\tint ans = INT_MAX;\n\t\n\twhile(low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tint sum = 0;\n\t\tfor (auto i: nums) {\n\t\t\tsum += ceil((double)i/mid);\n\t\t\tcout &lt;&lt; ceil((double)i/mid) &lt;&lt; &quot; &quot;;\n\t\t}\n\t\tcout &lt;&lt; endl;\n\t\tif (sum&lt;=threshold) {\n\t\t\tans = min(mid, ans);\n\t\t\thigh = mid-1;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t\tcout &lt;&lt; sum &lt;&lt; &quot; &quot; &lt;&lt; ans &lt;&lt; &quot; &quot; &lt;&lt; low &lt;&lt; &quot;-&quot; &lt;&lt; mid &lt;&lt; &quot;-&quot; &lt;&lt; high &lt;&lt; endl;\n\t}\n\t\n\treturn ans;\n}\nCapacity To Ship Packages Within D Days\nint daysReq (vector&lt;int&gt;&amp; weights, int c) {\n\tint days = 0;\n\tint curr_days_sum = 0;\n\t// cout &lt;&lt; &quot;-------------&quot; &lt;&lt; endl;\n\tfor (auto i: weights) {\n\t\tif ((curr_days_sum + i) &gt; c) {\n\t\t\tcurr_days_sum = i;\n\t\t\tdays++;\n\t\t} else {\n\t\t\tcurr_days_sum += i;\n\t\t}\n\t\t// cout &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; days &lt;&lt; &quot; &quot; &lt;&lt; curr_days_sum &lt;&lt; endl;\n\t}\n\t// cout &lt;&lt; &quot;-------------&quot; &lt;&lt; endl;\n\treturn days+1;\n}\n \nint shipWithinDays(vector&lt;int&gt;&amp; weights, int days) {\n\tint low = (*max_element(weights.begin(), weights.end()));\n\tint high = accumulate(weights.begin(), weights.end(), 0);\n\t\n\tint ans = -1;\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\t// cout &lt;&lt; low &lt;&lt; &quot; &quot; &lt;&lt; mid &lt;&lt; &quot; &quot; &lt;&lt; high &lt;&lt; endl;\n\t\tint days_req = daysReq(weights, mid); \n\t\tif (days_req &lt;= days) {\n\t\t\tans = mid;\n\t\t\thigh = mid-1;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t\t// cout &lt;&lt; ans &lt;&lt; &quot; &quot; &lt;&lt; days_req &lt;&lt; endl; \n\t}\n\t\n\treturn ans;\n}\nKth Missing Positive Number\nint findKthPositive(vector&lt;int&gt;&amp; arr, int k) {\n\tif (k&lt;arr[0]) {\n\t\treturn k;\n\t}\n\tint n = arr.size()-1;\n\tif (k&gt;arr[n]) {\n\t\treturn k+(n+1);\n\t}\n\tint low = 0;\n\tint high = n;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tint missing = arr[mid]-(mid+1); \n\t\tif (missing&lt;k) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t\tcout &lt;&lt; low &lt;&lt; &quot; &quot; &lt;&lt; mid &lt;&lt; &quot; &quot; &lt;&lt; high &lt;&lt; endl;\n\t}\n\t\n\treturn k+high+1;\n}\nKth Smallest Element in a Sorted Matrix\nint countLessThan(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int mid, int n) {\n\tint cnt = 0;\n\tfor (int i=0; i&lt;n; i++) {\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (matrix[i][j] &lt;= mid) cnt++;\n\t\t\telse break;\n\t\t}\n\t}\n\t\n\treturn cnt;\n}\n \nint kthSmallest(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int k) {\n\tint n = matrix[0].size();\n\tint low = matrix[0][0], high = matrix[n-1][n-1];\n\t\n\twhile (low&lt;high) {\n\t\tint mid = low + (high-low)/2;\n\t\tint cnt = countLessThan(matrix, mid, n);\n\t\t\n\t\tif (cnt &lt; k) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid;\n\t\t}\n\t}\n\t\n\treturn low;\n}\nBinary Search on Answers find min(max) or max(min)\nmax(min) type ‚áí return high\nmin(max) type ‚áí return low\nthis is because low and high exchange at the lowest/highest possible answer.\nso it‚Äôs like :\n0, 1, 2, 3, .......... n-1, n, n+1, ....... m\n\t\t\t\t\t    ^   ^     ^\n\t\t\t\t\t   low high\n\nlet n be highest possible so for max(min) we will return max i.e highest i.e n.\nif n is highest possible the n-1 is lowest for not possible answer i.e min(max).\nAggressive Cows\nmax(min) type\nbool canWePlaceCows (vector&lt;int&gt;&amp; stalls, int dist, int cows) {\n\tint n = stalls.size()-1;\n\tint cntCows = 1;\n\tint last = stalls[0];\n\t\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (stalls[i]-last &gt;= dist) {\n\t\t\tcntCows++;\n\t\t\tlast = stalls[i];\n\t\t}\n\t\tif (cntCows &gt;= cows) return true;\n\t}\n\t\n\treturn false;\n}\n \nint aggressiveCows(vector&lt;int&gt; &amp;stalls, int k) {\n\tsort(stalls.begin(), stalls.end());\n\t\n\tint n = stalls.size() - 1;\n\tint low = 1;\n\tint high = stalls[n] - stalls[0];\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (canWePlaceCows(stalls, mid, k)) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\treturn high;\n}\nAllocate Minimum Number of Pages\nmin(max) type\nbool canAllotPage(vector&lt;int&gt;&amp; pageNumbers, int m, int capacity) {\n\tint n = pageNumbers.size()-1;\n\tint alloted = 0;\n\tint currSum = 0;\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (currSum+pageNumbers[i] &gt; capacity) {\n\t\t\talloted++;\n\t\t\tcurrSum = pageNumbers[i];\n\t\t} else {\n\t\t\tcurrSum += pageNumbers[i];\n\t\t}\n\t}\n\tcout &lt;&lt; capacity &lt;&lt; &quot; &quot; &lt;&lt; currSum &lt;&lt; &quot; &quot; &lt;&lt; alloted &lt;&lt; endl;\n\tif (alloted &gt;= m) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}\n \nint allocatePages(vector&lt;int&gt;&amp; pageNumbers, int m) {\n\tint n = pageNumbers.size() - 1;\n\tif (m &gt; (n+1)) return -1;\n\tint low = *max_element(pageNumbers.begin(), pageNumbers.end());\n\tint high = accumulate(pageNumbers.begin(), pageNumbers.end(), 0);\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tcout &lt;&lt; low &lt;&lt; &quot;-&quot; &lt;&lt; mid &lt;&lt; &quot;-&quot; &lt;&lt; high &lt;&lt; endl;\n\t\tif (canAllotPage(pageNumbers, m, mid)) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\treturn low;\n}\nSplit Array - Largest Sum\nmin(max) type\nint countPartitions (vector&lt;int&gt;&amp; nums, int capacity) {\n\tint n = nums.size()-1;\n\tint currSum = 0;\n\tint divisions = 1;\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (currSum + nums[i] &gt; capacity) {\n\t\t\tdivisions++;\n\t\t\tcurrSum = nums[i];\n\t\t} else {\n\t\t\tcurrSum += nums[i];\n\t\t}\n\t}\n\t// cout &lt;&lt; capacity &lt;&lt; &quot; &quot; &lt;&lt; currSum &lt;&lt; &quot; &quot; &lt;&lt;  divisions &lt;&lt; endl;\n\treturn divisions;\n}\n \nint splitArray(vector&lt;int&gt;&amp; nums, int k) {\n\tint n = nums.size()-1;\n\tint low = *max_element(nums.begin(), nums.end());\n\tint high = accumulate(nums.begin(), nums.end(), 0);\n \n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\t// cout &lt;&lt; low &lt;&lt; &quot;-&quot; &lt;&lt; mid &lt;&lt; &quot;-&quot; &lt;&lt; high &lt;&lt; endl;\n\t\tint possibleDivisions = countPartitions(nums, mid);\n\t\tif (possibleDivisions == k) {\n\t\t\thigh = mid-1;\n\t\t} else if (possibleDivisions &gt; k) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n \n\treturn low;\n}\nPainter‚Äôs Partition Problem\nmin(max) type\nint partitionsReq(vector&lt;int&gt;&amp; boards, int time) {\n\tint n = boards.size()-1;\n\tint partitions = 1;\n\tint timeSum = 0;\n\t\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (timeSum + boards[i] &gt; time) {\n\t\t\ttimeSum = boards[i];\n\t\t\tpartitions++;\n\t\t} else {\n\t\t\ttimeSum += boards[i];\n\t\t}\n\t}\n\t// cout &lt;&lt; time &lt;&lt; &quot; &quot; &lt;&lt; timeSum &lt;&lt; &quot; &quot; &lt;&lt; partitions &lt;&lt; endl; \n\t\n\treturn partitions;\n}\n \nint paintersProblem (vector&lt;int&gt;&amp; boards, int k) {\n\tint n = boards.size()-1;\n\tint low = *max_element(boards.begin(), boards.end());\n\tint high = accumulate(boards.begin(), boards.end(), 0);\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\t// cout &lt;&lt; low &lt;&lt; &quot;-&quot; &lt;&lt; mid &lt;&lt; &quot;-&quot; &lt;&lt; high &lt;&lt; endl;\n\t\tint partitions = partitionsReq(boards, mid);\n\t\tif (partitions &gt; k) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\t\n\treturn low;\n}\nMinimize Maximum Distance between Gas Stations\nmin(max) type, but we have to place them so the points are also variable not like Aggressive Cows questions where we had to place cows on given stalls, therefore for this problem we have to find optimal way to reduce maximum distance which is:\nplace new stations between largest gaps and distribute equal length of distance/gap between them.\nbut we can‚Äôt apply BS directly too as low mid high are int‚Äôs but we have long double positions\nso what we will do is for low &lt;= high we will check for the first 10^-6 values as it‚Äôs specified in question that as limit.\nand low = mid+1 to low = mid\nand high = mid-1 to high = mid\nStrings\nASCII values:\n\nlowercase ‚áí 97 - 122\nuppercase ‚áí 65 - 90\ndigits ‚áí 48 - 57\n\nTwo strings¬†s¬†and¬†t¬†are isomorphic if the characters in¬†s¬†can be replaced to get¬†t.\nbool isIsomorphic(string s, string t) {\n\tunordered_map&lt;char, char&gt; chars;\n\tunordered_map&lt;char, char&gt; chars2;\n\tfor (int i=0; i&lt;s.length(); i++) {\n\t\tif (chars.find(s[i]) != chars.end()) {\n\t\t\tif (chars[s[i]] != t[i] ) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} \n\t\tif (chars2.find(t[i]) != chars2.end()) {\n\t\t\tif (chars2[t[i]] != s[i]) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} \n\t\n\t\tchars[s[i]] = t[i]; \n\t\tchars2[t[i]] = s[i];\n\t}\n\t\n\treturn true;\n}\nSort characters by frequency\nstring frequencySort(string s) {\n  unordered_map&lt;char, int&gt; freq;\n \n  for (char c: s) {\n    freq[c]++;\n  }\n \n  vector&lt;pair&lt;char, int&gt;&gt; freqVec;\n  for (auto [key, val]: freq) {\n    freqVec.push_back({key, val});\n  }\n \n  sort(freqVec.begin(), freqVec.end(), [](auto&amp; a, auto&amp; b) {\n    return a.second &gt; b.second;\n  });\n \n  string res;\n  for (auto p: freqVec) {\n    while (p.second--) {\n      res += p.first;\n    }\n  }\n \n  return res;\n}\nCount Number of Homogenous Substrings\nA string is¬†homogenous¬†if all the characters of the string are the same.\nInput: s = &quot;abbcccaa&quot;\nOutput: 13\nExplanation: The homogenous substrings are listed as below:\n&quot;a&quot;   appears 3 times.\n&quot;aa&quot;  appears 1 time.\n&quot;b&quot;   appears 2 times.\n&quot;bb&quot;  appears 1 time.\n&quot;c&quot;   appears 3 times.\n&quot;cc&quot;  appears 2 times.\n&quot;ccc&quot; appears 1 time.\n3 + 1 + 2 + 1 + 3 + 2 + 1 = 13.\n\nnumber of subarrays in a &#039;n&#039; length = n(n+1) / 2\ntherefore count for a single homogeneous substring = n(n+1) / 2\nint countHomogenous(string s) {\n\ts +=&#039; &#039;;\n\tconst int modu = 1e9+7;\n\tlong long count = 0;\t\n\tlong long curr_count = 1;\n\tchar curr_char = s[0];\n \n\tfor (int i=1; i&lt;s.size(); i++) {\n\t\tcout &lt;&lt; s[i] &lt;&lt; endl;\n\t\tcout &lt;&lt; curr_char &lt;&lt; &quot; &quot; &lt;&lt; curr_count &lt;&lt; endl;\n\t\tif (s[i] == curr_char) {\n\t\t\tcurr_count++;\n\t\t} else {\n\t\t\tcount += (curr_count*(curr_count+1))/2;\n\t\t\tcurr_char = s[i];\n\t\t\tcurr_count = 1;\n\t\t}\n\t}\n\t\n\treturn count%modu;\n}\nLongest Palindromic Substring\nint expandAroundCenter(string s, int left, int right) {\n\twhile (left &gt;= 0 &amp;&amp; right &lt; s.length() &amp;&amp; s[left] == s[right]) {\n\t\tleft--;\n\t\tright++;\n\t}\n\treturn right - left - 1;\n} \nstring longestPalindrome(string s) {\n\tif (s.empty()) {\n\t\treturn &quot;&quot;;\n\t}\n\t\n\tint start = 0;\n\tint end = 0;\n\t\n\tfor (int i = 0; i &lt; s.length(); i++) {\n\t\tint odd = expandAroundCenter(s, i, i);\n\t\tint even = expandAroundCenter(s, i, i + 1);\n\t\tint max_len = max(odd, even);\n\t\t\n\t\tif (max_len &gt; end - start) {\n\t\t\tstart = i - (max_len - 1) / 2;\n\t\t\tend = i + max_len / 2;\n\t\t}\n\t}\n\t\n\treturn s.substr(start, end - start + 1);        \n}\nSum of Beauty of All Substrings\nint beautySum(string s) {\n\tint n = s.size();\n\tint totalSum=0;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tunordered_map&lt;char, int&gt; mp;\n\t\tfor (int j=i; j&lt;n; j++) {\n\t\t\tmp[s[j]]++;\n\t\t\tint maxi = INT_MIN;\n\t\t\tint mini = INT_MAX;\n\t\t\t\n\t\t\tfor (auto it: mp) {\n\t\t\t\tmaxi = max(it.second, maxi);\n\t\t\t\tmini = min(it.second, mini);\n\t\t\t}\n\t\t\t\n\t\t\ttotalSum += (maxi-mini);\n\t\t}\n\t}\n\t\n\treturn totalSum;\n}\nString Hashing\ncp-algorithms.com/string/string-hashing.html\nLinked List\nthe fast slow pointers used here are very useful in array and in general traversal of any data structure.\nMiddle element in a Linked List\ntwo pointer fast and slow such that fast moves 2 * slows so in O(N/2) we can find middle element.\nListNode* middleNode(ListNode* head) {\n\tListNode* slow = head;\n\tListNode* fast = head;\n\t\n\twhile (fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next-&gt;next;\n\t}\n\t\n\treturn slow;\n}\nReverse a linked list (iterative)\nListNode* reverseList(ListNode* head) {\n\tListNode* prev = nullptr;\n\tListNode* next = head;\n\tListNode* curr = head;\n\t\n\twhile (next!=nullptr) {\n\t\tnext = curr-&gt;next;\n\t\tcurr-&gt;next = prev;\n\t\tprev = curr;\n\t\tcurr = next;\n\t}\n\t\n\treturn prev;\n}\nReverse a linked list (recursive)\nListNode* reverseList(ListNode* head) {\n\tif (head == nullptr || head-&gt;next == nullptr) {\n\t\treturn head;\n\t}\n\t\n\tListNode* new_head = reverseList(head-&gt;next);\n\tListNode* next = head-&gt;next;\n\tnext-&gt;next = head;\n\thead-&gt;next = nullptr;\n\t\n\treturn new_head;\n}\nDetect Loop in Linked List using 2 pointer (fast and slow)\ninside loop, slow move by 1 and fast by 2 so each iteration causes distance between them to reduce by 1\nbool hasCycle(ListNode *head) {\n\tListNode* slow = head;\n\tListNode* fast = head;\n\twhile (fast!=NULL &amp;&amp; fast-&gt;next!=NULL) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next-&gt;next;\n\t\tif (slow==fast) return true;\n\t}\n\treturn false;\n}\nFind Starting point of Loop in Linked List (fast and slow)\nIf distance from starting of Linked List to starting of Loop is d, then\nthe collision point of fast and slow is always mid point of loop,\nwhich is d so:\nhead ‚áê- d -‚áí loop starting ‚áê- d -‚áí collision point ‚áê-d -‚áí loop starting\nListNode *detectCycle(ListNode *head) {\n\tListNode* slow = head;\n\tListNode* fast = head;\n\tbool found = false;\n\t\n\twhile (fast!=NULL &amp;&amp; fast-&gt;next!=NULL) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next-&gt;next;\n\t\tif (slow==fast) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!found) {\n\t\treturn NULL;\n\t}\n\t\n\tslow = head;\n\twhile (slow!=fast) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next;\n\t}\n\t\n\treturn fast;\n}\nPalindrome:\nListNode* reverseList(ListNode* head) {\n\tif (head == nullptr || head-&gt;next == nullptr) {\n\t\treturn head;\n\t}\n\t\n\tListNode* new_head = reverseList(head-&gt;next);\n\tListNode* next = head-&gt;next;\n\tnext-&gt;next = head;\n\thead-&gt;next = nullptr;\n\t\n\treturn new_head;\n}\n \nbool isPalindrome(ListNode* head) {\n\tListNode* slow = head;\n\tListNode* fast = head;\n\t\n\twhile (fast-&gt;next!=nullptr&amp;&amp;fast-&gt;next-&gt;next!=nullptr) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next-&gt;next;\n\t}\n\tListNode* newHead = reverseList(slow-&gt;next);\n\tListNode* end = newHead;\n\tListNode* start = head;\n\twhile (end!=nullptr) {\n\t\tif (start-&gt;val != end-&gt;val) {\n\t\t\treturn false;\n\t\t}\n\t\tstart = start-&gt;next;\n\t\tend = end-&gt;next;\n\t}\n\treverseList(slow-&gt;next);\n\treturn true;\n}\nAll odd nodes before and then even nodes:\nListNode* oddEvenList(ListNode* head) {\n\tif (head==nullptr || head-&gt;next==nullptr) return head;\n\tListNode* evenHead = head-&gt;next;\n\tListNode* odd = head;\n\tListNode* even = head-&gt;next;\n \n\twhile (even!=nullptr &amp;&amp; even-&gt;next!=nullptr) {\n\t\todd-&gt;next = odd-&gt;next-&gt;next;\n\t\teven-&gt;next = even-&gt;next-&gt;next;\n\t\todd = odd-&gt;next;\n\t\teven = even-&gt;next;\n\t}\n\todd-&gt;next = evenHead;\n \n\treturn head;\n}\nRemove Nth node from the end (i.e. (length-N)th node)\nTo reach nth node from end,\nwe first move fast pointer n nodes so now it has length-n nodes left\nso now if we start moving slow pointer from start till fast pointer cover length-n nodes\nslow pointer cover length-n nodes too therefore reaching nth node from the end.\nListNode* removeNthFromEnd(ListNode* head, int n) {\n\tif (head-&gt;next == nullptr) {\n\t\tdelete head;\n\t\treturn nullptr;\n\t}\n\tListNode* fast = head;\n\tfor (int i=0; i&lt;n; i++){\n\t\tif (fast-&gt;next != nullptr) {\n\t\t\tfast = fast-&gt;next;\n\t\t} else {\n\t\t\tListNode* temp = head-&gt;next;\n\t\t\tdelete head;\n\t\t\treturn temp;\n\t\t}\n\t}\n\t\n\tListNode* slow = head;\n\twhile (fast-&gt;next!=nullptr) {\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next;\n\t}\n\tListNode* delNode = slow-&gt;next;\n\tslow-&gt;next = slow-&gt;next-&gt;next;\n\tdelete delNode;\n\t\n\treturn head;\n}\nMerge Sort for Linked List:\nListNode* findMiddle(ListNode* head) {\n\tListNode* prev = nullptr;\n\tListNode* slow = head;\n\tListNode* fast = head;\n\t\n\twhile (fast!=nullptr &amp;&amp; fast-&gt;next!=nullptr) {\n\t\tprev = slow;\n\t\tslow = slow-&gt;next;\n\t\tfast = fast-&gt;next-&gt;next;\n\t}\n\t\n\treturn prev;\n}\n \nListNode* mergeTwoSortedLinkedLists(ListNode* list1, ListNode* list2) {\n\tListNode* dummyNode = new ListNode(-1);\n\tListNode* temp = dummyNode;\n\t\n\twhile (list1 != nullptr &amp;&amp; list2 != nullptr) {\n\t\tif (list1-&gt;val &lt;= list2-&gt;val) {\n\t\t\ttemp-&gt;next = list1;\n\t\t\tlist1 = list1-&gt;next;\n\t\t} else {\n\t\t\ttemp-&gt;next = list2;\n\t\t\tlist2 = list2-&gt;next;\n\t\t}\n\t\ttemp = temp-&gt;next; \n\t}\n\t\n\tif (list1 != nullptr) {\n\t\ttemp-&gt;next = list1;\n\t} else {\n\t\ttemp-&gt;next = list2;\n\t}\n\t\n\treturn dummyNode-&gt;next;\n}\n \nListNode* sortList(ListNode* head) {\n\tif (head == nullptr || head-&gt;next == nullptr) {\n\t\treturn head;\n\t}\n\t\n\tListNode* middle = findMiddle(head);\n\tListNode* right = middle-&gt;next;\n\tmiddle-&gt;next = nullptr;\n\tListNode* left = head;\n\t\n\tleft = sortList(left);\n\tright = sortList(right);\n\t\n\treturn mergeTwoSortedLinkedLists(left, right);\n}\nIntersection Node of Two Linked Lists\nListNode *getIntersectionNode(ListNode *headA, ListNode *headB) {\n\tif (headA == NULL || headB == NULL) {\n\t\treturn NULL;\n\t}\n\tListNode* t1 = headA;\n\tListNode* t2 = headB;\n\t\n\twhile (t1!=t2) {\n\t\tt1 = t1-&gt;next;\n\t\tt2 = t2-&gt;next;\n\t\t\n\t\tif (t1 == t2) {\n\t\t\treturn t1;\n\t\t}\n\t\tif (t1 == NULL) {\n\t\t\tt1 = headB;\n\t\t}\n\t\tif (t2 == NULL) {\n\t\t\tt2 = headA;\n\t\t}\n\t}\n\t\n\treturn t1;\n}\nreverse K nodes groups:\nListNode* reverseList(ListNode* head) {\n\tListNode* prev = nullptr;\n\tListNode* next = head;\n\tListNode* curr = head;\n\t\n\twhile (next!=nullptr) {\n\t\tnext = curr-&gt;next;\n\t\tcurr-&gt;next = prev;\n\t\tprev = curr;\n\t\tcurr = next;\n\t}\n\t\n\treturn prev;\n}\n \nListNode* getKthNode(ListNode* temp, int k){\n\tk -= 1; \n\twhile(temp != nullptr &amp;&amp; k &gt; 0){\n\t\tk--; \n\t\ttemp = temp -&gt; next; \n\t}\n\treturn temp; \n}\n \nListNode* reverseKGroup(ListNode* head, int k) {\n\tListNode* temp = head; \n\tListNode* prevLast = nullptr; \n\t\n\twhile(temp != nullptr){\n\t\tListNode* kThNode = getKthNode(temp, k); \n\t\tif(kThNode == nullptr){\n\t\t\tif(prevLast){\n\t\t\t\tprevLast -&gt; next = temp; \n\t\t\t}\n\t\t\tbreak; \n\t\t}\n\t\t\n\t\tListNode* nextNode = kThNode -&gt; next;\n\t\tkThNode -&gt; next = nullptr; \n\t\treverseList(temp); \n\t\t\n\t\tif(temp == head){\n\t\t\thead = kThNode;\n\t\t}else{\n\t\t\tprevLast -&gt; next = kThNode; \n\t\t}\n\t\t\n\t\tprevLast = temp; \n\t\ttemp = nextNode; \n\t}\n\t\n\treturn head; \n}\nRecursion\nBinary Exponentiation - Errichto\ndouble myPow(double x, int n) {\n\tdouble res = 1;\n\tlong long nn = n;\n\tif (nn&lt;0) {\n\t\tnn = -1*nn;\n\t\tx = 1/x;\n\t}\n\twhile (nn &gt; 0) {\n\t\tif (nn%2 == 1) res*=x;\n\t\tx *= x;\n\t\tnn /= 2;\n\t}\n\t\n\treturn res;\n}\nGenerate Binary Strings Without Adjacent Zeros (Iterative)\nvector&lt;string&gt; generate_binary_strings(vector&lt;string&gt; bs, int n) {\n\tvector&lt;string&gt; temp = bs; \n    while (n--) {\n        vector&lt;string&gt; current = temp;\n        temp.clear();\n\t\t\n        for (const auto&amp; b : current) {\n            if (b.back() == &#039;0&#039;) {\n                temp.push_back(b + &#039;1&#039;);\n            } else {\n                temp.push_back(b + &#039;0&#039;);\n                temp.push_back(b + &#039;1&#039;);\n            }\n        }\n    }\n    return temp;\n}\n \nvector&lt;string&gt; validStrings(int n) {\n\treturn generate_binary_strings({&quot;0&quot;, &quot;1&quot;}, n-1); \n}\nGenerate Binary Strings Without Adjacent Zeros (Recursive)\nvector&lt;string&gt; generate_binary_strings(vector&lt;string&gt; bs, int n) {\n\tif (n == 0) return bs;\n\t\n\tvector&lt;string&gt; current = bs;\n\tbs.clear();\n\tfor (const auto&amp; b : current) {\n\t\tif (b.back() == &#039;0&#039;) {\n\t\t\tbs.push_back(b + &#039;1&#039;);\n\t\t} else {\n\t\t\tbs.push_back(b + &#039;0&#039;);\n\t\t\tbs.push_back(b + &#039;1&#039;);\n\t\t}\n\t}\n\t\n\treturn generate_binary_strings(bs, n-1);\n}\n \nvector&lt;string&gt; validStrings(int n) {\n\treturn generate_binary_strings({&quot;0&quot;,&quot;1&quot;}, n-1);\n}\nRecursive Backtracking\nRecursive backtracking is complex, but very useful when we have to conditionally skip/create a branch of choices\nwe can understand recursive backtracking with problems like conditional subsets\nhow recursion might help ? ‚Üí In recursion if we know a branch won‚Äôt yield the results we can simply skip whole branch.\nlets say we have an array and we want to generate subsets what can we do ?\nMethods:\n\nUse bitmask (2^n * n) ‚Üí use only if use want all subsets as it‚Äôs same as recursive but is simpler than recursive\nUse Recursion ‚Üí for each element think if you want to take it or not sequentially\nExample: Combination Sum I or Subsets I\nUse Recursion ‚Üí sequentially pick how many elements you want in subsets\nExample: Combination Sum II or Subsets II\n\nSubsets II\nvoid findSubsets(int pos, vector&lt;int&gt;&amp; nums, vector&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds){\n\tans.push_back(ds);\n\tfor (int i=pos; i&lt;nums.size(); i++){\n\t\tif(i!=pos &amp;&amp; nums[i] == nums[i-1]) continue;\n\t\tds.push_back(nums[i]);\n\t\tfindSubsets(i+1, nums, ans, ds);\n\t\tds.pop_back();\n\t}\n}\n \nvector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) {\n\tvector&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\t\n\tsort(nums.begin(), nums.end());\n\tfindSubsets(0, nums, ans, ds);\n\t\n\treturn ans;\n}\nCombination Sum\nall subsequences that sum up to target and each element can be selected multiple times\nvoid find_combinations (int pos, int target, vector&lt;int&gt;&amp; candidates, vector&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds) {\n\tif (pos == candidates.size()) {\n\t\tif (target == 0){\n\t\t\tans.push_back(ds);\n\t\t}\n\t\treturn;\n\t}\n\t\n\tif (candidates[pos] &lt;= target) {\n\t\tds.push_back(candidates[pos]);\n\t\t// taking the same element again\n\t\tfind_combinations(pos, target - candidates[pos], candidates, ans, ds);\n\t\t// after backtracking if this branch final ds does not sum up to target we pop back the element\n\t\tds.pop_back();\n\t}\n\t\n\t// taking the next element\n\tfind_combinations(pos+1, target, candidates, ans, ds);\n}\n \nvector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) {\n\tvector&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\t\n\tfind_combinations(0, target, candidates, ans, ds);\n\treturn ans;\n}\nCombination Sum II\nall subsequences that sum up to target and each element can be selected once only\nto solve this we can use similar method as used in Combination Sum, i.e at each point select or not select and then move ahead to next recursion with updated target and length of array. We just need to move to next element no matter what and use set to store.\nvoid find_unique_combinations (int pos, int target, vector&lt;int&gt;&amp; candidates, set&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds) {\n\tif (pos == candidates.size()) {\n\t\tif (target == 0){\n\t\t\tif (ans.find(ds) == ans.end()) {\n\t\t\t\tans.insert(ds);\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n\t\n\tif (candidates[pos] &lt;= target) {\n\t\tds.push_back(candidates[pos]);\n\t\tfind_unique_combinations(pos+1, target - candidates[pos], candidates, ans, ds);\n\t\tds.pop_back();\n\t}\n\t\n    find_unique_combinations(pos+1, target, candidates, ans, ds);\n}\n \nvector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt; &amp;candidates, int target) {\n\tset&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tsort(candidates.begin(), candidates.end());\n\tfind_unique_combinations(0, target, candidates, ans, ds);\n\tfor (auto i : ans) {\n\t\tres.push_back(i);\n\t}\n\t\n\treturn res;\n}\nHere instead of picking not picking each element we pick every possible element that is unique for given length of subset\nvoid find_unique_combinations(int pos, int target, vector&lt;int&gt; &amp;candidates, vector&lt;vector&lt;int&gt;&gt; &amp;ans, vector&lt;int&gt; &amp;ds) {\n\tif (target == 0) {\n\t\tans.push_back(ds);\n\t\treturn;\n\t}\n\tfor (int i = pos; i &lt; candidates.size(); i++) {\n\t\t// Skip duplicates at the same level\n\t\tif (i != pos &amp;&amp; candidates[i] == candidates[i - 1])\n\t\t\tcontinue;\n\t\t// Stop if the current element is too large\n\t\tif (candidates[i] &gt; target)\n\t\t\tbreak;\n\t\t// Include the current element\n\t\tds.push_back(candidates[i]);\n\t\tfind_unique_combinations(i + 1,target - candidates[i],candidates,ans,ds);\n\t\tds.pop_back(); // Backtrack\n\t}\n}\n \nvector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt; &amp;candidates, int target) {\n\tvector&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\tsort(candidates.begin(), candidates.end());\n\tfind_unique_combinations(0, target, candidates, ans, ds);\n\treturn ans;\n}\nStandard Recursive questions\nPalindrome Partitioning\nbool ispalin(string s, int start, int end) {\n\twhile (start&lt;=end) {\n\t\tif (s[start++] != s[end--]) return false;\n\t}\n\treturn true;\n}\n \nvoid func(int pos, string s, vector&lt;vector&lt;string&gt;&gt;&amp; ans, vector&lt;string&gt;&amp; ds) {\n\tif (pos == s.size()) {\n\t\tans.push_back(ds);\n\t\treturn;\n\t}\n\t\n\tfor (int i=pos; i&lt;s.size(); i++) {\n\t\tif (ispalin(s, pos, i)) {\n\t\t\tds.push_back(s.substr(pos, i-pos+1));\n\t\t\tfunc(i+1, s, ans, ds);\n\t\t\tds.pop_back();\n\t\t}\n\t}\n}\n \nvector&lt;vector&lt;string&gt;&gt; partition(string s) {\n\tvector&lt;vector&lt;string&gt;&gt; ans;\n\tvector&lt;string&gt; ds;\n\t\n\tfunc(0, s, ans, ds);\n\treturn ans;\n}\nWord Search in 2D Grid\nbool try_search(int pos, vector&lt;vector&lt;char&gt;&gt; board, string word, int i, int j, int n, int m) {\n\tif (pos == word.length()) return true;\n \n\tif (i &lt; 0 || j &lt; 0 || j == m || i == n || board[i][j] != word[pos] or board[i][j] == &#039;!&#039;)\n\t\treturn false;\n \n\tchar temp = board[i][j]; \n\tboard[i][j] = &#039;!&#039;;\n\tbool bottom = try_search(pos+1, board, word, i+1, j, n, m);\n\tbool right = try_search(pos+1, board, word, i, j+1, n, m);\n\tbool top = try_search(pos+1, board, word, i-1, j, n, m);\n\tbool left = try_search(pos+1, board, word, i, j-1, n, m);\n\tboard[i][j] = temp;\n\t\n\treturn top || bottom || right || left;\n}\n \nbool exist(vector&lt;vector&lt;char&gt;&gt;&amp; board, string word) {\n\tint n = board.size();\n\tint m = board[0].size();\n\tfor (int i=0; i&lt;n; i++) {\n\t\tfor (int j=0; j&lt;m; j++) {\n\t\t\tif (board[i][j] == word[0]){\n\t\t\t\tif (try_search(0, board, word, i, j, n, m)) return true;\n\t\t\t} \n\t\t}\n\t}\n\treturn false;\n}\nBit Manipulation\nBitwise operations for beginners - Codeforces\nyoutu.be/LGrE0siZ-ZA\nEven or Odd\nif (x%2 == 0)    // even\nif (x&amp;1 == 0)    // even (takes O(1) time dbetter way)\nas last bit of every even number is 0\nCheck if number is prime\nbool is_prime(int n) {\n\tif (n&lt;=1) return false;\n\tif (n == 2) return true;\n\tif ((n&amp;1) == 0) return false;\n\t\n\tint root = sqrt(n);\n\tfor (int i=3; i&lt;=root; i+=2) {\n\t\tif (n%i == 0) {\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}\nPrime factors of a number\nif a number is divisible by i(lets say 2) then divide it till it can so that all multiples of i are removed and at last as we are iterating only till sqrt of n if a number is still in n then it is the prime factor above sqrt of n.\nvector&lt;int&gt; prime_factors(int n) {\n\tint root = sqrt(n);\n\tvector&lt;int&gt; factors;\n\t\n\tfor (int i=2; i&lt;=root; i++) {\n\t\tif (n%i == 0) {\n\t\t\tfactors.push_back(i);\n\t\t\twhile (n%i == 0) {\n\t\t\t\tn = n/i;\n\t\t\t}\n\t\t}\n\t}\n\tif (n!=1) factors.push_back(n);\n\t\n\treturn factors;\n}\nfactors of a number\nvector&lt;int&gt; all_factors(int n) {\n\tvector&lt;int&gt; f1, f2;\n\tint root = sqrt(n);\n\t\n\tfor (int i=1; i&lt;=root; i++) {\n\t\tif (n%i == 0) {\n\t\t\tf1.push_back(i);\n\t\t\tif (i != n/i) {\n\t\t\t\tf2.insert(f2.begin(), n/i);\n\t\t\t}\n\t\t}\n\t}\n\t\n\tvector&lt;int&gt; result;\n\tresult.reserve(f1.size() + f2.size());\n\tresult.insert(result.end(), f1.begin(), f1.end());\n\tresult.insert(result.end(), f2.begin(), f2.end());\n\treturn result;\n}\nSieve of Eratosthenes\nprime till n, mark all multiples of a number as 0 in an array\nvector&lt;int&gt; prime_till_n(int n) {\n\tint primes[n+1];\n\tfor (int i=2; i&lt;=n; i++) primes[i] = 1;\n\t\n\tfor (int i=2; (i*i)&lt;=n; i++) {\n\t\tif (is_prime(i) == 1) {\n\t\t\tfor (int j=i*i; j&lt;=n; j+=i){\n\t\t\t\tprimes[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tvector&lt;int&gt; result;\n\tfor (int i=2; i&lt;=n; i++) {\n\t\tif (primes[i] == 1) result.push_back(i);\n\t}\n\t\n\treturn result;\n}\ncheck if number is power of 2\nbool powerof2(int x){\n\treturn x &amp;&amp; !( x&amp;(x-1) )\n}\nMultiply or Divide a number by 2^k\n\nx * 2^k  = x&lt;&lt;k\nx / 2^k  = x&gt;&gt;k\n\nkth bit:\n1&lt;&lt;k = 2^k\n\nToggle kth bit: x ^ (1&lt;&lt;k)\nSet kth bit (make kth bit 1): x | (1&lt;&lt;k)\nUnset kth bit (make kth bit 0): x &amp; ~(1&lt;&lt;k)\nRemove the last set bit (rightmost): x &amp; (x-1)\n\nSwap 2 numbers using bit manipulation\n\nx = x^y ‚áí x = x^y , y = y\ny = x^y ‚áí x = x^y , y = x^y^y = x\nx = x^y ‚áí x = x^y^x = y , y = x\n\nCount number of set bits (traditional method)\nint count_set_bits(int n) {\n\tint cnt = 0;\n\twhile (n&gt;1) {\n\t\tcnt += (n&amp;1);\n\t\tn = n&gt;&gt;1; \n\t}\n\tif (n==1) cnt+=1;\n\treturn cnt;\n}\nCount number of set bits (each step we turn off the right most bit)\nint count_set_bits(int n) {\n\tint cnt = 0;\n\twhile (n!=0) {\n\t\tn = n&amp;(n-1);\n\t\tcnt++; \n\t}\n\treturn cnt;\n}\nDivide without division operator\nint divide(int dividend, int divisor) {\n\tif(dividend == divisor) return 1;\n\tbool sign = true;\n\tif ((dividend&gt;=0 &amp;&amp; divisor&lt;0) || (dividend&lt;0 &amp;&amp; divisor&gt;0)) sign = false;\n\tlong long ans=0;\n\tlong long n = abs((long long)dividend);\n\tlong long d = abs((long long)divisor);\n\t\n\twhile (n&gt;=d) {\n\t\tlong long cnt = 0;\n\t\twhile(n&gt;=(d&lt;&lt;(cnt+1))){\n\t\t\tcnt++;\n\t\t}\n\t\tans += (long long)1&lt;&lt;cnt;\n\t\tn = n - (d*((long long)1&lt;&lt;cnt));\n\t}\n\t\n\tif (ans&gt;INT_MAX &amp;&amp; sign) return INT_MAX;\n\tif (ans&gt;INT_MAX &amp;&amp; !(sign)) return INT_MIN;\n\t\n\treturn sign ? ans : (-1*ans);\n}\nXOR from 1 to n (follows a pattern)\nint xor_till_n(int n) {\n\tif (n%4 == 0) return n;\n\telse if (n%4 == 1) return 1;\n\telse if (n%4 == 2) return n+1;\n\telse return 0;\n}\nSingle Number I\nall numbers appear twice except one that appear once\nsol :- xor of all numbers\nint singleNumber(vector&lt;int&gt;&amp; nums) {\n\tint temp = 0;\n\tfor (auto i: nums){\n\t\ttemp ^= i;\n\t}\n\treturn temp;\n}\nSingle Number II\nall numbers appear thrice except one that appear once\nsol 1:- count the number of set bits at a single position in all numbers, if it‚Äôs multiple of 3 then that bit of answer is 0 otherwise it‚Äôs 1\nint singleNumber(vector&lt;int&gt;&amp; nums) {\n\tint ans = 0;\n\tfor (int i=0; i&lt;31; i++) {\n\t\tint pos_bit = 1&lt;&lt;i;\n\t\tint cnt = 0;\n\t\tfor (auto num: nums) {\n\t\t\tif ((num&amp;pos_bit) != 0) {\n\t\t\t\tcnt++;\n\t\t\t}\n\t\t}\n\t\tif ((cnt%3) != 0) {\n\t\t\tans |= pos_bit;\n\t\t}\n\t}\n\treturn ans;\n}\nsol 2:- ones store numbers that appear once, if a number appear second time we store it in twos so, twos store numbers that appear twice and if number appear thrice we remove it from twos\n\nnow think that all thrice appearing numbers are together at start and last one is the answer (it‚Äôs for understanding but it all works out for any order because we are dealing with bits)\nnow first we check if new number is not in twos (as not of number and number is zero) and if it‚Äôs not in twos we add it in ones by xor (so that when we get second time it deletes and if it‚Äôs first time xor of 0 and number occurs leading to number)\nnow check if new number is already in ones\n\nint singleNumber(vector&lt;int&gt;&amp; nums) {\n\tint ones = 0;\n\tint twos = 0;\n\t\n\tfor (const int num : nums) {\n\t\tones ^= (num &amp; ~twos);\n\t\ttwos ^= (num &amp; ~ones);\n\t}\n\t\n\treturn ones;\n}\nSingle Number III\ntwo elements appear only once and all the other elements appear exactly twice.\nvector&lt;int&gt; singleNumber(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tlong long xorr=0;\n\tfor (auto num: nums) {\n\t\txorr ^= num;\n\t}\n\t\n\tlong long right_most_set_bit = (xorr&amp;(xorr-1))^xorr;\n\tint bucket_1 = 0;\n\tint bucket_2 = 0;\n\t\n\tfor (auto num: nums) {\n\t\tif (num&amp;right_most_set_bit) {\n\t\t\tbucket_1 ^= num;\n\t\t} else {\n\t\t\tbucket_2 ^= num;\n\t\t}\n\t}\n\t\n\treturn {bucket_1, bucket_2};\n}\nGenerate a Power set i.e all subsets i.e. all subsequences of an array\nouter loop from 0 to 2^n generates masks\ninner loop iterate through each bit in mask and if bit is 1 then take element from nums from that position.\nwe use mask as a map to guide us which element to take by &amp; operator checking for each bit if we want to take that element represented by i bit.\nvector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;vector&lt;int&gt;&gt; subsets;\n\t\n\tfor (long long mask=0; mask&lt;(1&lt;&lt;n); mask++) {\n\t\tvector&lt;int&gt; curr;\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (mask &amp; (1&lt;&lt;j)) {\n\t\t\t\tcurr.push_back(nums[j]);\n\t\t\t}\n\t\t}\n\t\tsubsets.push_back(curr);\n\t}\n\treturn subsets;\n}\nSubsequences with sum equal to k\nint subsequence_sum_equal_k(vector&lt;int&gt;&amp; nums, int k) {\n\tint n = nums.size();\n\tint curr_cnt = 0;\n\t\n\tfor (long long mask=0; mask&lt;(1&lt;&lt;n); mask++) {\n\t\tlong long sum_of_this_subset = 0;\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (mask &amp; (1&lt;&lt;j)) {\n\t\t\t\tsum_of_this_subset += nums[j];\n\t\t\t}\n\t\t}\n\t\tif (sum_of_this_subset == k) {\n\t\t\tcurr_cnt++;\n\t\t}\n\t}\n\t\n\treturn curr_cnt;\n}\nStacks and Queue\n\nStack ‚áí Last In First Out (LIFO) rule\nQueue ‚áí First In First Out (FIFO) rule\n\nstack using array\nclass Stack {\n\tint size;\n\tint* arr;\n\tint top;\n\t\n\tpublic:\n\t\tStack() {\n\t\t\ttop = -1;\n\t\t\tsize = 5;\n\t\t\tarr = new int[size];\n\t\t}\n\t\t\n\t\tvoid push(int n) {\n\t\t\tif (top+1 &gt; size) {\n\t\t\t\tcout &lt;&lt; &quot;stack full&quot; &lt;&lt; endl;\n\t\t\t}\n\t\t\ttop++;\n\t\t\tarr[top] = n;\n\t\t}\n\t\t\n\t\tint pop() {\n\t\t\tif (top-1 &lt; 0) {\n\t\t\t\tcout &lt;&lt; &quot;stack empty&quot; &lt;&lt; endl;\n\t\t\t}\n\t\t\tint res = arr[top];\n\t\t\ttop--;\n\t\t\t\n\t\t\treturn res;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\treturn arr[top];\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn top+1;\n\t\t}\n};\nqueue using array (this implementation keeps start at 0)\nclass Queue {\n\tint size;\n\tint* arr;\n\tint start;\n\tint end;\n\t\n\tpublic:\n\t\tQueue() {\n\t\t\tstart = -1;\n\t\t\tend = -1;\n\t\t\tsize = 5;\n\t\t\tarr = new int[size];\n\t\t}\n\t\t\n\t\tvoid push(int n) {\n\t\t\tif (end+1 &gt; size) {\n\t\t\t\tcout &lt;&lt; &quot;queue full&quot; &lt;&lt; endl;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (start == -1) {\n\t\t\t\tstart = 0;\n\t\t\t}\n\t\t\tend++;\n\t\t\tarr[end] = n;\n\t\t}\n\t\t\n\t\tint pop() {\n\t\t\tif (start == -1) {\n\t\t\t\tcout &lt;&lt; &quot;queue empty&quot; &lt;&lt; endl;\n\t\t\t\treturn INT_MIN;\n\t\t\t}\n\t\t\tint res = arr[start];\n\t\t\tfor (int i=1; i&lt;=end; i++) {\n\t\t\t\tarr[i-1] = arr[i];\n\t\t\t}\n\t\t\tend--;\n\t\t\n\t\t\treturn res;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\tif (end == -1) {\n\t\t\t\tcout &lt;&lt; &quot;queue empty&quot; &lt;&lt; endl;\n\t\t\t\treturn INT_MIN;\n\t\t\t}\n\t\t\treturn arr[end];\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn end+1;\n\t\t}\n};\nStack using Queue\nclass Stack_using_Queue {\n\tqueue&lt;int&gt; q;\n\t\n\tpublic:\n\t\tvoid Push(int n) {\n\t\t\tq.push(n);\n\t\t\tfor (int i=0; i&lt;q.size()-1; i++) {\n\t\t\t\tq.push(q.front());\n\t\t\t\tq.pop();\n\t\t\t}\n\t\t}\n\t\t\n\t\tint Pop() {\n\t\t\tint temp = q.front();\n\t\t\tq.pop();\n\t\t\treturn temp;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\treturn q.front();\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn q.size();\n\t\t}\n};\nQueue using Stack\nclass Queue_using_Stack {\n\tstack&lt;int&gt; s1, s2;\n\t\n\tpublic:\n\t\tvoid Push(int n) {\n\t\t\twhile (!s1.empty()) {\n\t\t\t\ts2.push(s1.top());\n\t\t\t\ts1.pop();\n\t\t\t}\n\t\t\ts2.push(n);\n\t\t\twhile (!s2.empty()) {\n\t\t\t\ts1.push(s2.top());\n\t\t\t\ts2.pop();\n\t\t\t}\n\t\t}\n\t\t\n\t\tint Pop() {\n\t\t\tint temp = s1.top();\n\t\t\ts1.pop();\n\t\t\treturn temp;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\treturn s1.top();\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn s1.size();\n\t\t}\n};\nCheck for Balanced Parentheses\nbool isValid(string s) {\n\tstack&lt;char&gt; st;\n\tfor (auto c: s) {\n\t\tif (c == &#039;(&#039; || c == &#039;{&#039; || c == &#039;[&#039;) {\n\t\t\tst.push(c);\n\t\t} else {\n\t\t\tif (st.size() == 0) return false;\n\t\t\tif ((st.top() == &#039;(&#039; &amp;&amp; c == &#039;)&#039;) || (st.top() == &#039;{&#039; &amp;&amp; c == &#039;}&#039;) || (st.top() == &#039;[&#039; &amp;&amp; c == &#039;]&#039;)) {\n\t\t\t\tst.pop();\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\treturn st.empty();\n}\nInfix Prefix Postfix\nInfix to Postfix\nstring infix_str = &quot;a+b*(c^d-e)^(f+g*h)-i&quot;;\nstring postfix_str = &quot;abcd^e-fgh*+^*+i-&quot;;\nstring prefix_str = &quot;-+a*b^-^cde+f*ghi&quot;;\n\nif any operand add to result\nif opening bracket add to operators stack, if closing bracket pop and add to result till opening bracket comes\nif an operator\n\nif it‚Äôs precedence is smaller than stack‚Äôs top operator i.e. last operator then remove the operator till stack is empty of the new operator have greater precedence than that in stack top\nfinally add the new operator in stack\n\n\nat the end if any operators are left print out all\n\nstring infix_to_postfix(string s) {\n\tstack&lt;char&gt; st;\n\tstring res;\n\t\n\tfor (auto c: s) {\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tres += c;\n\t\t} else if (c == &#039;(&#039;) {\n\t\t\tst.push(c);\n\t\t} else if (c == &#039;)&#039;) {\n\t\t\twhile (st.top() != &#039;(&#039;) {\n\t\t\t\tres += st.top();\n\t\t\t\tst.pop();\n\t\t\t}\n\t\t\tst.pop();\n\t\t} else {\n\t\t\twhile (!st.empty() &amp;&amp; prec(c)&lt;=prec(st.top())) {\n\t\t\t\tres += st.top();\n\t\t\t\tst.pop();\n\t\t\t}\n\t\t\tst.push(c);\n\t\t}\n\t}\n\t\n\twhile (!st.empty()) {\n\t\tres += st.top();\n\t\tst.pop();\n\t}\n\t\n\treturn res;\n}\nInfix to Prefix\n\nreverse the infix (make sure the brackets are reversed after reversing so that ( comes before ))\nresult = apply infix to postfix with condition that if ^ then pop till &lt;= precedence otherwise pop till &lt; precedence\nreverse the result (make sure the brackets are reversed after reversing so that ( comes before ))\n\nstring infix_to_prefix(string s) {\n\tstack&lt;char&gt; st;\n\tstring res;\n \n\treverse(s.begin(), s.end());\n\tfor (int i = 0; i&lt;s.length(); i++) {\n        if (s[i] == &#039;(&#039;) {\n            s[i] = &#039;)&#039;;\n        } else if (s[i] == &#039;)&#039;) {\n            s[i] = &#039;(&#039;;\n        }\n    }\n\t\n\tfor (auto c: s) {\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tres += c;\n\t\t} else if (c == &#039;(&#039;) {\n\t\t\tst.push(c);\n\t\t} else if (c == &#039;)&#039;) {\n\t\t\twhile (st.top() != &#039;(&#039;) {\n\t\t\t\tres += st.top();\n\t\t\t\tst.pop();\n\t\t\t}\n\t\t\tst.pop();\n\t\t} else {\n\t\t\tif (c == &#039;^&#039;) {\n\t\t\t\twhile (!st.empty() &amp;&amp; prec(c)&lt;=prec(st.top())) {\n\t\t\t\t\tres += st.top();\n\t\t\t\t\tst.pop();\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\twhile (!st.empty() &amp;&amp; prec(c)&lt;prec(st.top())) {\n\t\t\t\t\tres += st.top();\n\t\t\t\t\tst.pop();\n\t\t\t\t}\n\t\t\t}\n\t\t\tst.push(c);\n\t\t}\n\t}\n\t\n\twhile (!st.empty()) {\n\t\tres += st.top();\n\t\tst.pop();\n\t}\n\t\n\treverse(res.begin(), res.end());\n\tfor (int i = 0; i&lt;res.length(); i++) {\n        if (res[i] == &#039;(&#039;) {\n            res[i] = &#039;)&#039;;\n        } else if (res[i] == &#039;)&#039;) {\n            res[i] = &#039;(&#039;;\n        }\n    }\n\t\n\treturn res;\n}\nPostfix to Infix\n\nadd operands to stack\nif encounter a operator takes last 2 operands from stack, add operator between them and wrap them into a single unit such that top2 + operator + top1\n\nstring postfix_to_infix(string s) {\n\tstack&lt;string&gt; st;\n\t\n\tfor (auto c: s) {\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tstring temp;\n\t\t\ttemp.push_back(c);\n\t\t\tst.push(temp);\n\t\t} else {\n\t\t\tstring t1 = st.top();\n\t\t\tst.pop();\n\t\t\tstring t2 = st.top();\n\t\t\tst.pop();\n\t\t\tstring temp = &#039;(&#039; + t2 + c + t1 + &#039;)&#039;;\n\t\t\tst.push(temp);\n\t\t}\n\t}\n\t\n\treturn st.top();\n}\nPrefix to Infix\n\nstart iterator from end\nadd operands to stack\nif encounter a operator takes last 2 operands from stack, add operator between them and wrap them into a single unit such that top1 + operator + top2\n\nstring prefix_to_infix(string s) {\n\tstack&lt;string&gt; st;\n\tint i = s.length()-1;\n\t\n\twhile (i &gt;= 0) {\n\t\tchar c = s[i];\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tstring temp;\n\t\t\ttemp.push_back(c);\n\t\t\tst.push(temp);\n\t\t} else {\n\t\t\tstring t1 = st.top();\n\t\t\tst.pop();\n\t\t\tstring t2 = st.top();\n\t\t\tst.pop();\n\t\t\tstring temp = &#039;(&#039; + t1 + c + t2 + &#039;)&#039;;\n\t\t\tst.push(temp);\n\t\t}\n\t\ti--;\n\t}\n\t\n\treturn st.top();\n}\nPostfix to Infix\n\nadd operands to stack\nif encounter a operator takes last 2 operands from stack, add operator between them and wrap them into a single unit such that operator + top2 + top1\n\nstring postfix_to_prefix(string s) {\n\tstack&lt;string&gt; st;\n\t\n\tfor (auto c: s) {\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tstring temp;\n\t\t\ttemp.push_back(c);\n\t\t\tst.push(temp);\n\t\t} else {\n\t\t\tstring t1 = st.top();\n\t\t\tst.pop();\n\t\t\tstring t2 = st.top();\n\t\t\tst.pop();\n\t\t\tstring temp = c + t2 + t1;\n\t\t\tst.push(temp);\n\t\t}\n\t}\n\t\n\treturn st.top();\n}\nPostfix to Infix\n\nadd operands to stack\nif encounter a operator takes last 2 operands from stack, add operator between them and wrap them into a single unit such that top1 + top2 + operator\n\nstring prefix_to_postfix(string s) {\n\tstack&lt;string&gt; st;\n\tint i = s.length()-1;\n\t\n\twhile (i &gt;= 0) {\n\t\tchar c = s[i];\n\t\tif ((c&gt;=&#039;A&#039; &amp;&amp; c&lt;=&#039;Z&#039;) || (c&gt;=&#039;a&#039; &amp;&amp; c&lt;=&#039;z&#039;) || (c&gt;=&#039;0&#039; &amp;&amp; c&lt;=&#039;9&#039;)) {\n\t\t\tstring temp;\n\t\t\ttemp.push_back(c);\n\t\t\tst.push(temp);\n\t\t} else {\n\t\t\tstring t1 = st.top();\n\t\t\tst.pop();\n\t\t\tstring t2 = st.top();\n\t\t\tst.pop();\n\t\t\tstring temp = t1 + t2 + c;\n\t\t\tst.push(temp);\n\t\t}\n\t\ti--;\n\t}\n\t\n\treturn st.top();\n}\nMonotonic Stack/Queue problems\nNext greater element\n\nstart from end\nkeep stack in ascending order and if a number is &gt; top then remove from stack till we can place it in ascending order\n\nvector&lt;int&gt; nextGreaterElement(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) {\n\tint n = nums2.size()-1;\n\tunordered_map&lt;int, int&gt; reference;\n\tstack&lt;int&gt; nge;\n\t\n\tfor (int i=n; i&gt;=0; i--) {\n\t\twhile (!nge.empty() &amp;&amp; (nge.top() &lt; nums2[i])) {\n\t\t\tnge.pop();\n\t\t}\n\t\tif (nge.empty()) {\n\t\t\treference[nums2[i]] = -1;\n\t\t} else {\n\t\t\treference[nums2[i]] = nge.top();\n\t\t}\n\t\tnge.push(nums2[i]);\n\t}\n\t\n\tvector&lt;int&gt; res(nums1.size(), -1);\n\tfor (int i=0; i&lt;nums1.size(); i++) {\n\t\tres[i] = reference[nums1[i]];\n\t}\n\t\n\treturn res;\n}\nNext greater element (circular)\n\nstart from twice of end and use %n to get elements\nso for first n iterations of loop only push pop will be executed and thus leaving us with the rightmost greater elements in order in stack.\nkeep stack in ascending order and if a number is &gt; top then remove from stack till we can place it in ascending order\n\nvector&lt;int&gt; nextGreaterElements(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; nge(n, -1);\n\tstack&lt;int&gt; st;\n\t\n\tfor (int i=2*n-1; i &gt;= 0; i--) {\n\t\twhile (!st.empty() &amp;&amp; st.top() &lt;= nums[i % n]) {\n\t\t\tst.pop();\n\t\t}\n\t\t\n\t\tif (i &lt; n) {\n\t\t\tif (!st.empty()) nge[i] = st.top();\n\t\t}\n\t\tst.push(nums[i % n]);\n\t}\n\t\n\treturn nge;\n}\nTrapping Rain Water\nfor any arr[i] we know it can store water above it of height min(leftMax, rightMax) - arr[i]\nso for each position we need to find the maximum height on both sides of that position, which is equal to prefixMax and suffixMax, but finding all max would take O(N) for both prefix and suffix.\nwe can take 2 pointer each pointing to the max.\n\nprefixMax suffixMax method\n\nint trap(vector&lt;int&gt;&amp; arr) {\n\tint n = arr.size();\n\t\n\tint prefix[n], suffix[n];\n\tprefix[0] = arr[0];\n\tfor (int i = 1; i &lt; n; i++) {\n\t\tprefix[i] = max(prefix[i - 1], arr[i]);\n\t}\n\tsuffix[n - 1] = arr[n - 1];\n\tfor (int i = n - 2; i &gt;= 0; i--) {\n\t\tsuffix[i] = max(suffix[i + 1], arr[i]);\n\t}\n\t\n\tint waterTrapped = 0;\n\tfor (int i = 0; i &lt; n; i++) {\n\t\twaterTrapped += min(prefix[i], suffix[i]) - arr[i];\n\t}\n\t\n\treturn waterTrapped;\n}\n\nusing 2 pointer\n\nint trap(vector&lt;int&gt;&amp; height) {\n\tint n = height.size();\n\tint waterTrapped = 0; \n\tint leftMax = 0, rightMax = 0;\n\tint l=0, r=n-1;\n\t\n\twhile (l&lt;r) {\n\t\tif (height[l] &lt;= height[r]) {\n\t\t\tif (leftMax &gt; height[l]) {\n\t\t\t\twaterTrapped += leftMax - height[l]; \n\t\t\t} else {\n\t\t\t\tleftMax = height[l];\n\t\t\t}\n\t\t\tl = l+1;\n\t\t} else {\n\t\t\tif (rightMax &gt; height[r]) {\n\t\t\t\twaterTrapped += rightMax - height[r];\n\t\t\t} else {\n\t\t\t\trightMax = height[r];\n\t\t\t}\n\t\t\tr = r-1;\n\t\t}\n\t}\n\t\n\treturn waterTrapped;\n}\nasteroid collision\nvector&lt;int&gt; asteroidCollision(vector&lt;int&gt;&amp; asteroids) {\n\tint n = asteroids.size();\n\tvector&lt;int&gt; st;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tif (asteroids[i] &gt;= 0 ) st.push_back(asteroids[i]);\n\t\telse {\n\t\t\twhile(!st.empty() &amp;&amp; st.back()&gt;0 &amp;&amp; (st.back() &lt; abs(asteroids[i]))){\n\t\t\t\tst.pop_back();\n\t\t\t}\n\t\t\tif (!st.empty() &amp;&amp; st.back()==abs(asteroids[i])) {\n\t\t\t\tst.pop_back();\n\t\t\t} else if (st.empty() || st.back()&lt;0) {\n\t\t\t\tst.push_back(asteroids[i]);\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn st; \n}\nSum of subarray minimums\n\nfind after how many elements we get next smallest\nthen PnC\n\nvector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; nse;\n\t\n\tfor (int i=n-1; i&gt;=0; i--) {\n\t\twhile (!nse.empty() &amp;&amp; (nums[nse.top()] &gt;= nums[i])) {\n\t\t\tnse.pop();\n\t\t}\n\t\tif (nse.empty()) {\n\t\t\tres[i] = n;\n\t\t} else {\n\t\t\tres[i] = nse.top();\n\t\t}\n\t\tnse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; prevSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; pse;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!pse.empty() &amp;&amp; (nums[pse.top()] &gt; nums[i])) {\n\t\t\tpse.pop();\n\t\t}\n\t\tif (pse.empty()) {\n\t\t\tres[i] = -1;\n\t\t} else {\n\t\t\tres[i] = pse.top();\n\t\t}\n\t\tpse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nint sumSubarrayMins(vector&lt;int&gt;&amp; arr) {\n\tint n = arr.size();\n\tint mod = 1e9+7;\n\tlong long res = 0;\n\t\n\tvector&lt;int&gt; nse = nextSmallerElement(arr);\n\tvector&lt;int&gt; pse = prevSmallerElement(arr);\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tint left = i-pse[i];\n\t\tint right = nse[i]-i;\n\t\tres = (res + (right * left * (long long)1 * arr[i]) % mod) % mod; \n\t}\n\t\n\treturn res;\n}\nSum of subarray ranges\n \nRemove K digits to create smallest number\ngreedy - at each i iteratively check if it is smaller than stack‚Äôs top element, if it is, replace it.\nstring removeKdigits(string num, int k) {\n\tint n = num.length();\n\tstack&lt;char&gt; st;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!st.empty() &amp;&amp; k&gt;0 &amp;&amp; ((st.top()-&#039;0&#039;) &gt; (num[i]-&#039;0&#039;))) {\n\t\t\tst.pop();\n\t\t\tk--;\n\t\t}\n\t\tst.push(num[i]);\n\t}\n\t\n\twhile (k&gt;0) {\n\t\tst.pop();\n\t\tk--;\n\t}\n\t\n\tif (st.empty()) return &quot;0&quot;;\n\t\n\tstring res;\n\twhile (!st.empty()) {\n\t\tres += st.top();\n\t\tst.pop();\n\t}\n\t\n\twhile (res.size()!=0 &amp;&amp; res.back() == &#039;0&#039;) {\n\t\tres.pop_back();\n\t}\n\t\n\treverse(res.begin(), res.end());\n\t\n\tif (res.empty()) return &quot;0&quot;;\n\t\n\treturn res;\n}\nLargest Rectangle in Histogram\n\nto find the width for a height i we need the smallest previous and smallest next\nthen maximum area by that heighti is heights[i] * (nse[i]-pse[i]-1)\n\nvector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; nse;\n\t\n\tfor (int i=n-1; i&gt;=0; i--) {\n\t\twhile (!nse.empty() &amp;&amp; (nums[nse.top()] &gt;= nums[i])) {\n\t\t\tnse.pop();\n\t\t}\n\t\tif (nse.empty()) {\n\t\t\tres[i] = n;\n\t\t} else {\n\t\t\tres[i] = nse.top();\n\t\t}\n\t\tnse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; prevSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; pse;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!pse.empty() &amp;&amp; (nums[pse.top()] &gt;= nums[i])) {\n\t\t\tpse.pop();\n\t\t}\n\t\tif (pse.empty()) {\n\t\t\tres[i] = -1;\n\t\t} else {\n\t\t\tres[i] = pse.top();\n\t\t}\n\t\tpse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nint largestRectangleArea(vector&lt;int&gt;&amp; heights) {\n\tint res = 0;\n\tvector&lt;int&gt; pse = prevSmallerElement(heights);\n\tvector&lt;int&gt; nse = nextSmallerElement(heights);\n\t\n\tfor (int i=0; i&lt;heights.size(); i++) {\n\t\tres = max(res, (heights[i]*(nse[i] - pse[i]-1)));\n\t}\n\t\n\treturn res;\n}\nMaximal Rectangle\n\ntreat each row as a histogram and column as heights, now use the previous question\nto find heights use a prefix sum on each col with condition that if encountered 0 then reset sum\n\n vector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; nse;\n\t\n\tfor (int i=n-1; i&gt;=0; i--) {\n\t\twhile (!nse.empty() &amp;&amp; (nums[nse.top()] &gt;= nums[i])) {\n\t\t\tnse.pop();\n\t\t}\n\t\tif (nse.empty()) {\n\t\t\tres[i] = n;\n\t\t} else {\n\t\t\tres[i] = nse.top();\n\t\t}\n\t\tnse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; prevSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; pse;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!pse.empty() &amp;&amp; (nums[pse.top()] &gt;= nums[i])) {\n\t\t\tpse.pop();\n\t\t}\n\t\tif (pse.empty()) {\n\t\t\tres[i] = -1;\n\t\t} else {\n\t\t\tres[i] = pse.top();\n\t\t}\n\t\tpse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nint largestRectangleArea(vector&lt;int&gt;&amp; heights) {\n\tint res = 0;\n\tvector&lt;int&gt; pse = prevSmallerElement(heights);\n\tvector&lt;int&gt; nse = nextSmallerElement(heights);\n\t\n\tfor (int i=0; i&lt;heights.size(); i++) {\n\t\tres = max(res, (heights[i]*(nse[i] - pse[i]-1)));\n\t}\n\t\n\treturn res;\n}\n \nint maximalRectangle(vector&lt;vector&lt;char&gt;&gt;&amp; matrix) {\n\tint rows = matrix.size();\n\tint cols = matrix[0].size();\n\tvector&lt;vector&lt;int&gt;&gt; prefixSum(rows, vector&lt;int&gt;(cols, 0));\n\tint maxArea = 0;\n\t\n\tfor (int j=0; j&lt;cols; j++) {\n\t\tint curr_sum=0;\n\t\tfor (int i=0; i&lt;rows; i++) {\n\t\t\tcurr_sum += matrix[i][j]-&#039;0&#039;;\n\t\t\tif (matrix[i][j] == &#039;0&#039;) curr_sum = 0;\n\t\t\tprefixSum[i][j] = curr_sum; \n\t\t}\n\t}\n\t\n\tfor (int i=0; i&lt;rows; i++) {\n\t\tmaxArea = max(maxArea, largestRectangleArea(prefixSum[i]));\n\t}\n\t\n\treturn maxArea;\n}\nSliding Window maximum\nmaintain a dequeue that has elements in descending order.\nvector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) {\n\tif (k==1) return nums;\n\tint n = nums.size();\n\tvector&lt;int&gt; swmax;\n\tdeque&lt;int&gt; dq;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\t// this if ensures we maintain correct window \n\t\tif (!dq.empty() &amp;&amp; dq.front() &lt;= i - k) {\n\t\t\tdq.pop_front();\n\t\t}\n\t\t// maintain dq in decending order (front element is largest)\n\t\twhile (!dq.empty() &amp;&amp; nums[dq.back()] &lt;= nums[i]) {\n\t\t\tdq.pop_back();\n\t\t}\n\t\tdq.push_back(i);\n\t\n\t\tif (i &gt;= k-1) swmax.push_back(nums[dq.front()]); \n\t}\n\t\n\treturn swmax;\n}\nSliding Window and 2 Pointers\nLongest Substring Without Repeating Characters\n\nuse sliding window i.e. 2 pointers and an unordered map\n\nint lengthOfLongestSubstring(string s) {\n\tif (s.length() == 0) return 0; \n\tint start=0, end=0, res=0;\n\tunordered_map&lt;char, int&gt; mp;\n\t\n\tfor (int end = 0; end &lt; s.length(); end++) {\n        if (mp.find(s[end]) != mp.end() &amp;&amp; mp[s[end]] &gt;= start) {\n            start = mp[s[end]] + 1; // Move start to after the last occurrence\n        }\n        res = max(res, end - start + 1); // Update max length\n        mp[s[end]] = end; // Update last seen position\n    }\n\t\n\treturn res;\n}\nMax Consecutive Ones III\nint longestOnes(vector&lt;int&gt;&amp; nums, int k) {\n\tint n = nums.size();\n\tint start = 0, temp = k, res = 0;\n\t\n\tfor (int end=0; end&lt;n; end++) {\n\t\tif (nums[end] == 0) {\n\t\t\ttemp--;\n\t\t}\n\t\twhile (temp &lt; 0) {\n\t\t\tif (nums[start] == 0) {\n\t\t\t\ttemp++;\n\t\t\t}\n\t\t\tstart++;\n\t\t}\n\t\tres = max(res, end-start+1);\n\t}\n\t\n\treturn res;\n}\nLongest Repeating Character Replacement\nint characterReplacement(string s, int k) {\n\tint n = s.length();\n    unordered_map&lt;char, int&gt; mp;\n    int start = 0, res = 0, maxFreq = 0;\n    \n    for (int end = 0; end &lt; n; end++) {\n        mp[s[end]]++;\n        maxFreq = max(maxFreq, mp[s[end]]); // Track max frequency in window\n        \n        // If window size - max frequency &gt; k, shrink window\n        if (end - start + 1 - maxFreq &gt; k) {\n            mp[s[start]]--;\n            start++;\n        }\n        res = max(res, end - start + 1);\n    }\n    \n    return res;\n}\nBinary Subarrays With Sum\nThis questions seems similar to count subarrays with sum equal to k which is solved by using an unordered_map of prefix sums so that we can in O(1) search if we have encountered curr_sum - goal sum and if we have then we can directly add it‚Äôs count to ans\nint numSubarraysWithSum(vector&lt;int&gt;&amp; nums, int goal) {\n\tint n = nums.size();\n\tunordered_map&lt;int, int&gt; mp;\n\tmp[0] = 1; // Initialize for subarrays starting at index 0\n\tint res = 0, curr_sum = 0;\n\t\n\tfor (int i = 0; i&lt;n; i++) {\n\t\tcurr_sum += nums[i];\n\t\tif (mp.find(curr_sum-goal)!=mp.end()) {\n\t\t\tres += mp[curr_sum-goal];\n\t\t}\n\t\tmp[curr_sum]++;\n\t}\n\t\n\treturn res;\n}\nThis method takes O(N) time and O(N) space too, but we can also sum elements with Sliding Window using 2 pointers.\nbut here‚Äôs the catch, in Sliding Window we continuously move the end pointer and updates start upon reaching a condition,\nIn this question we would shrink the window (start++, curr_sum -= nums[start]) as soon as curr_sum == goal. This assumes only one subarray ending at end has sum goal, but multiple subarrays can end at end with the same sum due to different combinations of 1s and 2s.\nExample: nums = [1,1,2], goal = 4.\nSubarrays [1,1,2] (sum = 1+1+2 = 4) and [1,2] (sum = 1+2 = 3, but we will miss this because we shrink the window after finding [1,1,2]).\nThis approach counts only one subarray per window.\nSo what we can use the above prefix sum with hash map approach.\nAnd Sliding Window (At Most K) approach too\nNumber of Substrings Containing All Three Characters\nBrute force generate all substrings and count frequency\nBrute force optimized:\nWe know that if a substring has ((cnt_a &gt; 0) &amp;&amp; (cnt_b &gt; 0) &amp;&amp; (cnt_c &gt; 0)) then all substrings that contains that substring are valid so we directly add n-j to total count and break that iteration of j.\nint numberOfSubstrings(string s) {\n\tint n = s.length();\n\tint res = 0;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tint cnt_a=0, cnt_b=0, cnt_c=0;\n\t\tfor (int j=i; j&lt;n; j++) {\n\t\t\tif (s[j] == &#039;a&#039;) cnt_a++;\n\t\t\tif (s[j] == &#039;b&#039;) cnt_b++;\n\t\t\tif (s[j] == &#039;c&#039;) cnt_c++; \n\t\t\tif (cnt_a &amp;&amp; cnt_b &amp;&amp; cnt_c) {\n\t\t\t\tres += n-j;\n\t\t\t\tbreak;\t\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn res;\n}\nOptimal:\nwe keep track of last occurrence of a, b and c and when we encounter a character such that all of them becomes &gt; -1, we for sure know that each character has appeared more than once so the least last seen position is the minimal window and anything bigger than that on the left side will be valid.\ninstead of our usual approach of increasing the window from start by one we find minimal window the expand it to left.\nint numberOfSubstrings(string s) {\n\tint n = s.length();\n\tint res = 0;\n\tint pos_a=-1, pos_b=-1, pos_c=-1;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tif (s[i] == &#039;a&#039;) pos_a = i;\n\t\tif (s[i] == &#039;b&#039;) pos_b = i;\n\t\tif (s[i] == &#039;c&#039;) pos_c = i;\n\t\tif (pos_a &gt; -1 &amp;&amp; pos_b &gt; -1 &amp;&amp; pos_c &gt; -1) {\n\t\t\tint mini1 = min(pos_a, pos_b);\n\t\t\tint mini2 = min(mini1, pos_c);\n\t\t\tres += mini2+1;\n\t\t}\n\t}\n\t\n\treturn res;\n}\nMaximum Points You Can Obtain from Cards\nBrute Force: Recursion\nuse recursion where each branch is element taking either from front or back.\nint rec_sum (vector&lt;int&gt;&amp; cardPoints, int n, int sum, int l, int r, int k) {\n\tif (k==0) {\n\t\treturn sum;\n\t}\n\t\n\tint s1 = cardPoints[l]+rec_sum(cardPoints, n, sum, l+1, r,  k-1);\n\tint s2 = cardPoints[r]+rec_sum(cardPoints, n, sum, l, r-1, k-1);\n\treturn max(s1, s2);\n}\n \nint maxScore(vector&lt;int&gt;&amp; cardPoints, int k) {\n\tint n = cardPoints.size();\n\tif (k&gt;n) return accumulate(cardPoints.begin(), cardPoints.end(), 0);\n\treturn rec_sum(cardPoints, n, 0, 0, n-1,  k);\n}\nOptimal: Prefix Sum and Sliding Window\nSliding Window of size n-k, we will subtract the sum of sliding window from prefix sum leaving us with the sum of k elements distributed on both sides.\nint maxScore(vector&lt;int&gt;&amp; cardPoints, int k) {\n\tint n = cardPoints.size();\n\tint total_sum = accumulate(cardPoints.begin(), cardPoints.end(), 0);\n\tif (k&gt;n) return total_sum;\n\t\n\tvector&lt;int&gt; prefix_sum(n, 0);\n\tprefix_sum[0] = cardPoints[0];\n\tfor (int i=1; i&lt;n; i++) {\n\t\tprefix_sum[i] = cardPoints[i] + prefix_sum[i-1];\n\t}\n\t\n\tint l=-1, r=n-k;\n\tint res=0;\n\tfor (int i=n-k; i&lt;n; i++) {\n\t\tres += cardPoints[i];\n\t}\n\t\n\tl++;\n\tr++;\n\twhile (r&lt;=n) {\n\t\tres = max(res, total_sum - (prefix_sum[r-1] - prefix_sum[l]));\n\t\tl++;\n\t\tr++;\n\t}\n\t\n\treturn res;\n}\nSubarrays with K Different Integers\ninstead of finding subarrays with == k distinct integers find subarrays with ‚áêk and ‚áêk-1 distinct integers.\nint subarraysWithAtMostKDistinct(vector&lt;int&gt;&amp; nums, int k) {\n\tint n = nums.size();\n\tint l=0, r=0, res=0;\n\tunordered_map&lt;int, int&gt; mp;\n\t\n\twhile (r &lt; n) {\n\t\tmp[nums[r]]++;\n\t\t\n\t\t// shrink window till less than k\n\t\twhile (mp.size() &gt; k) {\n\t\t\tmp[nums[l]]--;\n\t\t\tif (mp[nums[l]] == 0) {\n\t\t\t\tmp.erase(nums[l]);\n\t\t\t}\n\t\t\tl++;\n\t\t}\n\t\t\n\t\t// total valid subarray with &lt;=k distinct elements are all elements\n\t\t// till r so length of a window == new valid subarrays\n\t\tres += r-l+1;\n\t}\n\t\n\treturn res;\n}\n \nint subarraysWithKDistinct(vector&lt;int&gt;&amp; nums, int k) {\n\treturn (subarraysWithAtMostKDistinct(nums, k) - subarraysWithAtMostKDistinct(nums, k-1));\n}\nHeap (Priority Queue)\nA binary tree where elements are arranged is called heap\ntwo types: min heap and max heap\nif a node in binary tree is represented by i then it‚Äôs children are 2*i + 1 and 2*i + 2.\nMax Heap in cpp using priority queue\npriority_queue&lt;int&gt; maxHeap;\n \n// Insert elements\nmaxHeap.push(3);\nmaxHeap.push(1);\nmaxHeap.push(4);\nmaxHeap.push(2);\n \n// Print and remove elements (largest first)\ncout &lt;&lt; &quot;Max Heap elements (in descending order): &quot;;\nwhile (!maxHeap.empty()) {\n\tcout &lt;&lt; maxHeap.top() &lt;&lt; &quot; &quot;;\n\tmaxHeap.pop();\n}\ncout &lt;&lt; endl;\nMin Heap in cpp using priority queue\npriority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minHeap;\n \n// Insert elements\nminHeap.push(3);\nminHeap.push(1);\nminHeap.push(4);\nminHeap.push(2);\n \n// Print and remove elements (smallest first)\ncout &lt;&lt; &quot;Min Heap elements (in ascending order): &quot;;\nwhile (!minHeap.empty()) {\n\tcout &lt;&lt; minHeap.top() &lt;&lt; &quot; &quot;;\n\tminHeap.pop();\n}\ncout &lt;&lt; endl;\nTask Scheduler\n\nwhile priority queue is not empty {\n\ngreedly allot n distinct elements if not possible then add idle\nreplace the alloted elements in priority_queue with a decrement in frequency\n\n\n}\n\nint leastInterval(vector&lt;char&gt;&amp; tasks, int n) {\n\tint time = 0;\n\t\n\tunordered_map&lt;char, int&gt; mp;\n    for (char c : tasks) {\n        mp[c]++;\n    }\n    \n    priority_queue&lt;pair&lt;int, char&gt;&gt; pq;\n    for (auto [c, f] : mp) {\n        pq.push({f, c});\n    }\n\t\n    while (!pq.empty()) {\n        vector&lt;pair&lt;int, char&gt;&gt; temp;\n        int cycle = n + 1; // Maximum tasks in one cycle\n        while (cycle &gt; 0 &amp;&amp; !pq.empty()) {\n            auto [f, c] = pq.top();\n            pq.pop();\n            if (f &gt; 1) {\n                temp.push_back({f - 1, c}); // Decrement frequency\n            }\n            time++; // One task scheduled\n            cycle--;\n        }\n        // Restore tasks for next cycle\n        for (auto p : temp) {\n            pq.push(p);\n        }\n        // Add idle time if queue is not empty\n        if (!pq.empty()) {\n            time += cycle;\n        }\n    }\n\t\n\treturn time;\n}\nOptimal:\n\nfind the number of elements required to fill the max number of elements\nthen fill it with other task and order don‚Äôt matter\n\nint leastInterval(vector&lt;char&gt;&amp; tasks, int n) {\n    vector&lt;int&gt; freq(26, 0); // Step 1: Frequency array for tasks A-Z\n\t\n    for (auto x : tasks) {\n        freq[x - &#039;A&#039;]++; // Step 2: Count frequency of each task\n    }\n\t\n    sort(freq.begin(), freq.end(), greater&lt;int&gt;()); // Step 3: Sort frequencies in descending order\n\t\n    int gap = (freq[0] - 1) * n; // Step 4: Calculate initial gaps (idle slots)\n\t\n    for (int i = 1; i &lt; freq.size(); i++) { // Step 5: Fill gaps with other tasks\n        gap = gap - min(freq[0] - 1, freq[i]);\n    }\n\t\n    return tasks.size() + max(0, gap); // Step 6: Return total time\n}\nHands of Straights\nbool isNStraightHand(vector&lt;int&gt;&amp; hand, int groupSize) {\n\tif (hand.size()%groupSize != 0) return false;\n\tmap&lt;int, int&gt; mp;\n\tfor (int i: hand) {\n\t\tmp[i]++;\n\t}\n\t\n\twhile (!mp.empty()) {\n\t\tint temp = mp.begin()-&gt;first;\n\t\tfor (int i = 0; i &lt; groupSize; i++) {\n\t\t\tif (mp[temp + i] == 0) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tmp[temp + i]--;\n\t\t\tif (mp[temp + i] &lt; 1) {\n\t\t\t\tmp.erase(temp + i);\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn true;\n}\nKth Largest Element in a Stream\nclass KthLargest {\n    int k;\n    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq;\npublic:\n    KthLargest(int k, vector&lt;int&gt;&amp; nums) {\n        this-&gt;k = k;\n        for (int num: nums) {\n            if (pq.size() &lt; k) {\n                pq.push(num);\n            } else {\n                if (num &gt; pq.top()) {\n                    pq.pop();\n                    pq.push(num);\n                }\n            }\n        }\n    }\n    \n    int add(int val) {\n        if (pq.size() &gt;= k) {\n\t\t\tif (val &gt; pq.top()) {\n\t\t\t\tpq.pop();\n\t\t\t\tpq.push(val);\n\t\t\t}\n\t\t} else {\n\t\t\tpq.push(val);\n\t\t}\n        return pq.top();\n    }\n};\nFind Median from Data Stream\nclass MedianFinder {\n    priority_queue&lt;int&gt; maxpq; // largest at top so, numbers &lt; median\n    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minpq;  // smallest at top so, numbers &gt; median\npublic:\n    MedianFinder() {}\n    \n    void addNum(int num) {\n        // Push to appropriate heap\n        if (maxpq.empty() || num &lt;= maxpq.top()) {\n            maxpq.push(num);\n        } else {\n            minpq.push(num);\n        }\n \n        // Balance heaps\n        if (maxpq.size() &gt; minpq.size()+1) {\n            minpq.push(maxpq.top());\n            maxpq.pop();\n        } else {\n            if (minpq.size() &gt; maxpq.size()) {\n                maxpq.push(minpq.top());\n                minpq.pop();\n            }\n        }\n    }\n    \n    double findMedian() {\n        // if equal size find mean of mids\n        if (maxpq.size() == minpq.size()) {\n            return ((maxpq.top() + minpq.top()) / 2.0); \n        } else {\n            return maxpq.top();\n        }\n    }\n};\nGreedy\nValid Parenthesis String\nbool checkValidString(string s) {\n\tint min_open = 0;   // &#039;*&#039; acts as &#039;)&#039;\n\tint max_open = 0;   // &#039;*&#039; acts as &#039;(&#039;\n\tfor (char c : s) {\n\t\tif (c == &#039;(&#039;) {\n\t\t\tmin_open++;\n\t\t\tmax_open++;\n\t\t} else if (c == &#039;)&#039;) {\n\t\t\tmin_open--;\n\t\t\tmax_open--;\n\t\t\tif (max_open &lt; 0) return false;\n\t\t\tif (min_open &lt; 0) min_open = 0;\n\t\t} else {\n\t\t\tmin_open--;\n\t\t\tmax_open++;\n\t\t\tif (min_open &lt; 0) min_open = 0;\n\t\t}\n\t}\n\treturn min_open == 0;\n}\nJump Game\nonly problem is when we encounter 0 as if all positive numbers we can definetly reach end by even one one jumps\nkeep track of max u can reach so that if any point you encounter a i that you can‚Äôt reach/cross-over in any way then return false\nbool canJump(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tint max_reach = 0;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tif (i &gt; max_reach) {\n\t\t\treturn false;\n\t\t}\n\t\tmax_reach = max(i+nums[i], max_reach);\n\t}\n\t\n\treturn true;\n}\nJump Game II\nfind minimum number of jumps\nwe keep track of range l -&gt; r where we can reach\nint jump(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tint cnt = 0, l = 0, r = 0;\n\t\n\twhile (r &lt; n-1) {\n\t\tint max_reach = 0;\n\t\tfor (int i=l; i&lt;=r; i++) {\n\t\t\tmax_reach = max(i+nums[i], max_reach);\n\t\t}\n\t\tl = r+1;\n\t\tr = max_reach;\n\t\tcnt++;\n\t}\n\t\n\treturn cnt;\n}\nCandy\nBrute Force:\n\nfind minimum number of candies that satisfies from left\nfind minimum number of candies that satisfies from right\nmaximum of both would satisfy both\n\nint candy(vector&lt;int&gt;&amp; ratings) {\n\tint n = ratings.size();\n\tint cnt = 0;\n\tvector&lt;int&gt; l(n, 0);\n\tvector&lt;int&gt; r(n, 0);\n\tl[0] = 1;\n\tr[n-1] = 1;\n\t\n\tfor (int i=1; i&lt;n; i++) {\n\t\tif (ratings[i] &gt; ratings[i-1]) {\n\t\t\tl[i] = l[i-1]+1;\n\t\t} else {\n\t\t\tl[i] = 1;\n\t\t}\n\t}\n\t\n\tfor (int i=n-2; i&gt;=0; i--) {\n\t\tif (ratings[i] &gt; ratings[i+1]) {\n\t\t\tr[i] = r[i+1]+1;\n\t\t} else {\n\t\t\tr[i] = 1;\n\t\t}\n\t}\n\t\n\tint sum = 0;\n\tfor (int i=0; i&lt;n; i++) {\n\t\tsum += max(l[i], r[i]);\n\t}\n\t\n\treturn sum;\n}\nOptimal: Peaks\nwe know peaks would have the largest number of candies so if we can find peaks then we can give every candies accordingly.\nmain observation ‚áí sum from top of peak == sum from bottom of peak, so after reaching peak we can start alloting from 1 to bottom then compare bottom candies and peak and take maximum of them.\nint candy(vector&lt;int&gt;&amp; ratings) {\n\tint n = ratings.size();\n\tint sum=1, i=1;\n\twhile (i&lt;n) {\n\t\tif (ratings[i] == ratings[i-1]) {\n\t\t\tsum++; \n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tint peak = 1;\n\t\twhile (i&lt;n &amp;&amp; ratings[i] &gt; ratings[i-1]) {\n\t\t\tpeak++;\n\t\t\tsum += peak;\n\t\t\ti++;\n\t\t}\n\t\tint down = 1;\n\t\twhile (i&lt;n &amp;&amp; ratings[i] &lt; ratings[i-1]) {\n\t\t\tsum += down;\n\t\t\tdown++;\n\t\t\ti++;\n\t\t}\n\t\t\n\t\tif (down &gt; peak) {\n\t\t\tsum += down-peak;\n\t\t}\n\t}  \n\treturn sum;\n}\nInsert Interval\ntry to optimize with binary search as they are sorted\nvector&lt;vector&lt;int&gt;&gt; insert(vector&lt;vector&lt;int&gt;&gt;&amp; intervals, vector&lt;int&gt;&amp; newInterval) {\n\tint n = intervals.size();\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\t\n\tint i = 0;\n\twhile (i &lt; n &amp;&amp; intervals[i][1] &lt; newInterval[0]) {\n\t\tres.push_back(intervals[i]);\n\t\ti++;\n\t}\n\t\n\twhile (i &lt; n &amp;&amp; intervals[i][0] &lt;= newInterval[1]) {\n\t\tnewInterval[0] = min(newInterval[0], intervals[i][0]);\n\t\tnewInterval[1] = max(newInterval[1], intervals[i][1]);\n\t\ti++;\n\t}\n\t\n\tres.push_back(newInterval);\n\twhile (i &lt; n) {\n\t\tres.push_back(intervals[i]);\n\t\ti++;\n\t}\n\t\n\treturn res;\n}\nNon-overlapping Intervals\n\nsort according to end time\nincrease counter if end time for a interval is smaller than it‚Äôs previous one\n\nint eraseOverlapIntervals(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) {\n\tint res = 0;\n\t\n\tsort(intervals.begin(), intervals.end(), [](const auto&amp; a, const auto&amp; b) {\n\t\treturn a[1] &lt; b[1];\n\t});\n\tint prev_end = intervals[0][1];\n\t\n\tfor (int i = 1; i &lt; intervals.size(); i++) {\n\t\tif (prev_end &gt; intervals[i][0]) {\n\t\t\tres++;\n\t\t} else {\n\t\t\tprev_end = intervals[i][1];\n\t\t}\n\t}\n\t\n\treturn res;\n}\nBinary Trees\nTypes:\n\nFull BT                ‚Üí either 2 or 0 children\nComplete BT      ‚Üí all levels except last have 0 or children, last level / leaf nodes should be as left as possible\nPerfect BT          ‚Üí all leaf nodes are at same level\nBalanced BT       ‚Üí height of tree must be less than equal to log(N)\nDegenerate BT   ‚Üí each node has a single child (basically a linked list)\n\nTraversal:\n\nDepth First Technique (DFS):\n\nInorder       (Left Root Right)\nPreorder    (Root Left Right)\nPostorder  (Left Right Root)\n\n\nBreadth First Technique (BFS):\nvisit all nodes at a level before moving to next\n\nTraversals\nRecursive DFS Traversal\n// Inorder\nvoid inorder(TreeNode* node, vector&lt;int&gt;&amp; res) {\n\tif (node == nullptr) return;\n\tinorder(node-&gt;left, res);\n\tres.push_back(node-&gt;val);\n\tinorder(node-&gt;right, res);\n}\nvector&lt;int&gt; inorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tinorder(root, res);\n\treturn res;\n}\n \n \n// Preorder\nvoid preorder(TreeNode* node, vector&lt;int&gt;&amp; res) {\n\tif (node == nullptr) return;\n\tres.push_back(node-&gt;val);\n\tpreorder(node-&gt;left, res);\n\tpreorder(node-&gt;right, res);\n}\nvector&lt;int&gt; preorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tpreorder(root, res);\n\treturn res;\n}\n \n \n// Postorder\nvoid postorder(TreeNode* node, vector&lt;int&gt;&amp; res) {\n\tif (node == nullptr) return;\n\tpostorder(node-&gt;left, res);\n\tpostorder(node-&gt;right, res);\n\tres.push_back(node-&gt;val);\n}\nvector&lt;int&gt; postorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tpostorder(root, res);\n\treturn res;\n}\nBFS Traversal\nvector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) {\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tif (root == nullptr) return res;\n\tqueue&lt;TreeNode*&gt; q;\n\tq.push(root);\n\t\n\twhile (!q.empty()) {\n\t\tvector&lt;int&gt; level;\n\t\tint size = q.size();\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tTreeNode* node = q.front();\n\t\t\tq.pop();\n\t\t\t\n\t\t\tif(node-&gt;left!=NULL){\n\t\t\t\tq.push(node-&gt;left);\n\t\t\t}\n\t\t\tif(node-&gt;right!=NULL){\n\t\t\t\tq.push(node-&gt;right);\n\t\t\t}\n\t\t\t\n\t\t\tlevel.push_back(node-&gt;val);\n\t\t}\n\t\t\n\t\tres.push_back(level);\n\t}\n\t\n\treturn res; \n}\nIterative DFS traversal\n// Preorder (Root Left Right)\n// as we are using stack i.e. LIFO we push right first then left\nvector&lt;int&gt; preorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tstack&lt;TreeNode*&gt; st;\n\tst.push(root);\n\twhile (!st.empty()) {\n\t\tTreeNode* node = st.top();\n\t\tst.pop();\n\t\tres.push_back(node-&gt;val);\n\t\t\n\t\tif (node-&gt;right != nullptr) {\n\t\t\tst.push(node-&gt;right);\n\t\t}\n\t\tif (node-&gt;left != nullptr) {\n\t\t\tst.push(node-&gt;left);\n\t\t}\n\t}\n\t\n\treturn res;\n}\n \n \n// Inorder (Left Root Right)\nvector&lt;int&gt; inorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tstack&lt;TreeNode*&gt; st;\n\tTreeNode* node = root;\n\twhile (true) {\n\t\tif (node != nullptr) {\n\t\t\tst.push(node);\n\t\t\tnode = node-&gt;left;\n\t\t} else {\n\t\t\tif (st.empty()) break;\n\t\t\tnode = st.top();\n\t\t\tst.pop();\n\t\t\tres.push_back(node-&gt;val);\n\t\t\tnode = node-&gt;right; \n\t\t}\n\t}\n\t\n\treturn res;\n}\nMaximum Depth of Binary tree\nint max_depth(TreeNode* node) {\n\tif (node == nullptr) return 0;\n\t\n\tint d1 = max_depth(node-&gt;left);\n\tint d2 = max_depth(node-&gt;right);\n\treturn max(d1, d2)+1;\n}\n \nint maxDepth(TreeNode* root) {\n\treturn max_depth(root);\n}\nCheck for Balanced Binary Tree\nint max_depth(TreeNode* node) {\n\tif (node == nullptr) return 0;\n\t\n\tint d1 = max_depth(node-&gt;left);\n\tif (d1 == -1) return -1; \n\tint d2 = max_depth(node-&gt;right);\n\tif (d2 == -1) return -1;\n\t\n\tif (abs(d1-d2) &gt; 1) return -1;\n\t\n\treturn max(d1, d2)+1;\n}\n \nbool isBalanced(TreeNode* root) {\n\tif (root == nullptr) return true; \n\treturn max_depth(root)!=-1;\n}\nDiameter of Binary Tree\nint fnc (TreeNode* node, int&amp; ans) {\n\tint lh = 0, rh = 0;\n\tif (node-&gt;left != nullptr) {\n\t\tlh = fnc(node-&gt;left, ans);\n\t}\n\tif (node-&gt;right != nullptr) {\n\t\trh = fnc(node-&gt;right, ans);\n\t}\n\tans = max(lh+rh+1, ans);\n\t\n\treturn max(lh+1, rh+1);\n}\n \nint diameterOfBinaryTree(TreeNode* root) {\n\tint ans = INT_MIN;\n\tint temp = fnc(root, ans);\n\treturn ans-1;\n}\nMaximum Path Sum\nint fnc (TreeNode* node, int&amp; ans) {\n\tint lh = 0, rh = 0;\n\tif (node-&gt;left != nullptr) {\n\t\tlh = max(lh, fnc(node-&gt;left, ans));\n\t}\n\tif (node-&gt;right != nullptr) {\n\t\trh = max(rh, fnc(node-&gt;right, ans));\n\t}\n\tans = max(lh+rh+node-&gt;val, ans); \n\t\n\treturn max(lh+node-&gt;val, rh+node-&gt;val);\n}\nint maxPathSum(TreeNode* root) {\n\tint ans = INT_MIN;\n\tint temp = fnc(root, ans);\n\treturn ans;\n}\nSame Tree\nbool isSameTree(TreeNode* p, TreeNode* q) {\n\tif (p == nullptr || q == nullptr) {\n\t\treturn p == q;\n\t}\n\treturn (p-&gt;val == q-&gt;val) &amp;&amp; isSameTree(p-&gt;left, q-&gt;left) &amp;&amp; isSameTree(p-&gt;right, q-&gt;right); \n}\nVertical Order Traversal of a Binary Tree\nvector&lt;vector&lt;int&gt;&gt; verticalTraversal(TreeNode* root) {\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tqueue&lt;pair&lt;TreeNode*, pair&lt;int, int&gt;&gt;&gt; q;\n\tmap&lt;int, map&lt;int, priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; &gt;&gt; mp;\n\tq.push({root, {0, 0}});\n\t\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tauto [node, cords] = q.front();\n\t\t\tint row = cords.first;\n\t\t\tint col = cords.second;\n\t\t\tq.pop();\n\t\t\tmp[col][row].push(node-&gt;val);\n\t\t\t\n\t\t\tif (node-&gt;left != nullptr) {\n\t\t\t\tq.push({node-&gt;left, {row+1, col-1}});\n\t\t\t}\n\t\t\tif (node-&gt;right != nullptr) {\n\t\t\t\tq.push({node-&gt;right, {row+1, col+1}});\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (auto&amp; [col, temp]: mp) {\n\t\tvector&lt;int&gt; vals;\n\t\tfor (auto&amp; [row, pq]: temp) {\n\t\t\twhile (!pq.empty()) {\n\t\t\t\tvals.push_back(pq.top());\n\t\t\t\tpq.pop();\n\t\t\t}\n\t\t}\n\t\tres.push_back(vals);\n\t}\n\t\n\treturn res;\n}\nBinary Tree Right Side View\nvector&lt;int&gt; rightSideView(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tqueue&lt;TreeNode*&gt; q;\n\tq.push(root);\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tTreeNode* node = q.front();\n\t\t\tq.pop();\n\t\t\tif (i == size-1) res.push_back(node-&gt;val);\n\t\t\tif (node-&gt;left) q.push(node-&gt;left);\n\t\t\tif (node-&gt;right) q.push(node-&gt;right);\n\t\t}\n\t}\n\t\n\treturn res;\n}\nSymmetric Tree\nbool isMirror(TreeNode* n1, TreeNode* n2) {\n\tif (n1 == nullptr &amp;&amp; n2 == nullptr) {\n\t\treturn true;\n\t}\n\tif (n1 == nullptr || n2 == nullptr) {\n\t\treturn false;\n\t}\n\treturn n1-&gt;val == n2-&gt;val &amp;&amp; isMirror(n1-&gt;left, n2-&gt;right) &amp;&amp; isMirror(n1-&gt;right, n2-&gt;left);\n}\n \nbool isSymmetric(TreeNode* root) {\n\treturn isMirror(root-&gt;left, root-&gt;right);\n}\nLowest Common Ancestor (LCA)\nbool root_to_node_path(TreeNode* node, int val, vector&lt;TreeNode*&gt;&amp; path) {\n\tif (node == nullptr) return false;\n\t\n\tpath.push_back(node);\n\tif (node-&gt;val == val) return true;\n\tif (root_to_node_path(node-&gt;left, val, path) || root_to_node_path(node-&gt;right, val, path)) {\n\t\treturn true;\n\t}\n\t\n\tpath.pop_back();\n\treturn false;\n}\n \nTreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {\n\tvector&lt;TreeNode*&gt; v1, v2;\n\tbool t1 = root_to_node_path(root, p-&gt;val, v1);\n\tbool t2 = root_to_node_path(root, q-&gt;val, v2);\n\t\n\tTreeNode* res = nullptr;\n\tint mini = min(v1.size(), v2.size());\n\tfor (int i=0; i&lt;mini; i++) {\n\t\tcout &lt;&lt; v1[i]-&gt;val &lt;&lt; &quot; &quot; &lt;&lt; v2[i]-&gt;val &lt;&lt; endl;\n\t\tif (v1[i] == v2[i]) {\n\t\t\tres = v1[i];\n\t\t}\n\t}\n\t\n\treturn res;\n}\nAll Nodes Distance K in Binary Tree\n\nmake a parent child map (creating parent pointers)\ndo a dfs till k from target\n\nvector&lt;int&gt; distanceK(TreeNode* root, TreeNode* target, int k) {\n\tvector&lt;int&gt; res;\n\tif (!root) return res;\n\t\n\tunordered_map&lt;TreeNode*, TreeNode*&gt; parent;\n\tqueue&lt;TreeNode*&gt; q;\n\tq.push(root);\n\t\n\twhile (!q.empty()) {\n\t\tTreeNode* node = q.front();\n\t\tq.pop();\n\t\tif (node-&gt;left) {\n\t\t\tparent[node-&gt;left] = node;\n\t\t\tq.push(node-&gt;left);\n\t\t}\n\t\tif (node-&gt;right) {\n\t\t\tparent[node-&gt;right] = node;\n\t\t\tq.push(node-&gt;right);\n\t\t}\n\t}\n\t\n\tunordered_set&lt;TreeNode*&gt; visited;\n\tq.push(target);\n\tvisited.insert(target);\n\tint dist = 0;\n\t\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\tif (dist == k) {\n\t\t\tfor (int i = 0; i &lt; size; i++) {\n\t\t\t\tTreeNode* node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tres.push_back(node-&gt;val);\n\t\t\t}\n\t\t\treturn res;\n\t\t}\n\t\tfor (int i = 0; i &lt; size; i++) {\n\t\t\tTreeNode* node = q.front();\n\t\t\tq.pop();\n\t\t\tif (node-&gt;left &amp;&amp; !visited.count(node-&gt;left)) {\n\t\t\t\tq.push(node-&gt;left);\n\t\t\t\tvisited.insert(node-&gt;left);\n\t\t\t}\n\t\t\tif (node-&gt;right &amp;&amp; !visited.count(node-&gt;right)) {\n\t\t\t\tq.push(node-&gt;right);\n\t\t\t\tvisited.insert(node-&gt;right);\n\t\t\t}\n\t\t\tif (parent.count(node) &amp;&amp; !visited.count(parent[node])) {\n\t\t\t\tq.push(parent[node]);\n\t\t\t\tvisited.insert(parent[node]);\n\t\t\t}\n\t\t}\n\t\tdist++;\n\t}\n\t\n\treturn res;\n}\nCount Complete Tree Nodes\nint countNodes(TreeNode* root) {\n\tif (root == nullptr) return 0;\n\t\n\tint lh = find_left_height(root);\n\tint rh = find_right_height(root);\n\t\n\tif (lh == rh) return (1&lt;&lt;lh) - 1;\n\treturn 1 + countNodes(root-&gt;left) + countNodes(root-&gt;right);\n}\n \nint find_left_height(TreeNode* node) {\n\tint height = 0;\n\twhile (node) {\n\t\theight++;\n\t\tnode = node-&gt;left;\n\t}\n\treturn height;\n}\n \nint find_right_height(TreeNode* node) {\n\tint height = 0;\n\twhile (node) {\n\t\theight++;\n\t\tnode = node-&gt;right;\n\t}\n\treturn height;\n}\nUnique Binary Tree\nif you are given Preorder and Postorder you can‚Äôt construct a unique Binary Tree\nFor Example:\nPreorder ‚Üí 123\nPostorder ‚Üí 321\nif we have Inorder and Preorder we can construct a unique Binary Tree out of it\nsimilarly if we have Inorder and Postorder we can construct a unique Binary Tree of it.\nConstruct Binary Tree from Preorder and Inorder Traversal\nTreeNode* buildsubTree(map&lt;int, int&gt; mp, vector&lt;int&gt;&amp; preorder, int preStart, int preEnd, vector&lt;int&gt;&amp; inorder, int inStart, int inEnd) {\n\tif (preStart &gt; preEnd || inStart &gt; inEnd) return nullptr;\n\t\n\tTreeNode* root = new TreeNode(preorder[preStart]);\n\tint inRoot = mp[preorder[preStart]];\n\tint leftCnt = inRoot - inStart;\n\t\n\troot-&gt;left = buildsubTree(mp, preorder, preStart+1, preStart+leftCnt, inorder, inStart, inRoot-1);\n\troot-&gt;right = buildsubTree(mp, preorder, preStart+leftCnt+1, preEnd, inorder, inRoot+1, inEnd);\n\t\t\n\treturn root;\n}\n \nTreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) {\n\tmap&lt;int, int&gt; mp;\n\tfor (int i=0; i&lt;inorder.size(); i++) {\n\t\tmp[inorder[i]] = i;\n\t}\n\t\n\treturn buildsubTree(mp, preorder, 0, preorder.size()-1, inorder, 0, inorder.size()-1);\n}\nSerialize and Deserialize Binary Tree\nclass Codec {\npublic:\n    // Encodes a tree to a single string.\n    string serialize(TreeNode* root) {\n        if (!root) return &quot;&quot;;\n        \n        string res;\n        queue&lt;TreeNode*&gt; q;\n        q.push(root);\n        while (!q.empty()) {\n            TreeNode* node = q.front();\n            q.pop();\n            if (node) {\n                res += to_string(node-&gt;val) + &quot;,&quot;;\n                q.push(node-&gt;left);\n                q.push(node-&gt;right);\n            } else {\n                res += &quot;#,&quot;;\n            }\n        }\n        return res;\n    }\n \n    vector&lt;string&gt; parseString(const string&amp; s) {\n        vector&lt;string&gt; result;\n        stringstream ss(s);\n        string token;\n        while (getline(ss, token, &#039;,&#039;)) {\n            result.push_back(token);\n        }\n        return result;\n    }\n\t\n    // Decodes your encoded data to tree.\n    TreeNode* deserialize(string data) {\n        if (data.empty()) return nullptr;\n\t\t\n        vector&lt;string&gt; parsed = parseString(data);\n        if (parsed.empty()) return nullptr;\n\t\t\n        queue&lt;TreeNode*&gt; q;\n        TreeNode* root = new TreeNode(stoi(parsed[0]));\n        q.push(root);\n        int i = 1;\n\t\t\n        while (!q.empty() &amp;&amp; i &lt; parsed.size()) {\n            TreeNode* node = q.front();\n            q.pop();\n\t\t\t\n            // Left child\n            if (i &lt; parsed.size() &amp;&amp; parsed[i] != &quot;#&quot;) {\n                node-&gt;left = new TreeNode(stoi(parsed[i]));\n                q.push(node-&gt;left);\n            }\n            i++;\n\t\t\t\n            // Right child\n            if (i &lt; parsed.size() &amp;&amp; parsed[i] != &quot;#&quot;) {\n                node-&gt;right = new TreeNode(stoi(parsed[i]));\n                q.push(node-&gt;right);\n            }\n            i++;\n        }\n\t\t\n        return root;\n    }\n};\nMorris Traversal\nMorris Traversal ‚áí Threaded Binary Tree\n// Inorder (Left Root Right)\nvector&lt;int&gt; inorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tTreeNode* curr = root;\n\twhile (curr!=nullptr) {\n\t\t// if curr is root without left node\n\t\tif (curr-&gt;left == nullptr) {\n\t\t\tres.push_back(curr-&gt;val);\n\t\t\tcurr = curr-&gt;right;\n\t\t} else {\n\t\t\t// when curr have left node\n\t\t\tTreeNode* prev = curr-&gt;left;\n\t\t\twhile (prev-&gt;right &amp;&amp; prev-&gt;right != curr) {\n\t\t\t\tprev = prev-&gt;right;\n\t\t\t}\n\t\t\t// if thread already not exist\n\t\t\tif (prev-&gt;right == nullptr) {\n\t\t\t\t// create thread from rightmost of the left subtree to root \n\t\t\t\tprev-&gt;right = curr;\n\t\t\t\t// as inorder after root move left\n\t\t\t\tcurr = curr-&gt;left;\n\t\t\t} else {\n\t\t\t\t// when thread already exist and we return back to curr \n\t\t\t\t// i.e. prev-&gt;right == curr\n\t\t\t\t\n\t\t\t\t// cut the thread\n\t\t\t\tprev-&gt;right = nullptr;\n\t\t\t\tres.push_back(curr-&gt;val);\n\t\t\t\t// as inorder and left is done move right\n\t\t\t\tcurr = curr-&gt;right;\n\t\t\t}\n\t\t\t\n\t\t}\n\t}\n\t\n\treturn res;\n}\n \n \n// Preorder (Root Left Right)\nvector&lt;int&gt; preorderTraversal(TreeNode* root) {\n\tvector&lt;int&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tTreeNode* curr = root;\n\twhile (curr!=nullptr) {\n\t\t// if curr is root without left node\n\t\tif (curr-&gt;left == nullptr) {\n\t\t\tres.push_back(curr-&gt;val);\n\t\t\tcurr = curr-&gt;right;\n\t\t} else {\n\t\t\t// when curr have left node\n\t\t\tTreeNode* prev = curr-&gt;left;\n\t\t\twhile (prev-&gt;right &amp;&amp; prev-&gt;right != curr) {\n\t\t\t\tprev = prev-&gt;right;\n\t\t\t}\n\t\t\t// if thread already not exist\n\t\t\tif (prev-&gt;right == nullptr) {\n\t\t\t\t// create thread from rightmost of the left subtree to root \n\t\t\t\tprev-&gt;right = curr;\n\t\t\t\tres.push_back(curr-&gt;val);\n\t\t\t\t// as preorder after root move left\n\t\t\t\tcurr = curr-&gt;left;\n\t\t\t} else {\n\t\t\t\t// when thread already exist and we return back to curr \n\t\t\t\t// i.e. prev-&gt;right == curr\n\t\t\t\t\n\t\t\t\t// cut the thread\n\t\t\t\tprev-&gt;right = nullptr;\n\t\t\t\t// as preorder and left is done move right\n\t\t\t\tcurr = curr-&gt;right;\n\t\t\t}\n\t\t\t\n\t\t}\n\t}\n\t\n\treturn res;\n}\nFlatten Binary Tree to Linked List\nreverse preorder traversal\nclass Solution {\n    TreeNode* prev = nullptr;\npublic:\n    // reverse pre order traversal (Right Left Root)\n    void flatten(TreeNode* node) {\n        if (node == nullptr) return;\n        flatten(node-&gt;right);\n        flatten(node-&gt;left);\n\t\n        node-&gt;right = prev;\n        node-&gt;left = nullptr;\n        prev = node;\n    }\n};\nBinary Search Tree (BST)\n\nNote: Inorder of a BST is always in sorted order\n\nInsert a node in BST (Iterative)\nTreeNode* insertIntoBST(TreeNode* root, int val) {\n\tif (root == nullptr) return new TreeNode(val);\n\t\n\tTreeNode* curr = root;\n\twhile (true) {\n\t\tif (curr-&gt;val &lt; val) {\n\t\t\tif (curr-&gt;right) curr = curr-&gt;right;\n\t\t\telse {\n\t\t\t\tcurr-&gt;right = new TreeNode(val);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (curr-&gt;left) curr = curr-&gt;left;\n\t\t\telse {\n\t\t\t\tcurr-&gt;left = new TreeNode(val);\n\t\t\t\tbreak;\n\t\t\t} \n\t\t}\n\t}\n\t\n\treturn root;\n}\nInsert a node in BST (Recursive)\n\nin base case we return the new node and the assign it to root-&gt;left or root-&gt;right which ever encountered base case first\n\nTreeNode* insertIntoBST(TreeNode* root, int val) {\n\tif(root == nullptr){\n\t\treturn new TreeNode(val);\n\t}\n\tif(root-&gt;val &gt; val){\n\t\troot-&gt;left = insertIntoBST(root-&gt;left, val);\n\t}\n\telse{\n\t\troot-&gt;right = insertIntoBST(root-&gt;right, val);\n\t}\n\treturn root;\n}\nDelete Node in a BST\n\nstart normal iteration according to the value of key\nif key is found then we can replace it with smallest value in the Right Subtree\n\nwhy ?\nbecause smallest value in the right subtree is greater than all values in left and smaller than all values in right\ntherefore maintaining BST property\n\n\nafter replacing the value we call function with root as right subtree and key as the smallest value in the right subtree\nso when we reach that smallest value we basically reach a leaf node\n\ntherefore we trigger if (!root-&gt;left) return root-&gt;right; or if (!root-&gt;right) return root-&gt;left; part of code which return nullptr\ntherefore completely removing the key\n\n\n\nTreeNode* deleteNode(TreeNode* root, int key) {\n\tif (!root) return nullptr;\n\t\n\tif (root-&gt;val &lt; key) {\n\t\troot-&gt;right = deleteNode(root-&gt;right, key);\n\t} else if (root-&gt;val &gt; key) {\n\t\troot-&gt;left = deleteNode(root-&gt;left, key);\n\t} else {\n\t\tif (!root-&gt;left) return root-&gt;right;\n\t\tif (!root-&gt;right) return root-&gt;left;\n\t\t\n\t\tTreeNode* ln = root-&gt;right;\n\t\twhile (ln-&gt;left) {\n\t\t\tln = ln-&gt;left;\n\t\t}\n\t\troot-&gt;val = ln-&gt;val;\n\t\troot-&gt;right = deleteNode(root-&gt;right, ln-&gt;val);\n\t}\n\t\n\treturn root;\n}\nKth Smallest Element in BST\ninorder traversal gives sorted order of all values\nvoid inorder(TreeNode* node, int&amp; k, int&amp; ans) {\n\tif (node == nullptr) return;\n\tinorder(node-&gt;left, k, ans);\n\tk--;\n\tif (k==0) {\n\t\tans = node-&gt;val;\n\t\treturn;\n\t}\n\tinorder(node-&gt;right, k, ans);\n}\n \nint kthSmallest(TreeNode* root, int k) {\n\tint ans = 0;\n\tinorder(root, k, ans);\n\treturn ans;\n}\nValidate Binary Search Tree\nbool isValidNode(TreeNode* node, long mini, long maxi) {\n\tif (node == nullptr) return true;\n\tif (node-&gt;val &gt;= maxi || node-&gt;val &lt;=mini) return false;\n\t\n\treturn isValidNode(node-&gt;left, mini, node-&gt;val) &amp;&amp; isValidNode(node-&gt;right, node-&gt;val, maxi);\n}\n \nbool isValidBST(TreeNode* root) {\n\treturn isValidNode(root, LONG_MIN, LONG_MAX);\n}\nLowest Common Ancestor of a Binary Search Tree\nbool root_to_node_path(TreeNode* node, TreeNode* search, vector&lt;TreeNode*&gt;&amp; path) {\n\tif (node == nullptr) return false;\n\t\n\tpath.push_back(node);\n\tif (node-&gt;val == search-&gt;val) return true;\n\tif (node-&gt;val &gt; search-&gt;val) return root_to_node_path(node-&gt;left, search, path);\n\telse return root_to_node_path(node-&gt;right, search, path);\n\t\n\tpath.pop_back();\n\treturn false;\n}\n \nTreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {\n\tvector&lt;TreeNode*&gt; v1, v2;\n\tbool t1 = root_to_node_path(root, p, v1);\n\tbool t2 = root_to_node_path(root, q, v2);\n\t\n\tTreeNode* res = nullptr;\n\tint mini = min(v1.size(), v2.size());\n\tfor (int i=0; i&lt;mini; i++) {\n\t\tcout &lt;&lt; v1[i]-&gt;val &lt;&lt; &quot; &quot; &lt;&lt; v2[i]-&gt;val &lt;&lt; endl;\n\t\tif (v1[i] == v2[i]) {\n\t\t\tres = v1[i];\n\t\t}\n\t}\n\t\n\treturn res;\n}\nConstruct Binary Search Tree from Preorder Traversal\nTreeNode* fnc (vector&lt;int&gt;&amp; preorder, int start, int end) {\n\tif (start&gt;end || end&gt;=preorder.size()) return nullptr;\n\t\n\tTreeNode* node = new TreeNode(preorder[start]);\n\tint j=start+1;\n\twhile (j&lt;preorder.size() &amp;&amp; preorder[j] &lt; preorder[start]) {\n\t\tj++;\n\t}\n\tnode-&gt;left = fnc (preorder, start+1, j-1);\n\tnode-&gt;right = fnc (preorder, j, end); \n\t\n\treturn node;\n}\n \nTreeNode* bstFromPreorder(vector&lt;int&gt;&amp; preorder) {\n\tif (preorder.size() == 0) return nullptr;\n\t\n\tTreeNode* root = fnc(preorder, 0, preorder.size()-1);\n\treturn root;\n}\nBST Inorder Iterator using stack\nclass BSTIterator {\n    stack&lt;TreeNode*&gt; st;\npublic:\n    BSTIterator(TreeNode* root) {\n        while (root) {\n            st.push(root);\n            root = root-&gt;left;\n        }\n    }\n    \n    int next() {\n        TreeNode* node = st.top();\n        st.pop();\n        TreeNode* curr = node;\n        if (curr-&gt;right) {\n            curr = curr-&gt;right;\n            while (curr) {\n                st.push(curr);\n                curr = curr-&gt;left;\n            }\n        }\n\t\t\n        return node-&gt;val;\n    }\n    \n    bool hasNext() {\n        return !st.empty();\n    }\n};\nRecover Binary Search Tree\nonly 2 nodes are swapped\nclass Solution {\n    TreeNode* first;\n    TreeNode* middle;\n    TreeNode* last;\n    TreeNode* prev;\npublic:\n    void inorder(TreeNode* root) {\n        if (root == nullptr) return;\n\t\t\t\n        inorder(root-&gt;left);\n        if (prev != nullptr &amp;&amp; (root-&gt;val &lt; prev-&gt;val)) {\n            if (first == nullptr) {\n                first = prev;\n                middle = root;\n            } else {\n                last = root;\n            }\n        }\n        prev = root;\n        inorder(root-&gt;right);\n    }\n\t\n    void recoverTree(TreeNode* root) {\n        first = middle = last = nullptr;\n        prev = new TreeNode(INT_MIN);\n        inorder(root);\n        \n        if (first &amp;&amp; last) swap(first-&gt;val, last-&gt;val);\n        else if (first &amp;&amp; middle) swap(first-&gt;val, middle-&gt;val);\n    }\n};\nGraphs\nGraphs(V, E) ‚áí   V ‚Üí vertices and E ‚Üí edges\nA Graph can be Directed or Undirected and cyclic or acyclic\n\nPath: contains a lot of vertices and each of them are reachable, a vertex cannot appear twice in a path.\nDegree of a vertex: number of edges that go inside or outside of a vertex.\n\nIndegree of vertex: number of edges that go inside of a vertex.\nOutdegree of vertex: number of edges that go outside of a vertex.\n\n\nConnected Components: if there exist a path between any two vertices of that graph\n\nProperties:\n\nTotal degree of a graph = 2 * Number of edges.\n\nRepresentation:\n\n\nAdjacency Matrix (Space ‚Üí O(N^2))\nint n, m;\ncin &gt;&gt; n &gt;&gt; m;\nint adj[n+1][m+1];\nfor (int i=0; i&lt;m; i++) {\n\tint u, v;\n\tcin &gt;&gt; u &gt;&gt; v;\n\tadj[u][v] = 1;\n\tadj[v][u] = 1;\n}\nFor weighted graphs instead of 1 store the weight\n\n\nAdjacency List (Space ‚Üí O(2 * E))\nint n, m;\ncin &gt;&gt; n &gt;&gt; m;\nvector&lt;int&gt; adj[n+1];\nfor (int i=0; i&lt;m; i++) {\n\tint u, v;\n\tcin &gt;&gt; u &gt;&gt; v;\n\tadj[u].push_back(v);\n\tadj[v].push_back(u);\n}\nFor weighted graphs store a pair for all n vertices vector&lt;pair&lt;int, int&gt;&gt; adj[n+1]\n\n\nTraversals\nFor all traversals we need to now about number of connected components\nso we keep a visited array\nThis way we can keep track that vertices are visited therefore visiting all connected commponents\nvector&lt;bool&gt; visited(n+1, false);\nfor (int i=1; i&lt;n+1; i++) {\n\tif (!visited[i]) {\n\t\ttraversal(i, visited);\n\t}\n}\nBreadth First Search(BFS) - Iterative\nvector&lt;int&gt; bfsOfGraph(int v, int start, vector&lt;int&gt; adj[]) {\n\tvector&lt;int&gt; bfs;\n\t\n\tvector&lt;bool&gt; visited(v, false);\n\tvisited[start] = true;\n\t\n\tqueue&lt;int&gt; q;\n\tq.push(start);\n\twhile (!q.empty()) {\n\t\tint vertex = q.front();\n\t\tq.pop();\n\t\tbfs.push_back(vertex);\n\t\t\n\t\tfor (int it: adj[vertex]){\n\t\t\tif (!visited[it]) {\n\t\t\t\tvisited[it] = true;\n\t\t\t\tq.push(it);\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn bfs;\n}\nDepth First Search(DFS) - Iterative\nvector&lt;int&gt; dfsOfGraph(int v, int start, vector&lt;int&gt; adj[]) {\n\tvector&lt;int&gt; dfs;\n\t\n\tvector&lt;bool&gt; visited(v, false);\n\tvisited[start] = true;\n\t\n\tstack&lt;int&gt; st;\n\tst.push(start);\n\twhile (!st.empty()) {\n\t\tint vertex = st.top();\n\t\tst.pop();\n\t\tdfs.push_back(vertex);\n\t\t\n\t\t// traverse in reverse order to match the recursive solution \n\t\tfor (auto it = adj[vertex].rbegin(); it != adj[vertex].rend(); ++it) {\n\t\t\tif (!visited[*it]) {\n\t\t\t\tvisited[*it] = true;\n\t\t\t\tst.push(*it);\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn dfs;\n}\nDepth First Search(DFS) - Recursive\nvoid dfsRecursive(int vertex, vector&lt;int&gt; adj[], vector&lt;bool&gt;&amp; visited, vector&lt;int&gt;&amp; dfs) {\n    visited[vertex] = true;\n    dfs.push_back(vertex);\n    for (int neighbor : adj[vertex]) {\n        if (!visited[neighbor]) {\n            dfsRecursive(neighbor, adj, visited, dfs);\n        }\n    }\n}\n \nvector&lt;int&gt; dfsOfGraph(int v, int start, vector&lt;int&gt; adj[]) {\n    vector&lt;int&gt; dfs;\n    vector&lt;bool&gt; visited(v, false);\n    \n    dfsRecursive(start, adj, visited, dfs);\n    return dfs;\n}\nNumber of Provinces\n\nequivalent to find number of connected components\n\nint findCircleNum(vector&lt;vector&lt;int&gt;&gt;&amp; isConnected) {\n\tint n = isConnected.size();\n\tvector&lt;bool&gt; visited(n, false);\n\t\n\tint provinces = 0;\n\tqueue&lt;int&gt; q;\n\tfor (int i=0; i&lt;n; i++) {\n\t\tif (!visited[i]) {\n\t\t\tq.push(i);\n\t\t\tvisited[i] = true;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint vertex = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int i=0; i&lt;isConnected[vertex].size(); i++){\n\t\t\t\t\tif (isConnected[vertex][i] == 1 &amp;&amp; !visited[i]) {\n\t\t\t\t\t\tvisited[i] = true;\n\t\t\t\t\t\tq.push(i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tprovinces++;\n\t\t} \n\t}\n\t\n\treturn provinces;\n}\nRotten Oranges\n\nstart bfs from all rotten locations at same time\n\nint orangesRotting(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint m = grid.size();\n\tint n = grid[0].size();\n\tvector&lt;vector&lt;bool&gt;&gt; visited(m, vector&lt;bool&gt;(n, false));\n\t\n\tqueue&lt;pair&lt;int, int&gt;&gt; q;\n\tint fresh = 0;\n\tfor (int row = 0; row &lt; m; row++) {\n\t\tfor (int col = 0; col &lt; n; col++) {\n\t\t\tif (grid[row][col] == 2) {\n\t\t\t\tq.push({row, col});\n\t\t\t\tvisited[row][col] = true;\n\t\t\t} else if (grid[row][col] == 1) {\n\t\t\t\tfresh++;\n\t\t\t}\n\t\t}\n\t}\n\tif (fresh == 0) return 0;\n\t\n\tint time = 0;\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\tbool rotted = false;\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tauto [row, col] = q.front();\n\t\t\tq.pop();\n\t\t\tif (0 &lt;= row+1 &amp;&amp; row+1 &lt; m &amp;&amp; !visited[row+1][col] &amp;&amp; grid[row+1][col] == 1) {\n\t\t\t\tvisited[row+1][col] = true;\n\t\t\t\tq.push({row+1, col});\n\t\t\t\tfresh--;\n\t\t\t\trotted = true;\n\t\t\t}\n\t\t\tif (0 &lt;= row-1 &amp;&amp; row-1 &lt; m &amp;&amp; !visited[row-1][col] &amp;&amp; grid[row-1][col] == 1) {\n\t\t\t\tvisited[row-1][col] = true;\n\t\t\t\tq.push({row-1, col});\n\t\t\t\tfresh--;\n\t\t\t\trotted = true;\n\t\t\t}\n\t\t\tif (0 &lt;= col+1 &amp;&amp; col+1 &lt; n &amp;&amp; !visited[row][col+1] &amp;&amp; grid[row][col+1] == 1) {\n\t\t\t\tvisited[row][col+1] = true;\n\t\t\t\tq.push({row, col+1});\n\t\t\t\tfresh--;\n\t\t\t\trotted = true;\n\t\t\t}\n\t\t\tif (0 &lt;= col-1 &amp;&amp; col-1 &lt; n &amp;&amp; !visited[row][col-1] &amp;&amp; grid[row][col-1] == 1) {\n\t\t\t\tvisited[row][col-1] = true;\n\t\t\t\tq.push({row, col-1});\n\t\t\t\tfresh--;\n\t\t\t\trotted = true;\n\t\t\t} \n\t\t}\n\t\t\n\t\tif(rotted) time++;\n\t}\n\t\n\treturn fresh == 0 ? time : -1;\n}\nCycle Detection in undirected Graph (DFS)\nWithout tracking the parent, visiting a neighbor that is the parent node could be mistaken for a cycle.\nbool hasCycle(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n    int n = graph.size();\n    unordered_set&lt;int&gt; visited;\n    stack&lt;pair&lt;int, int&gt;&gt; stk; // Pair of (node, parent)\n\t\n    for (int start = 0; start &lt; n; ++start) { // Handle disconnected components\n        if (visited.find(start) != visited.end()) continue;\n        \n        stk.push({start, -1}); // Start node has no parent\n        visited.insert(start);\n\t\t\n        while (!stk.empty()) {\n            auto [node, parent] = stk.top();\n            stk.pop();\n\t\t\t\n            for (int neighbor : graph[node]) {\n                if (neighbor == parent) continue; // Skip the parent node\n                if (visited.find(neighbor) != visited.end()) {\n                    return true; // Cycle detected (non-parent visited node)\n                }\n                visited.insert(neighbor);\n                stk.push({neighbor, node});\n            }\n        }\n    }\n    return false; // No cycle found\n}\nDistance of Nearest Cell having 0\nvector&lt;vector&lt;int&gt;&gt; updateMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; mat) {\n\tint m = mat.size(), n = mat[0].size();\n\tvector&lt;vector&lt;int&gt;&gt; dist(m, vector&lt;int&gt;(n, -1));\n\tqueue&lt;pair&lt;int, int&gt;&gt; q;\n\t\n\tfor (int i = 0; i &lt; m; ++i) {\n\t\tfor (int j = 0; j &lt; n; ++j) {\n\t\t\tif (mat[i][j] == 0) {\n\t\t\t\tq.push({i, j});\n\t\t\t\tdist[i][j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tvector&lt;pair&lt;int, int&gt;&gt; dirs = {{0, 1}, {0, -1}, {1, 0}, {-1, 0}};\n\t\n\twhile (!q.empty()) {\n\t\tauto [row, col] = q.front();\n\t\tq.pop();\n\t\t\n\t\tfor (auto [dr, dc] : dirs) {\n\t\t\tint newRow = row + dr, newCol = col + dc;\n\t\t\tif (newRow &gt;= 0 &amp;&amp; newRow &lt; m &amp;&amp; newCol &gt;= 0 &amp;&amp; newCol &lt; n &amp;&amp; dist[newRow][newCol] == -1) {\n\t\t\t\tdist[newRow][newCol] = dist[row][col] + 1;\n\t\t\t\tq.push({newRow, newCol});\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn dist;\n}\nSurrounded Regions\nvoid bfs(vector&lt;vector&lt;char&gt;&gt;&amp; board, int sr, int sc, int m, int n) {\n\tqueue&lt;pair&lt;int, int&gt;&gt; q;\n\tvector&lt;pair&lt;int, int&gt;&gt; directions = {{0, 1}, {0, -1}, {1, 0}, {-1, 0}};\n\t\n\tboard[sr][sc] = &#039;m&#039;;\n\tq.push({sr,sc});\n\t\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tauto [row, col] = q.front();\n\t\t\tq.pop();\n\t\t\t\n\t\t\tfor (int i=0; i&lt;4; i++) {\n\t\t\t\tint newRow = row + directions[i].first;\n\t\t\t\tint newCol = col + directions[i].second;\n\t\t\t\t\n\t\t\t\tif (newRow &gt;= 0 &amp;&amp; newRow &lt; m &amp;&amp;\n\t\t\t\t\tnewCol &gt;= 0 &amp;&amp; newCol &lt; n &amp;&amp;\n\t\t\t\t\tboard[newRow][newCol] == &#039;O&#039;) {\n\t\t\t\t\t\tboard[newRow][newCol] = &#039;m&#039;;\n\t\t\t\t\t\tq.push({newRow, newCol});\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\t}\n}\n \nvoid solve(vector&lt;vector&lt;char&gt;&gt;&amp; board) {\n\tint m = board.size();\n\tint n = board[0].size();\n\t\n\tfor (int j = 0; j &lt; n; j++) {\n\t\tif (board[0][j] == &#039;O&#039;) bfs(board, 0, j, m, n); \n\t\tif (board[m-1][j] == &#039;O&#039;) bfs(board, m-1, j, m, n);\n\t}\n\t\n\tfor (int i = 0; i &lt; m; i++) {\n\t\tif (board[i][0] == &#039;O&#039;) bfs(board, i, 0, m, n);\n\t\tif (board[i][n-1] == &#039;O&#039;) bfs(board, i, n-1, m, n);\n\t}\n\t\n\tfor (int i=0; i&lt;m; i++) {\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (board[i][j] == &#039;O&#039;) {\n\t\t\t\tboard[i][j] = &#039;X&#039;;\n\t\t\t} else if (board[i][j] == &#039;m&#039;) {\n\t\t\t\tboard[i][j] = &#039;O&#039;;\n\t\t\t}\n\t\t}\n\t}\n}\nWord Ladder\n\nwe replace each character of startWord and form new words that exist in wordList\nwe make(don‚Äôt store it just generate next possible words in bfs traversal) a tree from startWord to endWord and keep track of levels\n\nint ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) {\n\tunordered_set&lt;string&gt; s;\n\tfor (string i: wordList) {\n\t\ts.insert(i);\n\t}\n\t\n\tint cnt = 1;\n\tqueue&lt;pair&lt;string, int&gt;&gt; q;   // pair of word, level\n\tq.push({beginWord, 1});\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tauto [str, lvl] = q.front();\n\t\t\tq.pop();\n\t\t\t\n\t\t\tif (str == endWord) {\n\t\t\t\treturn lvl;\n\t\t\t}\n\t\t\t\n\t\t\tfor (int i=0; i&lt;str.length(); i++) {\n\t\t\t\tchar ch = str[i];\n\t\t\t\tfor (char c=&#039;a&#039;; c&lt;=&#039;z&#039;; c++) {\n\t\t\t\t\tstr[i] = c;\n\t\t\t\t\tif (s.find(str) != s.end()) {\n\t\t\t\t\t\ts.erase(str);\n\t\t\t\t\t\tq.push({str, lvl+1});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tstr[i] = ch;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn 0;\n}\nIs Graph Bipartite? (using coloring)\nif a graph has odd length of loop then it can‚Äôt be bipartite\nbool isBipartite(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n\tint n = graph.size();\n\tvector&lt;int&gt; color(n, -1);\n\t\n\tfor (int start = 0; start &lt; n; ++start) {    // for disconnected components\n\t\tif (color[start] != -1) continue;\n\t\t\n\t\tcolor[start] = 0;\n\t\tstack&lt;pair&lt;int, int&gt;&gt; st;\n\t\tst.push({start, 0});\n\t\twhile (!st.empty()) {\n\t\t\tauto [node, co] = st.top();\n\t\t\tst.pop();\n\t\t\t\n\t\t\tfor (int i=0; i&lt;graph[node].size(); i++) {\n\t\t\t\tif (color[graph[node][i]] == -1) {\n\t\t\t\t\tif (co == 1) color[graph[node][i]] = 0;\n\t\t\t\t\telse if (co == 0) color[graph[node][i]] = 1;\n\t\t\t\t\tst.push({graph[node][i], color[graph[node][i]]});\n\t\t\t\t} else if (color[graph[node][i]] == co) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn true;\n}\nIs Cyclic DAG ?\n\nthree colors ‚áí 0 = unvisited, 1 = visiting, 2 = visited\nit‚Äôs cyclic if we visit a node of same path which is represented by 1 i.e. currently visiting\n\nbool is_cyclic_dag(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n    int n = graph.size();\n    vector&lt;int&gt; visited(n, 0); // 0 = unvisited, 1 = visiting, 2 = visited\n\t\n    for (int i = 0; i &lt; n; i++) {\n        if (visited[i] != 0) continue;\n        \n        stack&lt;pair&lt;int, bool&gt;&gt; st; // {node, isExiting}\n        st.push({i, false}); // entering node\n        \n        while (!st.empty()) {\n            auto [node, isExiting] = st.top();\n            st.pop();\n            \n            if (isExiting) {\n                visited[node] = 2; // fully processed\n                continue;\n            }\n            \n            if (visited[node] == 1) {\n                // Back edge found ‚Äî cycle detected\n                return true;\n            }\n            \n            if (visited[node] == 0) {\n                visited[node] = 1; // mark as visiting\n                st.push({node, true}); // post-visit step\n                \n                for (int neighbor : graph[node]) {\n                    if (visited[neighbor] != 2) {\n                        st.push({neighbor, false}); // pre-visit step\n                    }\n                }\n            }\n        }\n    }\n\t\n    return false; // no cycles\n}\nTopo Sort (using DFS)\n\nonly applicable on DAG\ndirected graph should appear in it‚Äôs linear ordering (if u‚Üív then u should come before v)\n\nvector&lt;int&gt; toposort(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n    int n = graph.size();\n    vector&lt;bool&gt; visited(n, false);\n    stack&lt;int&gt; ans; // Stack for topological order\n\t\n    for (int i = 0; i &lt; n; ++i) {\n        if (visited[i]) continue;\n        \n\t    stack&lt;int&gt; st; // Stack for DFS traversal\n        st.push(i); // Start DFS from unvisited node\n        // here we won&#039;t mark i as visited as we haven&#039;t pushed it&#039;s neighbors in stack\n        while (!st.empty()) {\n            int node = st.top();\n            st.pop();\n            \n            if (!visited[node]) {\n                visited[node] = true;\n                st.push(node); // Re-push node for post-order processing\n                \n                // Push unvisited neighbors\n                for (int neighbor : graph[node]) {\n                    if (!visited[neighbor]) {\n                        st.push(neighbor);\n                    }\n                }\n            } else {\n                ans.push(node); // Add to result stack after processing neighbors\n            }\n        }\n    }\n\t\n    // Transfer from ans stack to result vector\n    vector&lt;int&gt; result;\n    while (!ans.empty()) {\n        result.push_back(ans.top());\n        ans.pop();\n    }\n    \n    return result;\n}\nTopo Sort (using BFS called Kahn‚Äôs algo)\nrepeatedly remove nodes without any dependencies from the graph\n\nwe keep track of in-degree of all node.\nthen in bfs decrease degree of all neighbors\nif at any point we can‚Äôt find a node with degree 0 though we have nodes with degree &gt; 0 then it‚Äôs because of cycle\n\nvector&lt;int&gt; toposort(vector&lt;vector&lt;int&gt;&gt;&amp; graph) {\n    int n = graph.size();\n    vector&lt;int&gt; res;\n    vector&lt;int&gt; degree(n, 0);\n    \n    // find in-degree of all nodes\n    for (auto i: graph) {\n        for (auto j: i) {\n            degree[j]++;\n        }\n    }\n    \n    // enter all 0 degree nodes i.e. nodes that have no dependencies initially\n    queue&lt;int&gt; q;\n    for (int i=0; i&lt;n; i++) {\n        if (degree[i] == 0) q.push(i);\n    }\n    \n    // BFS: Process level by level\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        res.push_back(node);\n\t\t\n        for (int neighbor : graph[node]) {\n            degree[neighbor]--;\n            if (degree[neighbor] == 0) {\n                q.push(neighbor);\n            }\n        }\n    }\n    \n    // Check for cycle\n    if (res.size() != n) return {};\n    \n\treturn res;\n}\nShortest Path\n\nFor Undirected, Unweighted graph\n\n‚Üí bfs (O(E+V))\n\n\nFor Undirected, Weighted (+ve only) graph\n\n‚Üí dijkstra\n\n\nFor Undirected, Weighted (both +ve and -ve) graph\n\n‚Üí bellman ford\n\n\nFor Unweighted DAG\n\n‚Üí bfs\n\n\nFor Weighted (both +ve and -ve) DAG\n\n‚Üí topo sort + relaxation\n\n\n\nSingle Source Shortest Path Algos:\n\nDijkstra ‚áí O((E+V) * log(V)) ‚áí pick the path with the shortest distance\nBellman Ford ‚áí O(EV) ‚áí relax edges v-1 times, if in v‚Äôth relaxation any change in shortest path occur then graph have negative cycle/s\n\nAll Pairs Shortest Path Algos:\n\nFloyd Warshal ‚áí O(V^3) ‚áí use an 3D-DP array to store the shortest path from i to j using k node\n\nShortest Path in Weighted DAG (Topo Sort)\nvector&lt;int&gt; toposort(vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt;&amp; graph) {\n    int n = graph.size();\n    vector&lt;int&gt; res;\n    vector&lt;int&gt; degree(n, 0);\n    \n    // find in-degree of all nodes\n    for (auto i: graph) {\n        for (auto j: i) {\n            degree[j.first]++;\n        }\n    }\n    \n    // enter all 0 degree nodes i.e. nodes that have no dependencies initially\n    queue&lt;int&gt; q;\n    for (int i=0; i&lt;n; i++) {\n        if (degree[i] == 0) q.push(i);\n    }\n    \n    // BFS: Process level by level\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n        res.push_back(node);\n\t\t\n        for (auto neighbor : graph[node]) {\n            degree[neighbor.first]--;\n            if (degree[neighbor.first] == 0) {\n                q.push(neighbor.first);\n            }\n        }\n    }\n    \n    // Check for cycle\n    if (res.size() != n) return {};\n    \n\treturn res;\n}\n \nvector&lt;int&gt; shortest_path_dag(int start, int v, int e, vector&lt;vector&lt;int&gt;&gt;&amp; edges) {\n    vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; graph(v, vector&lt;pair&lt;int, int&gt;&gt;());\n    for (int i=0; i&lt;e; i++) {\n        int u = edges[i][0];\n        int v = edges[i][1];\n        int w = edges[i][2];\n        graph[u].push_back({v, w});\n    }\n    \n    vector&lt;int&gt; temp = toposort(graph);\n    vector&lt;int&gt; dist(v, INT_MAX);\n    dist[start] = 0;\n    \n    for (int i=0; i&lt;temp.size(); i++) {\n        if (dist[temp[i]] == INT_MAX) continue;\n        for (auto neighbor: graph[temp[i]]) {\n            dist[neighbor.first] = min(dist[neighbor.first], dist[temp[i]] + neighbor.second);\n        }\n    }\n    \n    return dist;\n}\n \nint main()\n{\n    int v = 6, e = 7;\n    vector&lt;vector&lt;int&gt;&gt; edges= {{0,1,2},{0,4,1},{4,5,4},{4,2,2},{1,2,3},{2,3,6},{5,3,1}};\n\t\n\tvector&lt;int&gt; res = shortest_path_dag(0, v, e, edges);\n\tfor (int i: res) {\n\t    cout &lt;&lt; i &lt;&lt; &quot; &quot;;\n\t}\n\tcout &lt;&lt; endl;\n\t\n\treturn 0;\n}\nShortest Path in Weighted (+ve only) graph (Djikstra)\nDijkstra ‚áí pick the path with the shortest distance\nvector&lt;int&gt; djisktra (int v, int start, vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt;&amp; graph) {\n    priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; pq; // node index, distance from start\n    pq.push({start, 0});\n     \n    vector&lt;int&gt; dist(v, INT_MAX);\n    dist[start] = 0;\n    \n    while (!pq.empty()) {\n        auto node = pq.top();\n        pq.pop();\n        \n        for (auto neighbor: graph[node.first]) {\n            int new_dist = node.second + neighbor.second;\n            if (new_dist &lt; dist[neighbor.first]) {\n                dist[neighbor.first] = node.second + neighbor.second; \n                pq.push({neighbor.first, dist[neighbor.first]});\n            }\n        }\n    }\n    \n    return dist;\n}\n \nvector&lt;int&gt; shortest_path_pos(int start, int v, int e, vector&lt;vector&lt;int&gt;&gt;&amp; edges) {\n    vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; graph(v, vector&lt;pair&lt;int, int&gt;&gt;());\n    for (int i=0; i&lt;e; i++) {\n        int u = edges[i][0];\n        int v = edges[i][1];\n        int w = edges[i][2];\n        graph[u].push_back({v, w});\n    }\n    \n    return djisktra(v, start, graph);\n}\n \nint main()\n{\n    int v = 6, e = 7;\n    vector&lt;vector&lt;int&gt;&gt; edges= {{0,1,2},{0,4,1},{4,5,4},{4,2,2},{1,2,3},{2,3,6},{5,3,1}};\n\t\n\tvector&lt;int&gt; res = shortest_path_pos(0, v, e, edges);\n\tfor (int i: res) {\n\t    cout &lt;&lt; i &lt;&lt; &quot; &quot;;\n\t}\n\tcout &lt;&lt; endl;\n\t\n\treturn 0;\n}\nCheapest Flights Within K Stops\nint dijkstra(int v, int src, int dst, int k, vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt;&amp; graph) {\n\t// {price, city, stops}\n\tpriority_queue&lt;tuple&lt;int, int, int&gt;, vector&lt;tuple&lt;int, int, int&gt;&gt;, greater&lt;tuple&lt;int, int, int&gt;&gt;&gt; pq;\n\tpq.push({0, src, 0}); // {price, city, stops}\n\t\n\tvector&lt;vector&lt;int&gt;&gt; dist(v, vector&lt;int&gt;(k + 2, INT_MAX)); // Track dist per city and stops\n\tdist[src][0] = 0;\n\t\n\twhile (!pq.empty()) {\n\t\tauto [price, city, stops] = pq.top();\n\t\tpq.pop();\n\t\t\n\t\tif (city == dst) return price; // Return as soon as destination is reached\n\t\t\n\t\tif (stops &lt;= k) { // Allow up to k stops (k+1 edges)\n\t\t\tfor (auto [new_city, travel_price] : graph[city]) {\n\t\t\t\tint new_price = price + travel_price;\n\t\t\t\tif (new_price &lt; dist[new_city][stops + 1]) {\n\t\t\t\t\tdist[new_city][stops + 1] = new_price;\n\t\t\t\t\tpq.push({new_price, new_city, stops + 1});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn dist[dst][k + 1] == INT_MAX ? -1 : dist[dst][k + 1];\n}\n \nint findCheapestPrice(int n, vector&lt;vector&lt;int&gt;&gt;&amp; flights, int src, int dst, int k) {\n\tvector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; graph(n);\n\tfor (int i = 0; i &lt; flights.size(); i++) {\n\t\tint u = flights[i][0];\n\t\tint v = flights[i][1];\n\t\tint w = flights[i][2];\n\t\tgraph[u].push_back({v, w});\n\t}\n\t\n\treturn dijkstra(n, src, dst, k, graph);\n}\nNumber of ways to arrive at destination\nint djikstra(int n, int src, int dst, vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt;&amp; graph) {\n\tconst long long mod_val = 1e9 + 7;\n\tpriority_queue&lt;pair&lt;long long, int&gt;, vector&lt;pair&lt;long long, int&gt;&gt;, greater&lt;pair&lt;long long, int&gt;&gt;&gt; pq;\n\tpq.push({0, src});\n\t\n\tvector&lt;pair&lt;long long, long long&gt;&gt; min_times(n, {LLONG_MAX, 0});\n\tmin_times[src] = {0, 1};\n\t\n\twhile (!pq.empty()) {\n\t\tauto [time, node] = pq.top();\n\t\tpq.pop();\n\t\t\n\t\tif (time &gt; min_times[node].first) continue;\n\t\t\n\t\tfor (auto [neighbor, time_taken]: graph[node]) {\n\t\t\tlong long new_time_taken = time_taken + time;\n\t\t\tif (new_time_taken &lt; min_times[neighbor].first) {\n\t\t\t\tmin_times[neighbor] = {new_time_taken, min_times[node].second};\n\t\t\t\tpq.push({new_time_taken, neighbor});\n\t\t\t} else if (new_time_taken == min_times[neighbor].first) {\n\t\t\t\tmin_times[neighbor].second = (min_times[neighbor].second + min_times[node].second) % mod_val;\n\t\t\t} \n\t\t}\n\t}\n\t\n\treturn min_times[dst].first == LLONG_MAX ? 0 : min_times[dst].second % mod_val;\n}\n \nint countPaths(int n, vector&lt;vector&lt;int&gt;&gt;&amp; roads) {\n\t vector&lt;vector&lt;pair&lt;int, int&gt;&gt;&gt; graph(n);\n\tfor (int i = 0; i &lt; roads.size(); i++) {\n\t\tint u = roads[i][0];\n\t\tint v = roads[i][1];\n\t\tint w = roads[i][2];\n\t\tgraph[u].push_back({v, w});\n\t\tgraph[v].push_back({u, w});\n\t}\n\t\n\treturn djikstra(n, 0, n-1, graph);\n}\nBellman Ford Algorithm\nvector&lt;int&gt; bellman_ford(int start, int v, vector&lt;vector&lt;int&gt;&gt;&amp; edges) {\n    vector&lt;int&gt; dist(v, 1e8);\n    dist[start] = 0;\n    \n    for (int i=0; i&lt;v-1; i++) {\n        for (auto it: edges) {\n            int u = it[0];\n            int v = it[1];\n            int w = it[2];\n            if (dist[u] != 1e8 &amp;&amp; dist[u] + w &lt; dist[v]) {\n                dist[v] = dist[u] + w;\n            }\n        }\n    }\n    \n    // nth relaxation to check for negative cycle \n    for (auto it: edges) {\n        int u = it[0];\n        int v = it[1];\n        int w = it[2];\n        if (dist[u] != 1e8 &amp;&amp; dist[u] + w &lt; dist[v]) return {-1};\n    }\n    \n    return dist;\n}\nFloyd Warshal Algorithm\nvoid floyd_warshal(vector&lt;vector&lt;int&gt;&gt;&amp;matrix) {\n\tint n = matrix.size();\n\t// initalize\n\tfor (int i = 0; i &lt; n; i++) {\n\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t// if not reachable i.e. -1 then assign infinity\n\t\t\tif (matrix[i][j] == -1) {\n\t\t\t\tmatrix[i][j] = 1e9;\n\t\t\t}\n\t\t\tif (i == j) matrix[i][j] = 0;\n\t\t}\n\t}\n\t\n\t// find shortest via all k&#039;s\n\tfor (int k = 0; k &lt; n; k++) {\n\t\tfor (int i = 0; i &lt; n; i++) {\n\t\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t\tmatrix[i][j] = min(matrix[i][j], matrix[i][k] + matrix[k][j]);\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (int i = 0; i &lt; n; i++) {\n\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t// reverse the infinity assigned to unreachable nodes\n\t\t\tif (matrix[i][j] == 1e9) {\n\t\t\t\tmatrix[i][j] = -1;\n\t\t\t}\n\t\t}\n\t}\n}\nFind the City With the Smallest Number of Neighbors at a Threshold Distance\nvoid floyd_warshal(vector&lt;vector&lt;int&gt;&gt;&amp;matrix) {\n\tint n = matrix.size();\n\t// initalize\n\tfor (int i = 0; i &lt; n; i++) {\n\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t// if not reachable i.e. -1 then assign infinity\n\t\t\tif (matrix[i][j] == -1) {\n\t\t\t\tmatrix[i][j] = 1e9;\n\t\t\t}\n\t\t\tif (i == j) matrix[i][j] = 0;\n\t\t}\n\t}\n\t\n\t// find shortest via all k&#039;s\n\tfor (int k = 0; k &lt; n; k++) {\n\t\tfor (int i = 0; i &lt; n; i++) {\n\t\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t\tmatrix[i][j] = min(matrix[i][j], matrix[i][k] + matrix[k][j]);\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (int i = 0; i &lt; n; i++) {\n\t\tfor (int j = 0; j &lt; n; j++) {\n\t\t\t// reverse the infinity assigned to unreachable nodes\n\t\t\tif (matrix[i][j] == 1e9) {\n\t\t\t\tmatrix[i][j] = -1;\n\t\t\t}\n\t\t}\n\t}\n}\n \nint findTheCity(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges, int distanceThreshold) {\n\tvector&lt;vector&lt;int&gt;&gt; dist(n, vector&lt;int&gt; (n, -1));\n\tfor (auto it: edges) {\n\t\tint u = it[0];\n\t\tint v = it[1];\n\t\tint w = it[2];\n\t\tdist[u][v] = w;\n\t\tdist[v][u] = w;\n\t}\n\t\n\tfloyd_warshal(dist);\n\t\n\tint neighbor_cities = INT_MAX, res = 0;\n\tfor (int i=0; i&lt;n; i++) {\n\t\tint cnt = 0;\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (i!=j &amp;&amp; dist[i][j] &lt;= distanceThreshold) cnt++; \n\t\t}\n\t\tif (cnt &lt;= neighbor_cities) {\n\t\t\tneighbor_cities = cnt;\n\t\t\tres = i;\n\t\t}\n\t}\n\t\n\treturn res;\n}\nMinimum Spanning Tree (MST)\nSpanning Tree ‚áí A tree with n nodes, n-1 edges and all nodes are reachable from other nodes\nMinimum Spanning Tree ‚áí Spanning Tree in a graph with minimum sum of edge weights\nPrim‚Äôs Algorithm\nvector&lt;pair&lt;int, int&gt;&gt; prims_mst(int v, vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt;&amp; graph) {\n    priority_queue&lt;vector&lt;int&gt;, vector&lt;vector&lt;int&gt;&gt;, greater&lt;vector&lt;int&gt;&gt;&gt; pq;\n    vector&lt;int&gt; visited(v, 0);\n    vector&lt;pair&lt;int, int&gt;&gt; mst;\n    \n    pq.push({0, 0, -1}); // weight, node, parent\n    int mst_sum = 0;\n\t\n\t// between parent to node greedily pick the least weight\n    while (!pq.empty()) {\n        auto it = pq.top();\n        pq.pop();\n        \n        int wt = it[0];\n        int node = it[1];\n        int parent = it[2];\n        \n        if (visited[node]) continue;\n        visited[node] = 1;\n        \n        if (parent != -1) {\n            mst.push_back({parent, node});\n        }\n        mst_sum += wt;\n        \n        for (auto jt : graph[node]) {\n            int neighbor = jt[0];\n            int ewt = jt[1];\n            if (!visited[neighbor]) {\n                pq.push({ewt, neighbor, node});\n            }\n        }\n    }\n    \n    cout &lt;&lt; &quot;MST sum: &quot; &lt;&lt; mst_sum &lt;&lt; endl;\n    return mst;\n}\n \nint main() {\n    int V = 5;\n    vector&lt;vector&lt;int&gt;&gt; edges = {\n        {0, 1, 2}, {0, 2, 1}, {1, 2, 1},\n        {2, 3, 2}, {3, 4, 1}, {4, 2, 2}\n    };\n\t\n    vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; adj(V);\n    for (auto it : edges) {\n        int u = it[0], v = it[1], w = it[2];\n        adj[u].push_back({v, w});\n        adj[v].push_back({u, w});\n    }\n\t\n    vector&lt;pair&lt;int, int&gt;&gt; res = prims_mst(V, adj);\n    for (auto [u, v] : res) {\n        cout &lt;&lt; u &lt;&lt; &quot; &quot; &lt;&lt; v &lt;&lt; endl;\n    }\n\t\n    return 0;\n}\nDisjoint Set / Union Find\nused when array/graph is dynamic\nIt gives us two options:\n\nfinding ultimate parent ~ alpha(n) ~ O(1)\nunion ~ alpha(n) ~ O(1) ‚áí add new value to array/graph\n\nunion by rank\nunion by size\n\n\n\nclass DisjointSet {\n    vector&lt;int&gt; rank, union_size, parent;\n \npublic:\n    DisjointSet(int n) {\n        rank.resize(n+1, 0);\n        union_size.resize(n+1, 1);\n        parent.resize(n+1);\n        for (int i=0; i&lt;=n; i++) {\n            parent[i] = i;\n        }\n    }\n    \n    int find_ultimate_parent(int node) {\n        if (node == parent) return node;\n        // path compression\n        return parent[node] = find_ultimate_parent(parent[node]);\n    }\n    \n    void union_by_rank(int u, int v) {\n        int ultimate_parent_u = find_ultimate_parent(u);\n        int ultimate_parent_v = find_ultimate_parent(v);\n        \n        if (ultimate_parent_u == ultimate_parent_v) return;\n        \n        if (rank[ultimate_parent_u] &lt; rank[ultimate_parent_v]) {\n            parent[ultimate_parent_u] = ultimate_parent_v;\n        } else if (rank[ultimate_parent_u] &gt; rank[ultimate_parent_v]) {\n            parent[ultimate_parent_v] = ultimate_parent_u;\n        } else {\n            parent[ultimate_parent_v] = ultimate_parent_u;\n            rank[ultimate_parent_u]++;\n        }\n    }\n    \n    void union_by_size(int u, int v) {\n        int ultimate_parent_u = find_ultimate_parent(u);\n        int ultimate_parent_v = find_ultimate_parent(v);\n        \n        if (ultimate_parent_u == ultimate_parent_v) return;\n        \n        if (union_size[ultimate_parent_u] &lt; union_size[ultimate_parent_v]) {\n            parent[ultimate_parent_u] = ultimate_parent_v;\n            union_size[ultimate_parent_v] += union_size[ultimate_parent_u];\n        } else {\n            parent[ultimate_parent_v] = ultimate_parent_u;\n            union_size[ultimate_parent_u] += union_size[ultimate_parent_v];\n        }\n    }\n};\nKruskal‚Äôs Algorithm\nclass DisjointSet {\n    vector&lt;int&gt; union_size, parent;\npublic:\n    DisjointSet(int n) {\n        union_size.resize(n+1, 1);\n        parent.resize(n+1);\n        for (int i=0; i&lt;=n; i++) {\n            parent[i] = i;\n        }\n    }\n    \n    int find_ultimate_parent(int node) {\n        if (node == parent[node]) return node;\n        // path compression\n        return parent[node] = find_ultimate_parent(parent[node]);\n    }\n    \n    void union_by_size(int u, int v) {\n        int ultimate_parent_u = find_ultimate_parent(u);\n        int ultimate_parent_v = find_ultimate_parent(v);\n        \n        if (ultimate_parent_u == ultimate_parent_v) return;\n        \n        if (union_size[ultimate_parent_u] &lt; union_size[ultimate_parent_v]) {\n            parent[ultimate_parent_u] = ultimate_parent_v;\n            union_size[ultimate_parent_v] += union_size[ultimate_parent_u];\n        } else {\n            parent[ultimate_parent_v] = ultimate_parent_u;\n            union_size[ultimate_parent_u] += union_size[ultimate_parent_v];\n        }\n    }\n};\n \nint kruskal_mst(int v, vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt;&amp; edges) {\n    // edges =&gt; {weight, {u, v}}\n    \n    sort(edges.begin(), edges.end());\n    \n    DisjointSet ds(v);\n    int mst_sum = 0;\n    for (auto it: edges) {\n        int wt = it.first;\n        int u = it.second.first;\n        int v = it.second.second;\n        \n        if (ds.find_ultimate_parent(u) != ds.find_ultimate_parent(v)) {\n            mst_sum += wt;\n            ds.union_by_size(u, v);\n        }\n    }\n    \n    return mst_sum;\n}\nNumber of Operations to Make Network Connected\nclass DisjointSet {\n\tvector&lt;int&gt; union_size, parent;\npublic:\n\tDisjointSet(int n) {\n\t\tunion_size.resize(n+1, 1);\n\t\tparent.resize(n+1);\n\t\tfor (int i=0; i&lt;=n; i++) {\n\t\t\tparent[i] = i;\n\t\t}\n\t}\n\t\n\tint find_ultimate_parent(int node) {\n\t\tif (node == parent[node]) return node;\n\t\t// path compression\n\t\treturn parent[node] = find_ultimate_parent(parent[node]);\n\t}\n\t\n\tvoid union_by_size(int u, int v) {\n\t\tint ultimate_parent_u = find_ultimate_parent(u);\n\t\tint ultimate_parent_v = find_ultimate_parent(v);\n\t\t\n\t\tif (ultimate_parent_u == ultimate_parent_v) return;\n\t\t\n\t\tif (union_size[ultimate_parent_u] &lt; union_size[ultimate_parent_v]) {\n\t\t\tparent[ultimate_parent_u] = ultimate_parent_v;\n\t\t\tunion_size[ultimate_parent_v] += union_size[ultimate_parent_u];\n\t\t} else {\n\t\t\tparent[ultimate_parent_v] = ultimate_parent_u;\n\t\t\tunion_size[ultimate_parent_u] += union_size[ultimate_parent_v];\n\t\t}\n\t}\n};\n \nint makeConnected(int n, vector&lt;vector&lt;int&gt;&gt;&amp; connections) {\n\tDisjointSet ds(n);\n\tint cnt = 0; // Count redundant edges\n\tfor (auto&amp; it : connections) {\n\t\tint u = it[0];\n\t\tint v = it[1];\n\t\tif (ds.find_ultimate_parent(u) == ds.find_ultimate_parent(v)) {\n\t\t\tcnt++;\n\t\t} else {\n\t\t\tds.union_by_size(u, v);\n\t\t}\n\t}\n\t\n\t// Count components\n\tunordered_set&lt;int&gt; components;\n\tfor (int i = 0; i &lt; n; i++) {\n\t\tcomponents.insert(ds.find_ultimate_parent(i));\n\t}\n\tint num_components = components.size();\n\t\n\t// Need (num_components - 1) edges to connect all components\n\tif (cnt &gt;= num_components - 1) {\n\t\treturn num_components - 1;\n\t}\n\treturn -1; // Not enough edges to connect\n}\nMost Stones Removed with Same Row or Column\nclass DisjointSet {\n\tvector&lt;int&gt; union_size, parent;\n\tpublic: \n\t\tDisjointSet(int n) {\n\t\t\tunion_size.resize(n+1, 1);\n\t\t\tparent.resize(n+1);\n\t\t\tfor (int i=0; i&lt;n+1; i++) parent[i]=i;\n\t\t}\n\t\t\n\t\tint find_ultimate_parent(int node) {\n\t\t\tif (parent[node] == node) return node;\n\t\t\treturn parent[node] = find_ultimate_parent(parent[node]);\n\t\t}\n\t\t\n\t\tvoid union_by_size(int u, int v) {\n\t\t\tint ultimate_parent_u = find_ultimate_parent(u);\n\t\t\tint ultimate_parent_v = find_ultimate_parent(v);\n\t\t\t\n\t\t\tif (ultimate_parent_u == ultimate_parent_v) return;\n\t\t\t\n\t\t\tif (union_size[ultimate_parent_u] &lt; union_size[ultimate_parent_v]) {\n\t\t\t\tparent[ultimate_parent_u] = ultimate_parent_v;\n\t\t\t\tunion_size[ultimate_parent_v] += union_size[ultimate_parent_u];\n\t\t\t} else {\n\t\t\t\tparent[ultimate_parent_v] = ultimate_parent_u;\n\t\t\t\tunion_size[ultimate_parent_u] += union_size[ultimate_parent_v];\n\t\t\t}\n\t\t}\n};\n \nint removeStones(vector&lt;vector&lt;int&gt;&gt;&amp; stones) {\n\t// we can use dfs on each stone to find all connected stones\n\t// then from each of connected stone component remove all except one stone\n\t// therefore the formula boils down to (no of stones - no of connected components)\n\t\n\t// but we will use DSU to group them\n\t// but DSU have a 1D array so we will convert columns\n\t// rows number from 0 to no_of_rows then columns are (column_number + no_of_rows + 1)   \n\tint no_of_rows = 0;\n\tint no_of_cols = 0;\n\t\n\tfor (auto it: stones) {\n\t\tno_of_rows = max(no_of_rows, it[0]);\n\t\tno_of_cols = max(no_of_cols, it[1]);\n\t}\n\t\n\tDisjointSet ds(no_of_rows + no_of_cols + 1);\n\t\n\t// connect stones columns and rows to represent a connected component\n\tfor (auto it: stones) {\n\t\tint stone_row = it[0];\n\t\tint stone_col = it[1] + no_of_rows + 1;\n\t\tds.union_by_size(stone_row, stone_col);\n\t}\n\t\n\t// no of unique ultimate parents of stone  == no of components\n\tunordered_set&lt;int&gt; s;\n\tfor (auto it: stones) {\n\t\tint stone_row = it[0];\n\t\ts.insert(ds.find_ultimate_parent(stone_row));\n\t}\n\t\n\treturn stones.size() - s.size();\n}\nMaking A Large Island\nclass DSU{\n\tpublic: \n\t\tvector&lt;int&gt; union_size, parent;\n\t\tDSU(int n) {\n\t\t\tunion_size.resize(n+1, 1);\n\t\t\tparent.resize(n+1);\n\t\t\tfor (int i=0; i&lt;n+1; i++) parent[i] = i;\n\t\t}\n\t\t\n\t\tint find_ultimate_parent(int node) {\n\t\t\tif (parent[node] == node) return node;\n\t\t\treturn parent[node] = find_ultimate_parent(parent[node]);\n\t\t}\n\t\t\n\t\tvoid union_by_size(int u, int v) {\n\t\t\tint ultimate_parent_u = find_ultimate_parent(u);\n\t\t\tint ultimate_parent_v = find_ultimate_parent(v);\n\t\t\tif (ultimate_parent_u == ultimate_parent_v) return;\n\t\t\t\n\t\t\tif (ultimate_parent_u &lt; ultimate_parent_v) {\n\t\t\t\tparent[ultimate_parent_u] = ultimate_parent_v;\n\t\t\t\tunion_size[ultimate_parent_v] += union_size[ultimate_parent_u]; \n\t\t\t} else {\n\t\t\t\tparent[ultimate_parent_v] = ultimate_parent_u;\n\t\t\t\tunion_size[ultimate_parent_u] += union_size[ultimate_parent_v];\n\t\t\t}\n\t\t}\n};\n \nint largestIsland(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint n = grid.size();\n\tvector&lt;pair&lt;int, int&gt;&gt; directions = {{0, 1}, {0, -1}, {1, 0}, {-1, 0}};\n\tvector&lt;pair&lt;int, int&gt;&gt; zeros;\n\tDSU ds(n*n);\n\t\n\tfor (int i=0; i&lt;n; ++i) {\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (grid[i][j] == 0) {\n\t\t\t\tzeros.push_back({i, j});\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfor (auto it: directions) {\n\t\t\t\tint newRow = it.first+i;\n\t\t\t\tint newCol = it.second+j;\n\t\t\t\tif (newRow &gt;= 0 &amp;&amp; newRow &lt; n &amp;&amp;\n\t\t\t\t\tnewCol &gt;= 0 &amp;&amp; newCol &lt; n &amp;&amp;\n\t\t\t\t\tgrid[newRow][newCol] == 1) {\n\t\t\t\t\t\tint nodeNo = i * n + j;\n\t\t\t\t\t\tint adjNodeNo = newRow * n + newCol;\n\t\t\t\t\t\tds.union_by_size(nodeNo, adjNodeNo);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// entire grid is of one&#039;s\n\tbool allOnes = zeros.empty();\n\tif (allOnes) return n * n;\n\t\n\tint res = 0;\n\tfor (auto it: zeros) {\n\t\tint row = it.first;\n\t\tint col = it.second;\n\t\tset&lt;int&gt; components;\n\t\tfor (auto it: directions) {\n\t\t\tint newRow = it.first+row;\n\t\t\tint newCol = it.second+col;\n\t\t\tif (newRow &gt;= 0 &amp;&amp; newRow &lt; n &amp;&amp;\n\t\t\t\tnewCol &gt;= 0 &amp;&amp; newCol &lt; n &amp;&amp;\n\t\t\t\tgrid[newRow][newCol] == 1) {\n\t\t\t\t\tcomponents.insert(ds.find_ultimate_parent(newRow*n+newCol));\n\t\t\t}\n\t\t}\n\t\tint total_size = 0;\n\t\tfor (auto it: components) {\n\t\t\ttotal_size += ds.union_size[it];\n\t\t}\n\t\tres = max(res, total_size+1);\n\t}\n\t\n\treturn res;\n}\nSwim in Rising Water\nint swimInWater(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint n = grid.size();\n\tvector&lt;vector&lt;int&gt;&gt; directions = {{0, 1}, {0, -1}, {1, 0}, {-1, 0}};\n\tvector&lt;vector&lt;bool&gt;&gt; visited(n, vector&lt;bool&gt;(n, false));\n\tpriority_queue&lt;pair&lt;int, pair&lt;int, int&gt;&gt;, vector&lt;pair&lt;int, pair&lt;int, int&gt;&gt;&gt;, greater&lt;&gt;&gt; pq;\n\t\n\tpq.push({grid[0][0], {0, 0}});\n\tvisited[0][0] = true;\n\tint maxElevation = grid[0][0];\n\t\n\twhile (!pq.empty()) {\n\t\tauto [elevation, pos] = pq.top();\n\t\tint row = pos.first, col = pos.second;\n\t\tpq.pop();\n\t\t\n\t\tmaxElevation = max(maxElevation, elevation);\n\t\tif (row == n-1 &amp;&amp; col == n-1) return maxElevation;\n\t\t\n\t\tfor (auto&amp; dir : directions) {\n\t\t\tint newRow = row + dir[0], newCol = col + dir[1];\n\t\t\tif (newRow &gt;= 0 &amp;&amp; newRow &lt; n &amp;&amp; newCol &gt;= 0 &amp;&amp; newCol &lt; n &amp;&amp; !visited[newRow][newCol]) {\n\t\t\t\tvisited[newRow][newCol] = true;\n\t\t\t\tpq.push({grid[newRow][newCol], {newRow, newCol}});\n\t\t\t}\n\t\t}\n\t}\n\treturn maxElevation;\n}\nBridges in Graph\na bridge is any edges in graph that on removal will create a new connected component\nwhen we do a dfs traversal if we have visited an adjacent node then we skip that, this adjacent nodes are ancestors of the current node.\nThe skipped edges are called back edges while the edges of the resultant tree formed due to dfs are called forward edges.\nvoid dfs(int node, int parent, int timer, vector&lt;vector&lt;int&gt;&gt;&amp; adj, \n         vector&lt;vector&lt;int&gt;&gt;&amp; bridges, vector&lt;int&gt;&amp; visited,\n         vector&lt;int&gt;&amp; in_time, vector&lt;int&gt;&amp; lowest_time) {\n        \n    visited[node] = 1;\n    in_time[node] = timer;\n    lowest_time[node] = timer;\n    timer++;\n        \n    for (auto it: adj[node]) {\n        if (it == parent) continue;\n        \n        if (visited[it] == 0) {\n            dfs(it, node, timer, adj, bridges, visited, in_time, lowest_time);\n            \n            // take lowest of lowest_time of node and lowest_time of it\n            lowest_time[node] = min(lowest_time[node], lowest_time[it]);\n            // check if node to it is a bridge\n            if (lowest_time[it] &gt; in_time[node]) {\n                bridges.push_back({it, node});\n            }\n        } else {\n            lowest_time[node] = min(lowest_time[node], lowest_time[it]);\n        }\n    }\n}\n \nvector&lt;vector&lt;int&gt;&gt; tarjan_bridges(int n, vector&lt;vector&lt;int&gt;&gt;&amp; adj) {\n    vector&lt;int&gt; visited(n, 0);\n    vector&lt;int&gt; in_time(n);\n    vector&lt;int&gt; lowest_time(n);\n    vector&lt;vector&lt;int&gt;&gt; bridges;\n    \n    int timer = 1;\n    dfs(0, -1, timer, adj, bridges, visited, in_time, lowest_time);\n    return bridges;\n}\nArticulation Points in Graph\nnode that on removal create new connected components\nDP\nMethods to solve:\n\nTabulation (Iterative) ‚Üí bottom up\nMemoization (Recursive) ‚Üí top down\n\nfind recurrence relation in problems\nFibonacci numbers\nin recursion we end up solving same subproblems which are called overlapping subproblems\nso we memoization the condition of subproblem with solution using matrix, map, table etc\n// Recursion\nint fib (int n) {\n\tif (n &lt;= 1) return n;\n\treturn fib(n-1) + fib(n-2);\n}\n \n// Dynamic Programming\n// Memoization -&gt; Recursive -&gt; top down\nint fib (int n, vector&lt;int&gt;&amp; dp) {\n\tif (n &lt;= 1) return n;\n\tif (dp[n] != -1) return dp[n];\n\treturn dp[n] = fib(n-1, dp) + fib(n-2, dp);\n}\nint main() {\n\tint n = 7;\n\tvector&lt;int&gt; dp(n+1, -1);\n\tcout &lt;&lt; fib(n, dp) &lt;&lt; endl;\n\t\n\treturn 0;\n}\n \n// Tabulation -&gt; Iterative -&gt; bottom up\nint main() {\n\tint n = 7;\n\tvector&lt;int&gt; dp(n+1, -1);\n\t\n\tdp[0] = 0, dp[1] = 1;\n\tfor (int i=2; i&lt;=n; i++) {\n\t\tdp[i] = dp[i-1] + dp[i-2];\n\t}\n\tcout &lt;&lt; dp[n] &lt;&lt; endl;\n\t\n\treturn 0;\n}\n \n// Tabulation space optimized\nint main() {\n\tint n = 7;\n\t\n\tint prev2 = 0, prev = 1;\n\tfor (int i=2; i&lt;=n; i++) {\n\t\tint curr = prev + prev2;\n\t\tprev2 = prev;\n\t\tprev = curr;\n\t}\n\tcout &lt;&lt; prev &lt;&lt; endl;\n\t\n\treturn 0;\n}\n1D DP\n\nTry to represent the problem in terms of index\nwrite all possible ways an index can behave according to the question\nsum up, find min, find max etc. according to the question\n\nClimbing Stairs\n// Recursive\nint fnc(int stair) {\n\tif (stair == 0 || stair == 1) return 1;\n\tint c1 = fnc(stair-1);\n\tint c2 = fnc(stair-2);\n\treturn c1+c2; \n}\n \nint climbStairs(int n) {\n\treturn fnc(n);\n}\n \n// Memoization\nint fnc(int stair, vector&lt;int&gt;&amp; dp) {\n\tif (stair == 0 || stair == 1) return 1;\n\tint c1=0, c2=0;\n\tif (dp[stair-1] != -1) c1 = dp[stair-1];\n\telse {\n\t\tc1 = fnc(stair-1, dp);\n\t\tdp[stair-1] = c1;\n\t}\n\tif (dp[stair-2] != -1) c2 = dp[stair-2];\n\telse {\n\t\tc2 = fnc(stair-2, dp);\n\t\tdp[stair-2] = c2;\n\t}\n\treturn c1+c2; \n}\n \nint climbStairs(int n) {\n\tvector&lt;int&gt; dp(n+1, -1);\n\treturn fnc(n, dp);\n}\nHouse Robber\nquestion ‚áí don‚Äôt pick adjacent elements\nint fnc(int i, vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; memo) {\n\tif (i &gt;= nums.size()) return 0;\n\tif (memo[i] != -1) return memo[i];\n\t\n\tint skip = fnc(i + 1, nums, memo);\n\tint rob = nums[i] + fnc(i + 2, nums, memo);\n\t\n\treturn memo[i] = max(skip, rob);\n}\n \nint rob(vector&lt;int&gt;&amp; nums) {\n\tif (nums.empty()) return 0;\n\tvector&lt;int&gt; memo(nums.size(), -1);\n\treturn fnc(0, nums, memo);\n}\nHouse Robber II\nquestion ‚áí don‚Äôt pick adjacent elements where elements are in circle\napply algo on start to end-1 and start+1 to end then return max of both\nint fnc(int start, int end, vector&lt;int&gt;&amp; nums) {\n\tint prev_rob = 0, max_rob = 0;\n\tfor (int i=start; i&lt;=end; i++) {\n\t\tint temp = max(max_rob, prev_rob + nums[i]);\n\t\tprev_rob = max_rob;\n\t\tmax_rob = temp;\n\t}\n\treturn max_rob;\n}\n \nint rob(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tif (n == 0) return 0;\n\tif (n == 1) return nums[0];\n\tif (n == 2) return max(nums[0], nums[1]);\n\t\n\tint case1 = fnc(0, n - 2, nums);\n\tint case2 = fnc(1, n - 1, nums);\n\t\n\treturn max(case1, case2);\n}\n2D DP\n\ncount unique paths\ncount unique paths with obstacles\nmin path sum\nmax path sum\ntriangle problem\n2 start points\n\nCount unique paths\nquestion ‚áí unique paths from [0,0] to [m-1, n-1]\nwe can think of dfs but for each cell we go right and down so TC ‚áí O(2^(m*n)) SC ‚áí O(n-1 + m-1)\nint uniquePaths(int m, int n) {\n\tint cnt = 0;\n\t\n\tstack&lt;pair&lt;int, int&gt;&gt; st;\n\tst.push({0, 0});\n\twhile (!st.empty()) {\n\t\tauto [row, col] = st.top();\n\t\tst.pop();\n\t\t\n\t\tif (row == m-1 &amp;&amp; col == n-1) {\n\t\t\tcnt++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (row+1 &lt; m) st.push({row+1, col});\n\t\tif (col+1 &lt; n) st.push({row, col+1});\n\t}\n\t\n\treturn cnt;\n}\n \n// gives TLE\nso we need to memoize the repeating subproblems TC ‚áí O(n*m) SC ‚áí O(n-1 + m-1) + O(n*m)\nint fnc (int row, int col, int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; dp) {\n\tif (row == m-1 &amp;&amp; col == n-1) return 1;\n\tif (row &gt;= m || col &gt;= n) return 0;\n\t\n\tif(dp[row][col] != -1) return dp[row][col];\n\tint right = fnc(row, col+1, m, n, dp);\n\tint down = fnc(row+1, col, m, n, dp);\n\t\n\treturn dp[row][col] = right+down;\n}\n \nint uniquePaths(int m, int n) {\n\tvector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, -1));\n\treturn fnc(0 , 0, m, n, dp);\n}\nwe are using recursion stack space O(n-1 + m-1) which can be optimized by tabulation i.e. iterative bottom up approach\nint uniquePaths(int m, int n) {\n\tvector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, 0));\n\t\n\tfor (int i=0; i&lt;m; ++i) {\n\t\tfor (int j=0; j&lt;n; ++j) {\n\t\t\tif (i == 0 &amp;&amp; j == 0) dp[i][j] = 1;\n\t\t\telse {\n\t\t\t\tint left = 0, up = 0;\n\t\t\t\tif (i&gt;0) up = dp[i-1][j];\n\t\t\t\tif (j&gt;0) left = dp[i][j-1];\n\t\t\t\tdp[i][j] = up + left;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn dp[m-1][n-1];\n}\nCount Unique paths without obstacle\nint fnc (int row, int col, int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; dp, vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {\n\tif (row &gt;= m || col &gt;= n) return 0;\n\tif (obstacleGrid[row][col] == 1) return 0;\n\tif (row == m-1 &amp;&amp; col == n-1) return 1;\n\t\n\tif(dp[row][col] != -1) return dp[row][col];\n\tint right = fnc(row, col+1, m, n, dp, obstacleGrid);\n\tint down = fnc(row+1, col, m, n, dp, obstacleGrid);\n\t\n\treturn dp[row][col] = right+down;\n}\n \nint uniquePathsWithObstacles(vector&lt;vector&lt;int&gt;&gt;&amp; obstacleGrid) {\n\tint m = obstacleGrid.size();\n\tint n = obstacleGrid[0].size();\n\tvector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, -1));\n\t\n\treturn fnc(0 , 0, m, n, dp, obstacleGrid);\n}\nMinimum Path Sum in Grid\nint fnc (int row, int col, int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; dp, vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tif (row &gt;= m || col &gt;= n) return 1e7;\n\tif (row == m-1 &amp;&amp; col == n-1) return grid[row][col];\n\t\n\tif(dp[row][col] != -1) return dp[row][col];\n\tint right = grid[row][col] + fnc(row, col+1, m, n, dp, grid);\n\tint down = grid[row][col] + fnc(row+1, col, m, n, dp, grid);\n\t\n\treturn dp[row][col] = min(right, down);\n}\n \nint minPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint m = grid.size();\n\tint n = grid[0].size();\n\tvector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, -1));\n\t\n\treturn fnc(0 , 0, m, n, dp, grid);\n}\nMinimum Path Sum in Triangle\nRecursive top down approach\nint fnc(int row, int i, int m, vector&lt;vector&lt;int&gt;&gt;&amp; dp, vector&lt;vector&lt;int&gt;&gt;&amp; triangle) {\n\tif (row == m) return triangle[row][i];\n\tif (dp[row][i] != -1) return dp[row][i];\n\t\n\tint left = fnc(row + 1, i, m, dp, triangle);\n\tint right = fnc(row + 1, i + 1, m, dp, triangle);\n\t\n\treturn dp[row][i] = triangle[row][i] + min(left, right);\n}\n \nint minimumTotal(vector&lt;vector&lt;int&gt;&gt;&amp; triangle) {\n\tint m = triangle.size() - 1;\n\tvector&lt;vector&lt;int&gt;&gt; dp(triangle.size(), vector&lt;int&gt;(triangle.size(), -1));\n\treturn fnc(0, 0, m, dp, triangle);\n}\nIterative bottom up approach\nint minimumTotal(vector&lt;vector&lt;int&gt;&gt;&amp; triangle) {\n\tint m = triangle.size();\n\tif (m-1 == 0) return triangle[0][0];\n\tvector&lt;vector&lt;int&gt;&gt; dp = triangle;\n\t\n\tfor (int row = m-2; row &gt;= 0; --row) {\n\t\tfor (int col = 0; col &lt;= row; ++col) {\n\t\t\tdp[row][col] += min(dp[row+1][col], dp[row+1][col+1]);\n\t\t}\n\t}\n\treturn dp[0][0];\n}\nMinimum Falling Path Sum\nRecursive top down approach\nint fnc (int row, int col, int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; dp, vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {\n\tif (dp[row][col] != -1) return dp[row][col];\n\tif (row == m) return matrix[row][col];\n\t\n\tint dl =  INT_MAX, dr = INT_MAX, d = INT_MAX;\n\t\n\tif (col-1 &gt;= 0) dl = fnc(row+1, col-1, m, n, dp, matrix);\n\tif (col+1 &lt;= n) dr = fnc(row+1, col+1, m, n, dp, matrix);\n\td = fnc(row+1, col, m, n, dp, matrix);\n\t\n\treturn dp[row][col] = matrix[row][col] + min(d, min(dl, dr));\n}\n \nint minFallingPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {\n\tint m = matrix.size()-1;\n\tint n = matrix[0].size()-1;\n\tvector&lt;vector&lt;int&gt;&gt; dp(m+1, vector&lt;int&gt;(n+1, -1));\n\tint ans = INT_MAX;\n\t\n\tfor (int i=0; i&lt;=n; ++i) {\n\t\tans = min(ans, fnc(0, i, m, n, dp, matrix));\n\t}\n\t\n\treturn ans;\n}\nIterative bottom up approach\nint minFallingPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {\n\tint m = matrix.size()-1;\n\tint n = matrix[0].size()-1;\n\tvector&lt;vector&lt;int&gt;&gt; dp = matrix;\n\t\n\tfor (int row = m-1; row&gt;=0; --row) {\n\t\tfor (int col = 0; col&lt;=n; ++col) {\n\t\t\tint dlu =  INT_MAX, dru = INT_MAX, d = INT_MAX;\n\t\t\t\n\t\t\tif (col-1 &gt;= 0) dlu = dp[row+1][col-1];\n\t\t\tif (col+1 &lt;= n) dru = dp[row+1][col+1];\n\t\t\td = dp[row+1][col];\n\t\t\t\n\t\t\tdp[row][col] = matrix[row][col] + min(d, min(dlu, dru));\n\t\t}\n\t}\n\t\n\treturn *min_element(dp[0].begin(), dp[0].end());\n}\nCherry Pickup II\nint fnc(int row, int c1, int c2, vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt;&amp; dp, vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint rows = grid.size();\n\tint cols = grid[0].size();\n\t\n\tif (c1 &lt; 0 || c1 &gt;= cols || c2 &lt; 0 || c2 &gt;= cols) return -1e8;\n\t\n\tif (row == rows - 1) {\n\t\tif (c1 == c2) return grid[row][c1];\n\t\treturn grid[row][c1] + grid[row][c2];\n\t}\n\t\n\tif (dp[row][c1][c2] != -1) return dp[row][c1][c2];\n\t\n\tint maxi = 0;\n\tfor (int delta1 = -1; delta1 &lt;= 1; ++delta1) {\n\t\tfor (int delta2 = -1; delta2 &lt;= 1; ++delta2) {\n\t\t\tint new_c1 = c1 + delta1;\n\t\t\tint new_c2 = c2 + delta2;\n\t\t\tint value = (c1 == c2 ? grid[row][c1] : grid[row][c1] + grid[row][c2]);\n\t\t\tvalue += fnc(row + 1, new_c1, new_c2, dp, grid);\n\t\t\tmaxi = max(maxi, value);\n\t\t}\n\t}\n\t\n\treturn dp[row][c1][c2] = maxi;\n}\n \nint cherryPickup(vector&lt;vector&lt;int&gt;&gt;&amp; grid) {\n\tint rows = grid.size();\n\tint cols = grid[0].size();\n\tvector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(rows, vector&lt;vector&lt;int&gt;&gt;(cols, vector&lt;int&gt;(cols, -1)));\n\t\n\treturn fnc(0, 0, cols - 1, dp, grid);\n}\nDP on Subsequences / Subsets\nSubsequences (non-contiguous)\nSubsets (contiguous)\nPartition Equal Subset Sum\nbool fnc (int i, int n, int s1, int s2, vector&lt;int&gt;&amp; nums) {\n\tif (i == n) {\n\t\tif (s1 == s2) return true; \n\t\telse return false;\n\t}\n\tint res1 = false, res2 = false;\n\tres1 = fnc (i+1, n, s1+nums[i], s2, nums);\n\tres2 = fnc (i+1, n, s1, s2+nums[i], nums);\n\t\n\treturn res1 || res2;\n}\n \nbool canPartition(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tif (n == 1) return false; \n\t\n\treturn fnc (1, n, nums[0], 0, nums);\n}\nrecursive\nbool fnc (int i, int n, int s1, int total, vector&lt;int&gt;&amp; nums, vector&lt;vector&lt;int&gt;&gt;&amp; dp) {\n\tif (i == n) {\n\t\tint s2 = total - s1;\n\t\tif (s1 == s2) return true; \n\t\telse return false;\n\t}\n\tif (dp[i][s1] != -1) return dp[i][s1]; \n\tint res1 = false, res2 = false;\n\tres1 = fnc (i+1, n, s1+nums[i], total, nums, dp);\n\tres2 = fnc (i+1, n, s1, total, nums, dp);\n\t\n\treturn dp[i][s1] = (res1 || res2);\n}\n \nbool canPartition(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tif (n == 1) return false;\n\t\n\tint total = accumulate(nums.begin(), nums.end(), 0);\n\tif (total % 2 != 0) return false;\n\t\n\tvector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(total+1, -1));\n\treturn fnc (1, n, nums[0], total, nums, dp);\n}"},"DSA_CP/DSA":{"slug":"DSA_CP/DSA","filePath":"DSA_CP/DSA.md","title":"DSA","links":["DSA_CP/"],"tags":[],"content":"index\nStriver sheet A2Z :\ntakeuforward.org/strivers-a2z-dsa-course/strivers-a2z-dsa-course-sheet-2/\nCP-31 sheet :\nwww.tle-eliminators.com/cp-sheet\nSiddh recommendation :\nyoukn0wwho.academy/topic-list\nStandard Questions :\nInterviewBit\nNeetCode\nAlgoMap\nCP-algorithms :\ncp-algorithms.com/\nCSES Problemset :\ncses.fi/problemset/\nCodeforces all useful blogs :\nI compiled a list of almost all useful blogs ever published on Codeforces [update: till 09.06.2021] - Codeforces\nYoutube channels :\nAbdul Bari - YouTube\nAlgorithms Conquered - YouTube\nCF Step - YouTube\nErrichto Algorithms - YouTube\nColin Galen - YouTube\nBinary Box - YouTube\nJapanese ICPC contest website :\nOI Wiki - OI Wiki (oi-wiki.org)\nKyopro Encyclopedia of Algorithms | Kyopro Encyclopedia of Algorithms (noshi91.github.io)\n\nTime and Space Complexity :\nLoveBabbar\n[Strivers A2Z DSA Course](www.youtube.com/watch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData TypeSize (in bytes)Rangeshort int2-32,768 to 32,767unsigned short int20 to 65,535unsigned int40 to 4,294,967,295int4-2,147,483,648 to 2,147,483,647long int4-2,147,483,648 to 2,147,483,647unsigned long int40 to 4,294,967,295long long int8-(2^63) to (2^63)-1unsigned long long int80 to 18,446,744,073,709,551,615signed char1-128 to 127unsigned char10 to 255float4-3.4√ó10^38 to 3.4√ó10^38double8-1.7√ó10^308 to1.7√ó10^308long double12-1.1√ó10^4932 to1.1√ó10^4932wchar_t2 or 41 wide character\nImportant Takeaways :\n\nNever manipulate input data unless told.\nNoramlly servers do 10^8 operations per sec. So 2s ‚áí 2*(10^8) operations\n\nBasics :\n#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n \nvoid doSomething(int &amp;num){ // pass by reference\n¬† ¬† num++;\n¬† ¬† cout &lt;&lt; &quot;doSomething : &quot; &lt;&lt; num &lt;&lt; endl;\n}\n \nvoid doNothing(int num){ // pass by value\n¬† ¬† num++;\n¬† ¬† cout &lt;&lt; &quot;doNothing : &quot; &lt;&lt; num &lt;&lt; endl;\n}\n \nint main(){\n\tint x, y;\n¬† ¬† cin &gt;&gt; x &gt;&gt; y ;\n¬† ¬† cout &lt;&lt; &quot;value of x: &quot; &lt;&lt; x &lt;&lt; &quot; and y: &quot; &lt;&lt; y &lt;&lt; endl;\n \n¬† ¬† string s1, s2;\n¬† ¬† cin &gt;&gt; s1 &gt;&gt; s2;\n¬† ¬† cout &lt;&lt; s1 &lt;&lt; &quot; &quot; &lt;&lt; s2 &lt;&lt; endl;\n \n¬† ¬† string str;\n¬† ¬† getline(cin, str); // to get full line as cin don&#039;t take after a space\n¬† ¬† cout &lt;&lt; str &lt;&lt; endl;\n¬† ¬† cout &lt;&lt; str[2] &lt;&lt; endl; // str char can also be accessed like array\n¬† ¬† cout &lt;&lt; str.size() &lt;&lt; endl; // find length of string\n¬† ¬† str[2] = &#039;A&#039;;\n¬† ¬† cout &lt;&lt; str &lt;&lt; endl;\n \n¬† ¬† // array elements are stored in linear fashion (next to each other) im memory\n¬† ¬† // 2D array ==&gt; arr[row][col]\n \n¬† ¬† int num = 7;\n¬† ¬† doNothing(num);\n¬† ¬† cout &lt;&lt; num &lt;&lt; endl;\n¬† ¬† doSomething(num);\n¬† ¬† cout &lt;&lt; num &lt;&lt; endl;\n¬† ¬† \n¬† ¬† // arrays are always passed as reference where address of first element (arr[0]) is passed\n  \n¬† ¬† return 0;\n}\nsort function:\n#include &lt;bits/stdc++.h&gt;\n#include &lt;algorithm&gt;\nusing namespace std;\n \nint main()\n{\n    int arr[] = {1,7,2,12,43,4,100};\n    int n = sizeof(arr)/sizeof(arr[0]);\n    \n    sort(arr, arr + n, [](int a, int b){\n        return a&gt;b;\n    });\n    \n    for(int x:arr){\n        cout &lt;&lt; x &lt;&lt; &quot; &quot;;\n    }\n    \n    return 0;\n}\n \n// OUTPUT:\n// 100 43 12 7 4 2 1\npriority queue:\n#include &lt;bits/stdc++.h&gt;\n#include &lt;algorithm&gt;\nusing namespace std;\n \nint main()\n{\n    priority_queue&lt;int&gt; pq;\n    \n    vector vec = {1,7,2,12,43,4,100};\n    \n    sort(vec.begin(), vec.end(), [](int a, int b){\n        return a&gt;b;\n    });\n    \n    for(int x:vec){\n        pq.push(x);\n    }\n    \n    for(int x:vec){\n        cout &lt;&lt; pq.top() &lt;&lt; &quot; &quot;;\n        pq.pop();\n    }\n    // 100 43 12 7 4 2 1\n    \n    return 0;\n}\nTime Complexity :\n\nTime Complexity != Time taken by code to run\nRate at which time taken for code changes  == Time Complexity\n\n\nTime Complexity has Best Case, Average Case, Worst Case\n\nNotations :\n\nBig O Notation               Worst Case\nTheta (Œ∏) Notation          Average Case\nOmega (Œ©) Notation       Best Case\n\nSpace Complexity :\n\nAuxiliary Space : Space required to solve problem\nInput Space : Space required by inputs\n\nint a; // Input Space\nint b; // Input Space\ncin &gt;&gt; a &gt;&gt; b;\nint c = a + b; // Auxiliary Space\ncout &lt;&lt; c;\nBit Manuplialtion :\nBitwise operations for beginners - Codeforces\nyoutu.be/LGrE0siZ-ZA\nEven or Odd :\nif (x%2 == 0)    // even\nif (x&amp;1 == 0)    // even (takes O(1) time dbetter way)\nas last bit of every even number is 0\nPower of 2:\na number which is power of 2 (4,8,16 etc...) have only one bit as 1 other bits are 0.\n2 = 10\n4 = 100\n8 = 1000\n16 = 10000 etc‚Ä¶\nif we do x-1\n1 = 01\n3 = 011\n7 = 0111\n15 = 01111\nso if we do x &amp; x-1 then we get 0 which means x is an power of 2.\n10000 ==&gt; 16\n&amp;\n01111 ==&gt; 15\n=\n00000 ==&gt; 0\n\nNote: but if x = 0 then we will get power of 2.\n\nCPP function to check if number is power of 2:\nbool powerof2(int x){\n\treturn x &amp;&amp; !( x&amp;(x-1) )\n}\nkth bit:\n1&lt;&lt;k = 2^k obviously, just observe above example\n\nToggle kth bit : x ^ (1&lt;&lt;k)\nSet kth bit (make kth bit 1) : x | (1&lt;&lt;k)\nUnset kth bit (make kth bit 0) : x &amp; ~(1&lt;&lt;k)\n\nHere ~ flip all the bits in a number.\nNote : for 1&lt;&lt;k, ~(1&lt;&lt;k) == (1&lt;&lt;k)-1\nMultiply or Divide a number by 2^k\n\nx * 2^k  = x&lt;&lt;k\nx / 2^k  = x&gt;&gt;k\n\nx % 2^k\nx % 2^k === x &amp; (2^k - 1) === x &amp; (1&lt;&lt;k - 1)\nx &amp; (1&lt;&lt;k - 1) here\n1&lt;&lt; k make 100000..\nand 1&lt;&lt;k - 1 makes  011111..\nnow if we do AND the we get only last k bits of x which represents remainder.\nSwap 2 numbers using bit manipulation\nx = x^y ‚áí x = x^y , y = y\ny = x^y ‚áí x = x^y , y = x^y^y = x\nx = x^y ‚áí x = x^y^x = y , y = x\nExtra Tricks\nif(x==a) x=b;\nelse if(x==b) x=a;\nthis same code can be written as\nx = a^b^x\nas if x = a then a and x cancel out and only b is left, same for a.\n\nNote :\nA+B = (A^B) + 2(A&amp;B)\nA+B = (A|B) + (A&amp;B)\n\nto find number of set bits in a number (x) ‚áí __buitin_popcount(x) for int and __builtin_popcountll(x) for long long\nbitmask :\n#include &lt;iostream&gt;\nusing namespace std;\n \nvoid solve(){\n    int a[20] = {1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20};\n    int s = 135, n = 20;\n    \n    cout &lt;&lt; (1&lt;&lt;n) &lt;&lt; endl;\n    \n    for(int mask = 1; mask &lt; (1&lt;&lt;n); mask++){\n        long long sum_of_this_subset = 0;\n        \n        for(int i = 0; i &lt; n; i++) {\n    \t\tif(mask &amp; (1 &lt;&lt; i)) {\n    \t\t\tsum_of_this_subset += a[i];\n    \t\t}\n    \t}\n    \t\n    \tif(sum_of_this_subset == s) {\n    \t\tcout&lt;&lt;&quot;YES&quot;;\n    \t\treturn;\n    \t}\n    }\n    cout &lt;&lt; &quot;NO&quot;;\n\treturn;\n}\n \nint main()\n{\n    solve();\n    return 0;\n}\n\nIn above code, 1 &lt;&lt; n == 2^n generates all subsets for the array.\nSo mask values iterates from 0 to 1048576 (2^n)\nthen we use mask as a map to guide us which element to take by &amp; operator checking for each bit if we want to take that element represented by i bit.\n\n\nTime Complexity : O(2^n * n)\n\nbitsets :\nint num = 5\nbitset&lt;64&gt;(num)  // 101\nlike __builtin_popcount() bitsets has num.count() and other bit operation also work on bitsets.\n2 pointers (squeeze)\nlet l = start and r = end be indices move l and r inside such that they squeeze and stop when l&lt;=r.\n2 Pointers Algorithm - DSA Course in Python Lecture 12\n// Print all continuous sub-arrays.\n \nll l=0, r=n-1;\n    \nwhile(l&lt;=r){\n\tfor(ll i=l; i&lt;=r; i++){\n\t\tcout &lt;&lt; arr[i] &lt;&lt; &quot; &quot;;\n\t}\n\tcout &lt;&lt; endl;\n\tif(l==r &amp;&amp; l&lt;=n-1){\n\t\tl++;\n\t\tr=n;\n\t}\n\tr--;\n};\nQuestion Patterns\n\n\nFast &amp; Slow Pointer\nDetect cycles\nO(1) space\nPerfect for linked list traps\n\n\nMerge Intervals\nSort + merge overlapping\nMust-know for calendar/booking apps\n\n\nSliding Window\nFixed/variable window\nO(n) time ‚Äî used in 100+ array/string problems\n\n\nMatrix Traversal / Islands\nDFS + BFS in 2D grids\nConnected components, flood fill, etc.\n\n\nTwo Pointers\nStart-end pointer strategy\nAvoids nested loops, speeds up logic\n\n\nCyclic Sort\nIdeal for finding missing numbers\nO(n) time, O(1) space\n\n\nIn-place Linked List Reversal\nReverse without extra memory\nKey for real-world pointer skills\n\n\nBFS (Breadth First Search)\nShortest path\nLevel-order problems\n\n\nDFS (Depth First Search)\nRecursion/backtracking\nTree/graph explorations\n\n\nTwo Heaps\nMedian from stream\nMin + Max heaps combo\n\n\nSubsets\nAll combinations\nPowerset problems\n\n\nModified Binary Search\nSearch in rotated or weird arrays\nO(log n) magic\n\n\nBitwise XOR\nFind missing or unique elements\nConstant space tricks\n\n\nTop K Elements\nUse heaps or quickselect\nRanking &amp; frequency problems\n\n\nK-way Merge\nCombine sorted arrays/lists\nMin-heap powered\n\n\n0/1 Knapsack (DP)\nPick or skip decisions\nBase of dynamic programming\n\n\nUnbounded Knapsack (DP)\nUse an item unlimited times\nLike coin change problems\n\n\nTopological Sort\nTask ordering\nDirected Acyclic Graphs\n\n\nMonotonic Stack\nNext greater/smaller element\nClean up O(n¬≤) to O(n)\n\n\nBacktracking\nTry ‚Üí Recurse ‚Üí Undo\nSubset, permutation, sudoku, N-Queens\n\n\nGreedy Algorithm\nFast, local best strategy\nWorks for interval, coin, and scheduling problems\n\n\nLCM\nint lcm(int a, int b) {\n    return (a / std::gcd(a, b)) * b;\n}\nMerge Sort\nvector&lt;int&gt; sorter(vector&lt;int&gt; p1, vector&lt;int&gt; p2) {\n\tvector&lt;int&gt; res;\n\t\n\tint ptr1 = 0;\n\tint ptr2 = 0;\n\twhile (ptr1&lt;p1.size() &amp;&amp; ptr2&lt;p2.size()) {\n\t\tif (p1[ptr1] &lt; p2[ptr2]) {\n\t\t\tres.push_back(p1[ptr1]);\n\t\t\tptr1++;\n\t\t} else {\n\t\t\tres.push_back(p2[ptr2]);\n\t\t\tptr2++;\n\t\t}\n\t}\n\t\n\twhile (ptr1 &lt; p1.size()) {\n\t\tres.push_back(p1[ptr1]);\n\t\tptr1++;\n\t}\n\t\n\twhile (ptr2 &lt; p2.size()) {\n\t\tres.push_back(p2[ptr2]);\n\t\tptr2++;\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; mergesort(vector&lt;int&gt; nums, int start, int end) {\n\tvector&lt;int&gt; res;\n\tif (start == end) { \n\t\tres.push_back(nums[start]);\n\t\treturn res;\n\t}\n\tint half = start+((end-start)/2);\n\tvector&lt;int&gt; p1 = mergesort(nums, start, half);\n\tvector&lt;int&gt; p2 = mergesort(nums, half+1, end);\n\treturn sorter(p1, p2);\n}\nQuestions\n\nCount inversions\nint merge(vector&lt;int&gt; &amp;arr, int low, int mid, int high) {\n    vector&lt;int&gt; temp; // temporary array\n    int left = low;      // starting index of left half of arr\n    int right = mid + 1;   // starting index of right half of arr\n\t\n    //Modification 1: cnt variable to count the pairs:\n    int cnt = 0;\n\t\n    //storing elements in the temporary array in a sorted manner//\n\t\n    while (left &lt;= mid &amp;&amp; right &lt;= high) {\n        if (arr[left] &lt;= arr[right]) {\n            temp.push_back(arr[left]);\n            left++;\n        }\n        else {\n            temp.push_back(arr[right]);\n            cnt += (mid - left + 1); //Modification 2\n            right++;\n        }\n    }\n\t\n    // if elements on the left half are still left //\n\t\n    while (left &lt;= mid) {\n        temp.push_back(arr[left]);\n        left++;\n    }\n\t\n    //  if elements on the right half are still left //\n    while (right &lt;= high) {\n        temp.push_back(arr[right]);\n        right++;\n    }\n\t\n    // transfering all elements from temporary to arr //\n    for (int i = low; i &lt;= high; i++) {\n        arr[i] = temp[i - low];\n    }\n\t\n    return cnt; // Modification 3\n}\n \nint mergeSort(vector&lt;int&gt; &amp;arr, int low, int high) {\n    int cnt = 0;\n    if (low &gt;= high) return cnt;\n    int mid = (low + high) / 2 ;\n    cnt += mergeSort(arr, low, mid);  // left half\n    cnt += mergeSort(arr, mid + 1, high); // right half\n    cnt += merge(arr, low, mid, high);  // merging sorted halves\n    return cnt;\n}\n \nint numberOfInversions(vector&lt;int&gt;&amp;a, int n) {\n    // Count the number of pairs:\n    return mergeSort(a, 0, n - 1);\n}\n \nint main()\n{\n    vector&lt;int&gt; a = {5, 4, 3, 2, 1};\n    int n = 5;\n    int cnt = numberOfInversions(a, n);\n    cout &lt;&lt; &quot;The number of inversions are: &quot;\n         &lt;&lt; cnt &lt;&lt; endl;\n    return 0;\n}\n\n\nXOR\n\nxor of two number is 0\nxor of 0 and number is number\nxor of a range (0 ‚Üí n)\n\nif (n%4 == 0) return n\nelse if (n%4 == 1) return 1\nelse if (n%4 == 2) return n+1\nelse return 0\n\n\n\nQuestions:\n\nall numbers appear twice except on number ‚áí xor of all numbers\nfind missing number in a range ‚áí  xor of (xor of all numbers) and (xor of range)\nFind repeating and missing number\n\nintuition is when we take range and array missing number appears once and repeating appears thrice so xor of both will give  repeating ^ missing\nthen we can group all numbers according to the bit that is different in the xor we got in 2\nthen take xor in both groups\n\nvector&lt;int&gt; findMissingRepeatingNumbers(vector&lt;int&gt; a) {\n    int n = a.size(); // size of the array\n\t\n    int xr = 0;\n\t\n    //Step 1: Find XOR of all elements:\n    for (int i = 0; i &lt; n; i++) {\n        xr = xr ^ a[i];\n        xr = xr ^ (i + 1);\n    }\n\t\n    //Step 2: Find the differentiating bit number:\n    int number = (xr &amp; ~(xr - 1));\n\t\n    //Step 3: Group the numbers:\n    int zero = 0;\n    int one = 0;\n    for (int i = 0; i &lt; n; i++) {\n        //part of 1 group:\n        if ((a[i] &amp; number) != 0) {\n            one = one ^ a[i];\n        }\n        //part of 0 group:\n        else {\n            zero = zero ^ a[i];\n        }\n    }\n\t\n    for (int i = 1; i &lt;= n; i++) {\n        //part of 1 group:\n        if ((i &amp; number) != 0) {\n            one = one ^ i;\n        }\n        //part of 0 group:\n        else {\n            zero = zero ^ i;\n        }\n    }\n\t\n    // Last step: Identify the numbers:\n    int cnt = 0;\n    for (int i = 0; i &lt; n; i++) {\n        if (a[i] == zero) cnt++;\n    }\n\t\n    if (cnt == 2) return {zero, one};\n    return {one, zero};\n}\n\n\nArray\nLongest subarray with sum k\nusing hashing:\nint getLongestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n    int n = nums.size();\n    unordered_map&lt;int, int&gt; mp;\n    int prefixsum = 0, res = 0;\n    \n    for (int i=0; i&lt;n; ++i) {\n        prefixsum += nums[i];\n        \n        if (prefixsum == k) {\n            res = max(res, i+1);\n        }\n        \n        if (mp.find(prefixsum-k) != mp.end()) {\n            res = max(res, i-mp[prefixsum-k]+1);\n        }\n        \n        if (mp.find(prefixsum) == mp.end()) {\n            mp[prefixsum] = i;\n        }\n    }\n    \n    return res;\n}\noptimal 2 pointers:\nint getLongestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n    int n = nums.size();\n    int res = 0, ptr1 = 0, ptr2 = 0;\n    int sum = 0;\n    \n    while (ptr2&lt;n) {\n        sum += nums[ptr2];\n        \n        while (sum &gt; k &amp;&amp; ptr1 &lt; ptr2) {\n            sum -= nums[ptr1];\n            ++ptr1;\n        }\n        \n        if (sum == k) {\n            res = max(res, ptr2-ptr1+1);\n        }\n        \n        ++ptr2;\n    }\n    \n    return res;\n}\n2 sum\n\nusing hashing:\n\nvector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n\tint n = nums.size();\n\tunordered_map&lt;int, int&gt; mp;\n\tfor (int i=0; i&lt;n; ++i) {\n\t\tmp[nums[i]] = i;\n\t}\n\t\n\tvector&lt;int&gt; res;\n\tfor (int i=0; i&lt;n; ++i) {\n\t\tif (mp.find(target-nums[i]) != mp.end()) {\n\t\t\tif (mp[target-nums[i]] != i) {\n\t\t\t\tres.push_back(mp[target-nums[i]]);\n\t\t\t\tres.push_back(i);\n\t\t\t\treturn res;\n\t\t\t} \n\t\t}\n\t}\n\t\n\treturn res;\n}\n\noptimal 2 pointers:\n\nvector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n\tint n = nums.size();\n\tsort(nums.begin(), nums.end());\n\tvector&lt;int&gt; res;\n\tint ptr1 = 0, ptr2 = n-1;\n\t\n\twhile (ptr1&lt;ptr2) {\n\t\tint sum = nums[ptr1]+nums[ptr2];\n\t\tif (sum == target) {\n\t\t\tres.push_back(nums[ptr1]);\n\t\t\tres.push_back(nums[ptr2]);\n\t\t\treturn res;\n\t\t}\n\t\t\n\t\tif (sum &gt; target) --ptr2;\n\t\telse ++ptr1;\n\t}\n\t\n\treturn res;\n}\nFind All Duplicates in an Array (Negative marking)\nbecause we are given that elements of array are in the range [0 .. n] we can uses elements as indexes\nfor every element in array mark it‚Äôs absolute index -1 representing that element has been taken\nvector&lt;int&gt; findDuplicates(vector&lt;int&gt;&amp; nums) {\n\tif(nums.size()==1) return {};\n\t// Negative marking\n\t// Whenever we meet the element we mark the value - 1 as negative\n\tvector&lt;int&gt; ans;\n\tfor(int i = 0; i&lt;nums.size(); i++) {\n\t\tif(nums[abs(nums[i])-1]&gt;0)\n\t\t\tnums[abs(nums[i])-1] *=-1; // Mark it with negative\n\t\telse\n\t\t\tans.push_back(abs(nums[i]));\n\t}\n\treturn ans;\n}\nKadane‚Äôs Algorithm\nfor each index we find max_sum till that index by greedily taking max of sum of current index and sum till now\nint maxSubArray(vector&lt;int&gt;&amp; nums) {\n\tint glo_max = nums[0], curr_sum = nums[0];\n\t\n\tfor (int i=1; i&lt;nums.size(); ++i) {\n\t\tcurr_sum = max(curr_sum, 0) + nums[i];\n\t\tglo_max = max(glo_max, curr_sum);\n\t}\n\t\n\treturn glo_max;\n}\nQuestions:\n\nfind the subarray with maximum sum\n\nDutch National flag Algorithm\nwe divide whole array in 3 parts and then start alloting according to the part‚Äôs definition\n\ninitalize low = 0, mid = 0 and high = arr.size()-1\n\n[0 .. low-1] ‚Üí 0‚Äôs\n[low .. mid-1] ‚Üí 1‚Äôs\n[high+1 .. arr.size()-1] ‚Üí 2‚Äôs\nso initially mid to high is our unsorted array i.e. 0 to arr.size()-1\n\n\nwhile (mid &lt;= high)\n\nif arr[mid] == 0\n\n‚áí swap mid and low\n‚áí mid++ and low++\n\n\nif arr[mid] == 1\n\n‚áí mid++\n\n\nif arr[mid] == 2\n\n‚áí swap mid and high\n‚áí if (high != 0) high‚Äî else break\n\nhere we don‚Äôt increase mid as after swap mid contains an unsorted number\n\n\n\n\n\n\n\nQuestions:\n\nSort an array of 0‚Äôs 1‚Äôs and 2‚Äôs\n\nStock Buy and Sell\n\nmaxPro = 0 and minPrice = INT_MAX\nfor each day price i\n\nminPrice = min(minPrice, arr[i])\nmaxPro = max(maxPro, arr[i] - minPrice)\n\n\nreturn maxPro\n\nMoore‚Äôs Voting Algorithm\nif an elements appears more than n/2 then while counting other elements will cancel the element but won‚Äôt be able to reduce majority element to 0 as it appears more than n/2\nfor n/2\n\nele = arr[0] and cnt = 1\nfor each index from 1 to arr.size()-1\n\nif (cnt == 0)\n\n‚áí ele = arr[i]\n‚áí cnt = 1\n\n\nelse\n\nif (arr[i] == ele)\n\n‚áí cnt++\n\n\nelse\n\n‚áí cnt--\n\n\n\n\n\n\nreturn ele\n\nfor n/3\n\nele1 = ele2 = INT_MIN and cnt1 = cnt2 = 0\nfor each index from 0 to arr.size()-1\n\nif (cnt1 == 0 &amp;&amp; arr[i] != ele2)\n\n‚áí ele1 = arr[i]\n‚áí cnt1 = 1\n\n\nelse if (cnt2 == 0 &amp;&amp; arr[i] != ele1)\n\n‚áí ele2 = arr[i]\n‚áí cnt2 = 1\n\n\nelse if (ele1 == arr[i])\n\n‚áí cnt1++\n\n\nelse if (ele1 == arr[i])\n\n‚áí cnt2++\n\n\nelse\n\n‚áí cnt1--\n‚áí cnt2--\n\n\n\n\nreturn ele\n\nQuestions:\n\nmajority element (more than n/2 times)\nmajority element (more than n/3 times)\n\nNext Permutation\nfor n length we have n! permutations\nObservations\n\n\nfor next permutation in sorted permutations array we need to have longest prefix match\n\n\nwe need to play with the slope of numbers in array\n\nwe need to find from back the first place where we see peak index\n\npeak index is where we see a number surrounded by two smaller numbers\n\n\n\n\n\nFor Example: [2, 1, 5, 4, 3, 0, 0]\n\n\nwe can see that 5 is peak index so we need to change 1 that is miss placed to increase the number for next permutation\n\n\nnow we can replace 1 with 5, 4 and 3 only as 0 is already smaller but we need number just greater than the current so we take 3 i.e. smallest greater element\n\n\nnow for the rest keep it as smaller as possible\n\n\n[2, 3, 0, 0, 1, 4, 5]\n\n\nlonger prefix match\n\nfor i = [arr.size()-2 .. 0]\n\nbreak_point = arr[i] &lt; arr[i+1]\nbreak\n\n\n\n\n\nfind element just greater than break_point\n\n\nfill the rest in sorted order\n\nreverse the arr from break_point to arr.size()-1\n\n\n\nLongest Consecutive Subsequence\n\ncreate an unordered_set of array\nfor each ele in unordered_set\n\ncheck if it is the starting point i.e. if ele-1 doesn‚Äôt exit then\n\nstart finding the next elements and counting\n\n\n\n\n\n3 Sum\nvector&lt;vector&lt;int&gt;&gt; triplet(int n, vector&lt;int&gt; &amp;arr) {\n    vector&lt;vector&lt;int&gt;&gt; ans;\n    sort(arr.begin(), arr.end());\n    for (int i = 0; i &lt; n; i++) {\n        //remove duplicates:\n        if (i != 0 &amp;&amp; arr[i] == arr[i - 1]) continue;\n\t\t\n        //moving 2 pointers:\n        int j = i + 1;\n        int k = n - 1;\n        while (j &lt; k) {\n            int sum = arr[i] + arr[j] + arr[k];\n            if (sum &lt; 0) {\n                j++;\n            }\n            else if (sum &gt; 0) {\n                k--;\n            }\n            else {\n                vector&lt;int&gt; temp = {arr[i], arr[j], arr[k]};\n                ans.push_back(temp);\n                j++;\n                k--;\n                //skip the duplicates:\n                while (j &lt; k &amp;&amp; arr[j] == arr[j - 1]) j++;\n                while (j &lt; k &amp;&amp; arr[k] == arr[k + 1]) k--;\n            }\n        }\n    }\n    return ans;\n}\nMerge Intervals\nvector&lt;vector&lt;int&gt;&gt; merge(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) {\n\tint n = intervals.size();\n\tsort(intervals.begin(), intervals.end());\n\tvector&lt;vector&lt;int&gt;&gt; merged_intervals;\n\tmerged_intervals.push_back(intervals[0]);\n\t\n\tfor (int i=1; i&lt;n; ++i) {\n\t\tvector&lt;int&gt;&amp; last = merged_intervals.back();\n\t\tif (last[1] &gt;= intervals[i][0]) {\n\t\t\t\n\t\t\tint ele1 = last[0];\n\t\t\tint ele2 = max(intervals[i][1], last[1]);\n\t\t\t\n\t\t\tmerged_intervals.pop_back();\n\t\t\tmerged_intervals.push_back({ele1, ele2});\n\t\t} else {\n\t\t\tmerged_intervals.push_back(intervals[i]);\n\t\t}\n\t}\n\t\n\treturn merged_intervals;\n}\nBinary Search\nupper lower bound\nint lower_bound(vector&lt;int&gt; nums, int x) {\n    int n = nums.size();\n    int l = 0, r = n-1;\n    int res = INT_MAX;\n    \n    while (l&lt;=r) {\n        int mid = (l+r) &gt;&gt; 1;\n        if (nums[mid] &gt; x) {\n            res = nums[mid];\n            r = mid-1;\n        } else if (nums[mid] &lt; x) {\n            l = mid+1;\n        } else {\n            res = nums[mid];\n            return res;\n        }\n    }\n    \n    return res;\n}\n \nint upper_bound(vector&lt;int&gt; nums, int x) {\n    int n = nums.size();\n    int l = 0, r = n-1;\n    int res = INT_MIN;\n    \n    while (l&lt;=r) {\n        int mid = (l+r) &gt;&gt; 1;\n        if (nums[mid] &lt; x) {\n            res = nums[mid];\n            l = mid+1;\n        } else if (nums[mid] &gt; x) {\n            r = mid-1;\n        } else {\n            res = nums[mid];\n            return res;\n        }\n    }\n    \n    return res;\n}\nSearch in Rotated Sorted Array\nif rotated then when applied binary search, it will divide array into two parts where\n\none part is sorted and other isn‚Äôt (sorted part will have corners in right order, here corners are low - mid and mid - high pointer)\ncheck if element lies in the sorted part\n\nFind any peak element index in an array\nuse the similar concept of slope and peak as used in binary search\nwrite cases when at start or end of array\nBinary Search on Answers find min or max\nfind the range of answers, the separating condition is always like after a certain element in range all further elements are either not possible or possible as answer\nKoko Eating Bananas\nlong long timeReq(vector&lt;int&gt;&amp; piles, int k){\n\tlong long time = 0;\n\tfor (int pile : piles) {\n\t\ttime += (pile + cap - 1) / cap;\n\t}\n\treturn time;\n}\n \nint minEatingSpeed(vector&lt;int&gt;&amp; piles, int h) {\n\tint n = piles.size();\n\tif (n==1) return ceil((double)piles[0]/(double)h);\n\t\n\tint high = *max_element(piles.begin(), piles.end());\n\tint low = 0;\n\t\n\twhile (low&lt;high) {\n\t\tint mid = low + (high-low)/2;\n\t\tlong long time_req = timeReq(piles, mid);\n\t\tif (time_req &lt;= h) {\n\t\t\thigh = mid;\n\t\t} else {\n\t\t\tlow = mid+1;\n\t\t}\n\t}\n\treturn low;\n}\nQuestions\n\nKoko Eating Bananas\nMinimum days to make M bouquets:\nFind the Smallest Divisor Given a Threshold\nCapacity To Ship Packages Within D Days\n\nKth Missing Positive Number\nint findKthPositive(vector&lt;int&gt;&amp; arr, int k) {\n\tif (k&lt;arr[0]) {\n\t\treturn k;\n\t}\n\tint n = arr.size()-1;\n\tif (k&gt;arr[n]) {\n\t\treturn k+(n+1);\n\t}\n\tint low = 0;\n\tint high = n;\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tint missing = arr[mid]-(mid+1); \n\t\tif (missing&lt;k) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t\t// cout &lt;&lt; low &lt;&lt; &quot; &quot; &lt;&lt; mid &lt;&lt; &quot; &quot; &lt;&lt; high &lt;&lt; endl;\n\t}\n\t\n\treturn k+high+1;\n}\nBinary Search on Answers find min(max) or max(min)\n\nmax(min) type¬†‚áí¬†return high\nmin(max) type¬†‚áí¬†return low\n\nAggressive Cows\nmax(min) type\nrange of answers is [1 .. max_distance_between_two_stalls]\nso apply binary search on this range and if for a given distance you could place cows then increase the distance otherwise decrease it\nbool canWePlaceCows (vector&lt;int&gt;&amp; stalls, int dist, int cows) {\n\tint n = stalls.size()-1;\n\tint cntCows = 1;\n\tint last = stalls[0];\n\t\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (stalls[i]-last &gt;= dist) {\n\t\t\tcntCows++;\n\t\t\tlast = stalls[i];\n\t\t}\n\t\tif (cntCows &gt;= cows) return true;\n\t}\n\t\n\treturn false;\n}\n \nint aggressiveCows(vector&lt;int&gt; &amp;stalls, int k) {\n\tsort(stalls.begin(), stalls.end());\n\t\n\tint n = stalls.size() - 1;\n\tint low = 1;\n\tint high = stalls[n] - stalls[0];\n\t\n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tif (canWePlaceCows(stalls, mid, k)) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\treturn high;\n}\nAllocate Minimum Number of Pages\nmin(max) type\nmaximum number of pages assigned to a student is minimum\nso range of answers is [max_pages .. sum_of_all_pages]\nso apply binary search on this range and if for a given capacity of allocation of pages you could allot all books then increase the capacity otherwise decrease it\nbool canAllotPage(vector&lt;int&gt;&amp; pageNumbers, int m, int capacity) {\n\tint n = pageNumbers.size()-1;\n\tint alloted = 0;\n\tint currSum = 0;\n\tfor (int i=0; i&lt;=n; i++) {\n\t\tif (currSum+pageNumbers[i] &gt; capacity) {\n\t\t\talloted++;\n\t\t\tcurrSum = pageNumbers[i];\n\t\t} else {\n\t\t\tcurrSum += pageNumbers[i];\n\t\t}\n\t}\n\tcout &lt;&lt; capacity &lt;&lt; &quot; &quot; &lt;&lt; currSum &lt;&lt; &quot; &quot; &lt;&lt; alloted &lt;&lt; endl;\n\tif (alloted &gt;= m) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}\n \nint allocatePages(vector&lt;int&gt;&amp; pageNumbers, int m) {\n\tint n = pageNumbers.size() - 1;\n\tif (m &gt; (n+1)) return -1;\n\tint low = *max_element(pageNumbers.begin(), pageNumbers.end());\n\tint high = accumulate(pageNumbers.begin(), pageNumbers.end(), 0);\n\t \n\twhile (low&lt;=high) {\n\t\tint mid = (low+high)/2;\n\t\tcout &lt;&lt; low &lt;&lt; &quot;-&quot; &lt;&lt; mid &lt;&lt; &quot;-&quot; &lt;&lt; high &lt;&lt; endl;\n\t\tif (canAllotPage(pageNumbers, m, mid)) {\n\t\t\tlow = mid+1;\n\t\t} else {\n\t\t\thigh = mid-1;\n\t\t}\n\t}\n\treturn low;\n}\nQuestions\nmin(max) type\n\nAllocate Minimum Number of Pages\nSplit Array - Largest Sum\nPainter‚Äôs Partition Problem\nMinimize Maximum Distance between Gas Stations\n\nStrings\nLongest Palindromic Substring\ntreat each character (single for odd length and two for even length) as a potential center of a palindrome and expand outward to find the longest palindrome\nLinked List\nMiddle element in a Linked List\n\ntwo pointer fast and slow such that fast moves 2 * slows\nso in O(N/2) we can find middle element.\n\nthis method can be used to find nth element from array too by moving fast += n and slow += 1\nReverse a linked list (iterative)\nListNode* reverseList(ListNode* head) {\n\tListNode* prev = nullptr;\n\tListNode* next = head;\n\tListNode* curr = head;\n\t\n\twhile (next!=nullptr) {\n\t\tnext = curr-&gt;next;\n\t\tcurr-&gt;next = prev;\n\t\tprev = curr;\n\t\tcurr = next;\n\t}\n\t\n\treturn prev;\n}\nDetect Loop in Linked List using 2 pointer (fast and slow)\n\ninside loop, slow move by 1 and fast by 2\nso each iteration causes distance between them to reduce by 1\neventually slow catch up and is at same node as fast which signifies that LL has loop\n\nFind Starting point of Loop in Linked List (fast and slow)\n\nIf distance from starting of Linked List to starting of Loop is¬†d,\nthen the collision point of fast and slow is always mid point of loop,\nwhich is¬†d¬†so:\nhead¬†‚áê d ‚áí¬†loop starting¬†‚áê d ‚áí¬†collision point¬†‚áê d ‚áí¬†loop starting\n\nRecursion\nSubsets II\narray has duplicate elements but the power set must not contain duplicate subsets\n\nsort the array\nstart a recursion where we carry a data structure\nadd unique elements from array to data structures and call recursion again\nnote that here we each recursion level have data structure of same length\n\nvoid findSubsets(int pos, vector&lt;int&gt;&amp; nums, vector&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds){\n\tans.push_back(ds);\n\tfor (int i=pos; i&lt;nums.size(); i++){\n\t\tif(i!=pos &amp;&amp; nums[i] == nums[i-1]) continue;\n\t\tds.push_back(nums[i]);\n\t\tfindSubsets(i+1, nums, ans, ds);\n\t\tds.pop_back();\n\t}\n}\n \nvector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) {\n\tvector&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\t\n\tsort(nums.begin(), nums.end());\n\tfindSubsets(0, nums, ans, ds);\n\t\n\treturn ans;\n}\nCombination Sum\nall subsequences that sum up to target and each element can be selected multiple times\n\nstart a recursion where we carry a data structure\nwe can either pick element at pos or not pick\n\nvoid find_combinations (int pos, int target, vector&lt;int&gt;&amp; candidates, vector&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds) {\n\tif (pos == candidates.size()) {\n\t\tif (target == 0){\n\t\t\tans.push_back(ds);\n\t\t}\n\t\treturn;\n\t}\n\t\n\tif (candidates[pos] &lt;= target) {\n\t\tds.push_back(candidates[pos]);\n\t\t// taking the same element again\n\t\tfind_combinations(pos, target - candidates[pos], candidates, ans, ds);\n\t\t// after backtracking if this branch final ds does not sum up to target we pop back the element\n\t\tds.pop_back();\n\t}\n\t\n\t// taking the next element\n\tfind_combinations(pos+1, target, candidates, ans, ds);\n}\n \nvector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) {\n\tvector&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\t\n\tfind_combinations(0, target, candidates, ans, ds);\n\treturn ans;\n}\nCombination Sum II\nall subsequences that sum up to target and each element can be selected only once\n\nstart a recursion where we carry a data structure\nwe can either pick element at pos or not pick, but we can‚Äôt stay at same pos after processing it\nuse a set to store answers\n\nvoid find_unique_combinations (int pos, int target, vector&lt;int&gt;&amp; candidates, set&lt;vector&lt;int&gt;&gt;&amp; ans, vector&lt;int&gt;&amp; ds) {\n\tif (pos == candidates.size()) {\n\t\tif (target == 0){\n\t\t\tif (ans.find(ds) == ans.end()) {\n\t\t\t\tans.insert(ds);\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n\t\n\tif (candidates[pos] &lt;= target) {\n\t\tds.push_back(candidates[pos]);\n\t\tfind_unique_combinations(pos+1, target - candidates[pos], candidates, ans, ds);\n\t\tds.pop_back();\n\t}\n\t\n    find_unique_combinations(pos+1, target, candidates, ans, ds);\n}\n \nvector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt; &amp;candidates, int target) {\n\tset&lt;vector&lt;int&gt;&gt; ans;\n\tvector&lt;int&gt; ds;\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tsort(candidates.begin(), candidates.end());\n\tfind_unique_combinations(0, target, candidates, ans, ds);\n\tfor (auto i : ans) {\n\t\tres.push_back(i);\n\t}\n\t\n\treturn res;\n}\nBit Manipulation\n\nToggle kth bit: x ^ (1&lt;&lt;k)\nSet kth bit (make kth bit 1): x | (1&lt;&lt;k)\nUnset kth bit (make kth bit 0): x &amp; ~(1&lt;&lt;k)\nRemove the last set bit (rightmost): x &amp; (x-1)\n\nXOR from 1 to n (follows a pattern)\nint xor_till_n(int n) {\n\tif (n%4 == 0) return n;\n\telse if (n%4 == 1) return 1;\n\telse if (n%4 == 2) return n+1;\n\telse return 0;\n}\nSingle Number II\nall numbers appear thrice except one that appear once\nsol :- ones store numbers that appear once, if a number appear second time we store it in twos so, twos store numbers that appear twice and if number appear thrice we remove it from twos\n\nnow think that all thrice appearing numbers are together at start and last one is the answer (it‚Äôs for understanding but it all works out for any order because we are dealing with bits)\nnow first we check if new number is not in twos (as not of number and number is zero) and if it‚Äôs not in twos we add it in ones by xor (so that when we get second time it deletes and if it‚Äôs first time xor of 0 and number occurs leading to number)\nnow check if new number is already in ones\n\nint singleNumber(vector&lt;int&gt;&amp; nums) {\n\tint ones = 0;\n\tint twos = 0;\n\t\n\tfor (const int num : nums) {\n\t\tones ^= (num &amp; ~twos);\n\t\ttwos ^= (num &amp; ~ones);\n\t}\n\t\n\treturn ones;\n}\nGenerate a Power set i.e all subsets i.e. all subsequences of an array\nouter loop from 0 to 2^n generates masks\ninner loop iterate through each bit in mask and if bit is 1 then take element from nums from that position.\nwe use mask as a map to guide us which element to take by &amp; operator checking for each bit if we want to take that element represented by i bit.\nvector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;vector&lt;int&gt;&gt; subsets;\n\t\n\tfor (long long mask=0; mask&lt;(1&lt;&lt;n); mask++) {\n\t\tvector&lt;int&gt; curr;\n\t\tfor (int j=0; j&lt;n; j++) {\n\t\t\tif (mask &amp; (1&lt;&lt;j)) {\n\t\t\t\tcurr.push_back(nums[j]);\n\t\t\t}\n\t\t}\n\t\tsubsets.push_back(curr);\n\t}\n\treturn subsets;\n}\nStacks and Queue\nStack using Queue\nclass Stack_using_Queue {\n\tqueue&lt;int&gt; q;\n\t\n\tpublic:\n\t\tvoid Push(int n) {\n\t\t\tq.push(n);\n\t\t\tfor (int i=0; i&lt;q.size()-1; i++) {\n\t\t\t\tq.push(q.front());\n\t\t\t\tq.pop();\n\t\t\t}\n\t\t}\n\t\t\n\t\tint Pop() {\n\t\t\tint temp = q.front();\n\t\t\tq.pop();\n\t\t\treturn temp;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\treturn q.front();\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn q.size();\n\t\t}\n};\nQueue using Stack\nclass Queue_using_Stack {\n\tstack&lt;int&gt; s1, s2;\n\t\n\tpublic:\n\t\tvoid Push(int n) {\n\t\t\twhile (!s1.empty()) {\n\t\t\t\ts2.push(s1.top());\n\t\t\t\ts1.pop();\n\t\t\t}\n\t\t\ts2.push(n);\n\t\t\twhile (!s2.empty()) {\n\t\t\t\ts1.push(s2.top());\n\t\t\t\ts2.pop();\n\t\t\t}\n\t\t}\n\t\t\n\t\tint Pop() {\n\t\t\tint temp = s1.top();\n\t\t\ts1.pop();\n\t\t\treturn temp;\n\t\t}\n\t\t\n\t\tint Top() {\n\t\t\treturn s1.top();\n\t\t}\n\t\t\n\t\tint Size() {\n\t\t\treturn s1.size();\n\t\t}\n};\nMonotonic Stack/Queue problems\nNext greater element\n\nstart from end\nkeep stack in ascending order and if a number is &gt; top then remove from stack till we can place it in ascending order\n\nvector&lt;int&gt; nextGreaterElement(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) {\n\tint n = nums2.size()-1;\n\tunordered_map&lt;int, int&gt; reference;\n\tstack&lt;int&gt; nge;\n\t\n\tfor (int i=n; i&gt;=0; i--) {\n\t\twhile (!nge.empty() &amp;&amp; (nge.top() &lt; nums2[i])) {\n\t\t\tnge.pop();\n\t\t}\n\t\tif (nge.empty()) {\n\t\t\treference[nums2[i]] = -1;\n\t\t} else {\n\t\t\treference[nums2[i]] = nge.top();\n\t\t}\n\t\tnge.push(nums2[i]);\n\t}\n\t\n\tvector&lt;int&gt; res(nums1.size(), -1);\n\tfor (int i=0; i&lt;nums1.size(); i++) {\n\t\tres[i] = reference[nums1[i]];\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) {\n    int n = nums2.size() - 1;\n    unordered_map&lt;int, int&gt; reference;\n    stack&lt;int&gt; nse;\n\t\n    for (int i = n; i &gt;= 0; i--) {\n        while (!nse.empty() &amp;&amp; nse.top() &gt;= nums2[i]) {\n            nse.pop();\n        }\n        if (nse.empty()) {\n            reference[nums2[i]] = -1;\n        } else {\n            reference[nums2[i]] = nse.top();\n        }\n        nse.push(nums2[i]);\n    }\n\t\n    vector&lt;int&gt; res(nums1.size(), -1);\n    for (int i = 0; i &lt; nums1.size(); i++) {\n        res[i] = reference[nums1[i]];\n    }\n\t\n    return res;\n}\nTrapping Rain Water\nfor any arr[i] we know it can store water above it of height min(leftMax, rightMax) - arr[i]\nso for each position we need to find the maximum height on both sides of that position, which is equal to prefixMax and suffixMax, but finding all max would take O(N) for both prefix and suffix.\nwe can take 2 pointer each pointing to the max.\n\nprefixMax suffixMax method\n\nint trap(vector&lt;int&gt;&amp; arr) {\n\tint n = arr.size();\n\t\n\tint prefix[n], suffix[n];\n\tprefix[0] = arr[0];\n\tfor (int i = 1; i &lt; n; i++) {\n\t\tprefix[i] = max(prefix[i - 1], arr[i]);\n\t}\n\tsuffix[n - 1] = arr[n - 1];\n\tfor (int i = n - 2; i &gt;= 0; i--) {\n\t\tsuffix[i] = max(suffix[i + 1], arr[i]);\n\t}\n\t\n\tint waterTrapped = 0;\n\tfor (int i = 0; i &lt; n; i++) {\n\t\twaterTrapped += min(prefix[i], suffix[i]) - arr[i];\n\t}\n\t\n\treturn waterTrapped;\n}\n\nusing 2 pointer\n\nint trap(vector&lt;int&gt;&amp; height) {\n\tint n = height.size();\n\tint waterTrapped = 0; \n\tint leftMax = 0, rightMax = 0;\n\tint l=0, r=n-1;\n\t\n\twhile (l&lt;r) {\n\t\tif (height[l] &lt;= height[r]) {\n\t\t\tif (leftMax &gt; height[l]) {\n\t\t\t\twaterTrapped += leftMax - height[l]; \n\t\t\t} else {\n\t\t\t\tleftMax = height[l];\n\t\t\t}\n\t\t\tl = l+1;\n\t\t} else {\n\t\t\tif (rightMax &gt; height[r]) {\n\t\t\t\twaterTrapped += rightMax - height[r];\n\t\t\t} else {\n\t\t\t\trightMax = height[r];\n\t\t\t}\n\t\t\tr = r-1;\n\t\t}\n\t}\n\t\n\treturn waterTrapped;\n}\nSum of subarray minimums\n\nfind after how many elements we get next smallest\nthen PnC\n\nvector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; nse;\n\t\n\tfor (int i=n-1; i&gt;=0; i--) {\n\t\twhile (!nse.empty() &amp;&amp; (nums[nse.top()] &gt;= nums[i])) {\n\t\t\tnse.pop();\n\t\t}\n\t\tif (nse.empty()) {\n\t\t\tres[i] = n;\n\t\t} else {\n\t\t\tres[i] = nse.top();\n\t\t}\n\t\tnse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; prevSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; pse;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!pse.empty() &amp;&amp; (nums[pse.top()] &gt; nums[i])) {\n\t\t\tpse.pop();\n\t\t}\n\t\tif (pse.empty()) {\n\t\t\tres[i] = -1;\n\t\t} else {\n\t\t\tres[i] = pse.top();\n\t\t}\n\t\tpse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nint sumSubarrayMins(vector&lt;int&gt;&amp; arr) {\n\tint n = arr.size();\n\tint mod = 1e9+7;\n\tlong long res = 0;\n\t\n\tvector&lt;int&gt; nse = nextSmallerElement(arr);\n\tvector&lt;int&gt; pse = prevSmallerElement(arr);\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tint left = i-pse[i];\n\t\tint right = nse[i]-i;\n\t\tres = (res + (right * left * (long long)1 * arr[i]) % mod) % mod; \n\t}\n\t\n\treturn res;\n}\nSum of subarray ranges\n \nLargest Rectangle in Histogram\n\nto find the width for a height i we need the smallest previous and smallest next\nthen maximum area by that heighti is heights[i] * (nse[i]-pse[i]-1)\n\nvector&lt;int&gt; nextSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; nse;\n\t\n\tfor (int i=n-1; i&gt;=0; i--) {\n\t\twhile (!nse.empty() &amp;&amp; (nums[nse.top()] &gt;= nums[i])) {\n\t\t\tnse.pop();\n\t\t}\n\t\tif (nse.empty()) {\n\t\t\tres[i] = n;\n\t\t} else {\n\t\t\tres[i] = nse.top();\n\t\t}\n\t\tnse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nvector&lt;int&gt; prevSmallerElement(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tvector&lt;int&gt; res(n, -1);\n\tstack&lt;int&gt; pse;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\twhile (!pse.empty() &amp;&amp; (nums[pse.top()] &gt;= nums[i])) {\n\t\t\tpse.pop();\n\t\t}\n\t\tif (pse.empty()) {\n\t\t\tres[i] = -1;\n\t\t} else {\n\t\t\tres[i] = pse.top();\n\t\t}\n\t\tpse.push(i);\n\t}\n\t\n\treturn res;\n}\n \nint largestRectangleArea(vector&lt;int&gt;&amp; heights) {\n\tint res = 0;\n\tvector&lt;int&gt; pse = prevSmallerElement(heights);\n\tvector&lt;int&gt; nse = nextSmallerElement(heights);\n\t\n\tfor (int i=0; i&lt;heights.size(); i++) {\n\t\tres = max(res, (heights[i]*(nse[i] - pse[i]-1)));\n\t}\n\t\n\treturn res;\n}\nSliding Window and 2 Pointers\ncount subarrays with sum equal to k which is solved by using an unordered_map of prefix sums so that we can in O(1) search if we have encountered curr_sum - goal sum and if we have then we can directly add it‚Äôs count to ans\nThis method takes O(N) time and O(N) space too, but we can also sum elements with Sliding Window using 2 pointers.\nbut here‚Äôs the catch, in Sliding Window we continuously move the end pointer and updates start upon reaching a condition,\nIn this question we would shrink the window (start++, curr_sum -= nums[start]) as soon as curr_sum == goal. This assumes only one subarray ending at end has sum goal, but multiple subarrays can end at end with the same sum due to different combinations of 1s and 2s.\nExample: nums = [1,1,2], goal = 4.\nSubarrays [1,1,2] (sum = 1+1+2 = 4) and [1,2] (sum = 1+2 = 3, but we will miss this because we shrink the window after finding [1,1,2]).\nThis approach counts only one subarray per window.\nSliding Window (using at most k to find exactly k)\nSubarrays with K Different Integers\nint subarraysWithAtMostKDistinct(vector&lt;int&gt;&amp; nums, int k) {\n\tint n = nums.size();\n\tint l=0, r=0, res=0;\n\tunordered_map&lt;int, int&gt; mp;\n\t\n\twhile (r &lt; n) {\n\t\tmp[nums[r]]++;\n\t\t\n\t\t// shrink window till less than k\n\t\twhile (mp.size() &gt; k) {\n\t\t\tmp[nums[l]]--;\n\t\t\tif (mp[nums[l]] == 0) {\n\t\t\t\tmp.erase(nums[l]);\n\t\t\t}\n\t\t\tl++;\n\t\t}\n\t\t\n\t\t// total valid subarray with &lt;=k distinct elements are all elements\n\t\t// till r so length of a window == new valid subarrays\n\t\tres += r-l+1;\n\t}\n\t\n\treturn res;\n}\n \nint subarraysWithKDistinct(vector&lt;int&gt;&amp; nums, int k) {\n\treturn (subarraysWithAtMostKDistinct(nums, k) - subarraysWithAtMostKDistinct(nums, k-1));\n}\nHeap (Priority Queue)\nTask Scheduler\n\nwhile priority queue is not empty {\n\ngreedly allot n distinct elements if not possible then add idle\nreplace the alloted elements in priority_queue with a decrement in frequency\n\n\n}\n\nint leastInterval(vector&lt;char&gt;&amp; tasks, int n) {\n\tint time = 0;\n\t\n\tunordered_map&lt;char, int&gt; mp;\n    for (char c : tasks) {\n        mp[c]++;\n    }\n    \n    priority_queue&lt;pair&lt;int, char&gt;&gt; pq;\n    for (auto [c, f] : mp) {\n        pq.push({f, c});\n    }\n\t\n    while (!pq.empty()) {\n        vector&lt;pair&lt;int, char&gt;&gt; temp;\n        int cycle = n + 1; // Maximum tasks in one cycle\n        while (cycle &gt; 0 &amp;&amp; !pq.empty()) {\n            auto [f, c] = pq.top();\n            pq.pop();\n            if (f &gt; 1) {\n                temp.push_back({f - 1, c}); // Decrement frequency\n            }\n            time++; // One task scheduled\n            cycle--;\n        }\n        // Restore tasks for next cycle\n        for (auto p : temp) {\n            pq.push(p);\n        }\n        // Add idle time if queue is not empty\n        if (!pq.empty()) {\n            time += cycle;\n        }\n    }\n\t\n\treturn time;\n}\nOptimal:\n\nfind the number of elements required to fill the max number of elements\nthen fill it with other task and order don‚Äôt matter\n\nint leastInterval(vector&lt;char&gt;&amp; tasks, int n) {\n    vector&lt;int&gt; freq(26, 0); // Step 1: Frequency array for tasks A-Z\n\t\n    for (auto x : tasks) {\n        freq[x - &#039;A&#039;]++; // Step 2: Count frequency of each task\n    }\n\t\n    sort(freq.begin(), freq.end(), greater&lt;int&gt;()); // Step 3: Sort frequencies in descending order\n\t\n    int gap = (freq[0] - 1) * n; // Step 4: Calculate initial gaps (idle slots)\n\t\n    for (int i = 1; i &lt; freq.size(); i++) { // Step 5: Fill gaps with other tasks\n        gap = gap - min(freq[0] - 1, freq[i]);\n    }\n\t\n    return tasks.size() + max(0, gap); // Step 6: Return total time\n}\nFind Median from Data Stream\nclass MedianFinder {\n    priority_queue&lt;int&gt; maxpq; // largest at top so, numbers &lt; median\n    priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; minpq;  // smallest at top so, numbers &gt; median\npublic:\n    MedianFinder() {}\n    \n    void addNum(int num) {\n        // Push to appropriate heap\n        if (maxpq.empty() || num &lt;= maxpq.top()) {\n            maxpq.push(num);\n        } else {\n            minpq.push(num);\n        }\n\t\t\n        // Balance heaps\n        if (maxpq.size() &gt; minpq.size()+1) {\n            minpq.push(maxpq.top());\n            maxpq.pop();\n        } else {\n            if (minpq.size() &gt; maxpq.size()) {\n                maxpq.push(minpq.top());\n                minpq.pop();\n            }\n        }\n    }\n    \n    double findMedian() {\n        // if equal size find mean of mids\n        if (maxpq.size() == minpq.size()) {\n            return ((maxpq.top() + minpq.top()) / 2.0); \n        } else {\n            return maxpq.top();\n        }\n    }\n};\nGreedy\nValid Parenthesis String\nbool checkValidString(string s) {\n\tint min_open = 0;   // &#039;*&#039; acts as &#039;)&#039;\n\tint max_open = 0;   // &#039;*&#039; acts as &#039;(&#039;\n\tfor (char c : s) {\n\t\tif (c == &#039;(&#039;) {\n\t\t\tmin_open++;\n\t\t\tmax_open++;\n\t\t} else if (c == &#039;)&#039;) {\n\t\t\tmin_open--;\n\t\t\tmax_open--;\n\t\t\tif (max_open &lt; 0) return false;\n\t\t\tif (min_open &lt; 0) min_open = 0;\n\t\t} else {\n\t\t\tmin_open--;\n\t\t\tmax_open++;\n\t\t\tif (min_open &lt; 0) min_open = 0;\n\t\t}\n\t}\n\treturn min_open == 0;\n}\nJump Game\nonly problem is when we encounter 0 as if all positive numbers we can definetly reach end by even one one jumps\nkeep track of max u can reach so that if any point you encounter a i that you can‚Äôt reach/cross-over in any way then return false\nbool canJump(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tint max_reach = 0;\n\t\n\tfor (int i=0; i&lt;n; i++) {\n\t\tif (i &gt; max_reach) {\n\t\t\treturn false;\n\t\t}\n\t\tmax_reach = max(i+nums[i], max_reach);\n\t}\n\t\n\treturn true;\n}\nJump Game II\nfind minimum number of jumps\nwe keep track of range l -&gt; r where we can reach\nint jump(vector&lt;int&gt;&amp; nums) {\n\tint n = nums.size();\n\tint cnt = 0, l = 0, r = 0;\n\t\n\twhile (r &lt; n-1) {\n\t\tint max_reach = 0;\n\t\tfor (int i=l; i&lt;=r; i++) {\n\t\t\tmax_reach = max(i+nums[i], max_reach);\n\t\t}\n\t\tl = r+1;\n\t\tr = max_reach;\n\t\tcnt++;\n\t}\n\t\n\treturn cnt;\n}\nCandy\nBrute Force:\n\nfind minimum number of candies that satisfies from left\nfind minimum number of candies that satisfies from right\nmaximum of both would satisfy both\n\nint candy(vector&lt;int&gt;&amp; ratings) {\n\tint n = ratings.size();\n\tint cnt = 0;\n\tvector&lt;int&gt; l(n, 0);\n\tvector&lt;int&gt; r(n, 0);\n\tl[0] = 1;\n\tr[n-1] = 1;\n\t\n\tfor (int i=1; i&lt;n; i++) {\n\t\tif (ratings[i] &gt; ratings[i-1]) {\n\t\t\tl[i] = l[i-1]+1;\n\t\t} else {\n\t\t\tl[i] = 1;\n\t\t}\n\t}\n\t\n\tfor (int i=n-2; i&gt;=0; i--) {\n\t\tif (ratings[i] &gt; ratings[i+1]) {\n\t\t\tr[i] = r[i+1]+1;\n\t\t} else {\n\t\t\tr[i] = 1;\n\t\t}\n\t}\n\t\n\tint sum = 0;\n\tfor (int i=0; i&lt;n; i++) {\n\t\tsum += max(l[i], r[i]);\n\t}\n\t\n\treturn sum;\n}\nOptimal: Peaks\nwe know peaks would have the largest number of candies so if we can find peaks then we can give every candies accordingly.\nmain observation ‚áí sum from top of peak == sum from bottom of peak, so after reaching peak we can start alloting from 1 to bottom then compare bottom candies and peak and take maximum of them.\nint candy(vector&lt;int&gt;&amp; ratings) {\n\tint n = ratings.size();\n\tint sum=1, i=1;\n\twhile (i&lt;n) {\n\t\tif (ratings[i] == ratings[i-1]) {\n\t\t\tsum++; \n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tint peak = 1;\n\t\twhile (i&lt;n &amp;&amp; ratings[i] &gt; ratings[i-1]) {\n\t\t\tpeak++;\n\t\t\tsum += peak;\n\t\t\ti++;\n\t\t}\n\t\tint down = 1;\n\t\twhile (i&lt;n &amp;&amp; ratings[i] &lt; ratings[i-1]) {\n\t\t\tsum += down;\n\t\t\tdown++;\n\t\t\ti++;\n\t\t}\n\t\t\n\t\tif (down &gt; peak) {\n\t\t\tsum += down-peak;\n\t\t}\n\t}  \n\treturn sum;\n}\nNon-overlapping Intervals\n\nsort according to end time\nincrease counter if end time for a interval is smaller than it‚Äôs previous one\n\nBinary Trees\nTypes:\n\nFull BT                ‚Üí either 2 or 0 children\nComplete BT      ‚Üí all levels except last have 0 or children, last level / leaf nodes should be as left as possible\nPerfect BT          ‚Üí all leaf nodes are at same level\nBalanced BT       ‚Üí height of tree must be less than equal to log(N)\nDegenerate BT   ‚Üí each node has a single child (basically a linked list)\n\nTraversal:\n\nDepth First Technique (DFS):\n\nInorder       (Left Root Right)\nPreorder    (Root Left Right)\nPostorder  (Left Right Root)\n\n\nBreadth First Technique (BFS):\nvisit all nodes at a level before moving to next\n\nVertical Order Traversal of a Binary Tree\nvector&lt;vector&lt;int&gt;&gt; verticalTraversal(TreeNode* root) {\n\tvector&lt;vector&lt;int&gt;&gt; res;\n\tif (root == nullptr) return res;\n\t\n\tqueue&lt;pair&lt;TreeNode*, pair&lt;int, int&gt;&gt;&gt; q;\n\tmap&lt;int, map&lt;int, priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; &gt;&gt; mp;\n\tq.push({root, {0, 0}});\n\t\n\twhile (!q.empty()) {\n\t\tint size = q.size();\n\t\t\n\t\tfor (int i=0; i&lt;size; i++) {\n\t\t\tauto [node, cords] = q.front();\n\t\t\tint row = cords.first;\n\t\t\tint col = cords.second;\n\t\t\tq.pop();\n\t\t\tmp[col][row].push(node-&gt;val);\n\t\t\t\n\t\t\tif (node-&gt;left != nullptr) {\n\t\t\t\tq.push({node-&gt;left, {row+1, col-1}});\n\t\t\t}\n\t\t\tif (node-&gt;right != nullptr) {\n\t\t\t\tq.push({node-&gt;right, {row+1, col+1}});\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (auto&amp; [col, temp]: mp) {\n\t\tvector&lt;int&gt; vals;\n\t\tfor (auto&amp; [row, pq]: temp) {\n\t\t\twhile (!pq.empty()) {\n\t\t\t\tvals.push_back(pq.top());\n\t\t\t\tpq.pop();\n\t\t\t}\n\t\t}\n\t\tres.push_back(vals);\n\t}\n\t\n\treturn res;\n}\nLowest Common Ancestor (LCA)\n\nfind path from root to that node and return the first common occurrence\n\nbool root_to_node_path(TreeNode* node, int val, vector&lt;TreeNode*&gt;&amp; path) {\n\tif (node == nullptr) return false;\n\t\n\tpath.push_back(node);\n\tif (node-&gt;val == val) return true;\n\tif (root_to_node_path(node-&gt;left, val, path) || root_to_node_path(node-&gt;right, val, path)) {\n\t\treturn true;\n\t}\n\t\n\tpath.pop_back();\n\treturn false;\n}\n \nTreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) {\n\tvector&lt;TreeNode*&gt; v1, v2;\n\tbool t1 = root_to_node_path(root, p-&gt;val, v1);\n\tbool t2 = root_to_node_path(root, q-&gt;val, v2);\n\t\n\tTreeNode* res = nullptr;\n\tint mini = min(v1.size(), v2.size());\n\tfor (int i=0; i&lt;mini; i++) {\n\t\tcout &lt;&lt; v1[i]-&gt;val &lt;&lt; &quot; &quot; &lt;&lt; v2[i]-&gt;val &lt;&lt; endl;\n\t\tif (v1[i] == v2[i]) {\n\t\t\tres = v1[i];\n\t\t}\n\t}\n\t\n\treturn res;\n}"},"DSA_CP/Striver-Sheet-in-Rust":{"slug":"DSA_CP/Striver-Sheet-in-Rust","filePath":"DSA_CP/Striver Sheet in Rust.md","title":"Striver Sheet in Rust","links":["DSA_CP/"],"tags":[],"content":"index\nBasics\nPrint your Name N times using recursion\nfn solve(i:i32, n:i32){\n    if i==n{\n        return;\n    } else {\n        println!(&quot;hello&quot;);\n        solve(i+1, n);\n    }\n}\n \nfn main() {\n    solve(0,3);\n}\nPrint from 1 to N using Recursion\nfn solve(i:i32, n:i32){\n    if i==n{\n        return;\n    } else {\n        println!(&quot;{}&quot;, i);\n        solve(i+1, n);\n    }\n}\n \nfn main() {\n    solve(0,3);\n}\nPrinting integers from N to 1 (using Backtracking)\nfn solve(i:i32, n:i32){\n    if i==n{\n        return;\n    } else {\n        solve(i+1, n);\n        println!(&quot;{}&quot;, i);\n    }\n}\n \nfn main() {\n    solve(0,3);\n}\nRecursive way of calculating the sum of first N Natural Numbers:\n\n\nParameterized Way\nfn solve(i:i32, sum:i32){\n    if i==0{\n        println!(&quot;{}&quot;, sum);\n        return;\n    } else {\n        solve(i-1, sum+i);\n    }\n}\n \nfn main() {\n    solve(5,0);\n}\n\n\nFunctional Way\nfn solve(i:i32) -&gt; i32 {\n    if i==0{\n        return 0;\n    } else {\n        return i + solve(i-1);\n    }\n}\n \nfn main() {\n    println!(&quot;{}&quot;, solve(5));\n}\n\n\nReverse an array\nfn main() {\n    let mut v = vec![1, 2, 3, 4, 5];\n    v.reverse();\n    println!(&quot;{:?}&quot;, v);\n}\nGiven String is Palindrome or not\nuse basics::*;\n \nfn main() {\n    let input = take_string_as_vec();\n    let mut ispalin = true;\n    let mut ptr1= 0;\n    let mut ptr2 = input.len()-1;\n    let mut i = 0;\n    while i&lt;=(input.len()&gt;&gt;1) {\n        if input[ptr1] != input[ptr2] {\n            ispalin = false;\n            break\n        }\n        ptr1+=1;\n        ptr2-=1;\n        i+=1;\n    }\n    println!(&quot;{}&quot;, ispalin);\n}\nHashMap (unordered map)\nRust uses ahash by default\nGiven an array of integers: [1, 2, 1, 3, 2] and we are given some queries: [1, 3, 4, 2, 10]. For each query, we need to find out how many times the number appears in the array.\nuse std::collections::HashMap;\n \nfn main() {\n    let arr = vec![1, 2, 1, 3, 2];\n    let queries = vec![1, 3, 4, 2, 10];\n\t\n    let mut freq_map = HashMap::&lt;i32, usize&gt;::new();\n\t\n    for num in arr {\n        *(freq_map.entry(num).or_insert(0)) += 1;\n    }\n\t\n    for query in queries {\n        let result = freq_map.get(&amp;query);\n        let mut count=0;\n        match result {\n            Some(&amp;num) =&gt; count = num,\n            None =&gt; count = 0\n        }\n        println!(&quot;{} appears {} times&quot;, query, count);\n    }\n\t\n\t// Instead of matching the Option returned from get we could have used\n\t// unwrap but it doesn&#039;t work on &amp;{integer} so we can use .copied() that\n\t// converts and `Option&lt;&amp;usize&gt;` into `Option&lt;usize&gt;` \n\tfor query in queries {\n\t\tlet count = freq_map.get(&amp;query).copied().unwrap_or(0);\n\t    println!(&quot;{} appears {} times&quot;, query, count);\n    }\n}\nGiven an array of size N. Find the highest and lowest frequency element.\ncan use Moore‚Äôs Voting Algorithm too to find highest frequency element\nuse std::collections::HashMap;\n \nfn main() {\n    let arr = vec![1, 2, 1, 3, 2];\n    let mut freq_map = HashMap::&lt;i32, usize&gt;::new();\n    \n    for num in arr {\n        *freq_map.entry(num).or_insert(0) += 1;\n    }\n\t\n    let mut min_freq = usize::MAX;\n    let mut max_freq = usize::MIN;\n    let mut min_ele = 0;\n    let mut max_ele = 0;\n\t\n    for (&amp;num, &amp;count) in &amp;freq_map {\n        if count &lt; min_freq {\n            min_freq = count;\n            min_ele = num;\n        }\n        if count &gt; max_freq {\n            max_freq = count;\n            max_ele = num;\n        }\n    }\n\t\n    for key_value in &amp;freq_map {\n        println!(&quot;{} appears {} times&quot;, *key_value.0, *key_value.1);\n    }\n\t\n    println!(&quot;Maximum frequency element is {} with {} frequency&quot;, max_ele, max_freq);\n    println!(&quot;Minimum frequency element is {} with {} frequency&quot;, min_ele, min_freq);\n}\nSorting\nRust uses TimSort by default which takes O(nlogn)\nSelection Sort\nuse basics::*;\n \nfn main() {\n    let mut arr = take_vector_int();\n    let n = arr.len();\n\t\n    for i in 0..n {\n        let mut min = i;\n        for j in i+1..n {\n            if arr[j] &lt; arr[i] {\n                min = j;\n            }\n        }\n        let temp = arr[i];\n        arr[i] = arr[min];\n        arr[min] = temp;\n    }\n\t\n    for i in arr{\n        print!(&quot;{} &quot;, i);\n    }\n}\nBubble sort\nuse basics::*;\n \nfn main() {\n    let mut arr = take_vector_int();\n    let n = arr.len();\n\t\n    for i in 0..n {\n        for j in i+1..n {\n            if arr[j] &lt; arr[j-1] {\n                let temp = arr[j];\n                arr[j] = arr[j-1];\n                arr[j-1] = temp;\n            }\n        }\n    }\n\t\n    for i in arr{\n        print!(&quot;{} &quot;, i);\n    }\n}\nInsertion Sort\nuse basics::*;\n \nfn main() {\n    let mut arr = take_vector_int();\n    let n = arr.len();\n\t\n    for i in 1..n {\n        if arr[i] &lt; arr[i-1] {\n            for j in (1..=i).rev() {\n                if arr[j] &lt; arr[j-1] {\n                    let temp = arr[j];\n                    arr[j] = arr[j-1];\n                    arr[j-1] = temp;\n                } \n            }\n        }\n    }\n\t\n    for i in arr{\n        print!(&quot;{} &quot;, i);\n    }\n}\nMerge Sort\npub fn merge_sort(arr:Vec&lt;usize&gt;) -&gt; Vec&lt;usize&gt;{\n    let len = arr.len();\n    if len &lt;=1 {\n        return arr\n    }\n    let mid = len/2;\n\t\n    let arr1 = merge_sort(arr[..mid].to_vec());\n    let arr2 = merge_sort(arr[mid..].to_vec());\n    merge(arr1, arr2) \n}\n \npub fn merge(arr1:Vec&lt;usize&gt;, arr2:Vec&lt;usize&gt;) -&gt; Vec&lt;usize&gt; {\n    let mut arr3 = Vec::&lt;usize&gt;::new();\n\t\n    let mut i = 0;\n    let mut j = 0;\n    while i &lt; arr1.len() &amp;&amp; j &lt; arr2.len(){\n        if arr1[i] &lt; arr2[j] {\n            arr3.push(arr1[i]);\n            i+=1;\n        } else {\n            arr3.push(arr2[j]);\n            j+=1;\n        }\n    }\n\t\n    arr3.extend_from_slice(&amp;arr1[i..]);\n    arr3.extend_from_slice(&amp;arr2[j..]);\n\t\n    arr3\n}\n \nfn main() {\n    let arr = take_vector_int();\n\t\n    let sorted = merge_sort(arr);\n\t\n    for i in sorted{\n        print!(&quot;{} &quot;, i);\n    }\n}\nArrays\nCheck for rotated sorted array\npub fn check(nums: Vec&lt;i32&gt;) -&gt; bool {\n\tlet mut drop_count = 0;\n\tlet l = nums.len();\n\t\n\tfor i in 0..l {\n\t\tif nums[i] &gt; nums[(i + 1) % l] {\n\t\t\tdrop_count += 1;\n\t\t}\n\t}\n\tlet is_sorted_or_rotated = drop_count &lt;= 1;\n\tis_sorted_or_rotated\n}\nremove duplicates\npub fn remove_duplicates(nums: &amp;mut Vec&lt;i32&gt;) -&gt; i32 {\n\tlet l = nums.len();\n\tlet mut i = 0;\n\tfor j in 1..l{\n\t\tif nums[i] != nums[j]{\n\t\t\ti += 1;\n\t\t\tnums[i] = nums[j];\n\t\t}\n\t}\n\t(i+1) as i32\n}\nrotate array by k places:\npub fn rotate(nums: &amp;mut Vec&lt;i32&gt;, k: i32) {\n\tlet var = k as usize;\n\tlet l = nums.len();\n\tlet r = (var % l);\n\t\n\tlet temp = nums[(l-r)..].to_vec();\n\tnums.truncate(l-r);\n\tnums.splice(0..0, temp);\n}\nmove zeros to end:\nlet mut left = 0;\nfor right in 0..nums.len() {\n\tprintln!(&quot;{}, {}&quot;, left, right);\n\tif nums[right] != 0 {\n\t\tnums.swap(left, right);\n\t\tleft += 1;\n\t}\n\tprintln!(&quot;{:?}&quot;, nums);\n}\nfind missing number in a range\npub fn missing_number(nums: Vec&lt;i32&gt;) -&gt; i32 {\n\tlet l = nums.len();\n\tlet mut xor1 = 0;\n\tlet xor2 = match l%4 {\n\t\t0 =&gt; l,\n\t\t1 =&gt; 1,\n\t\t2 =&gt; l + 1,\n\t\t_ =&gt; 0,\n\t} as i32;\n\tfor i in nums {\n\t\txor1 ^= i;\n\t}\n\txor1^xor2\n}\nUsing  prefix sum array, subarray with maximum sum, return sum\npub fn max_sub_array(nums: Vec&lt;i32&gt;) -&gt; i32 {\n\tlet l = nums.len();\n\t\n\tif l == 1{\n\t\treturn nums[0]\n\t}\n\t\n\tlet mut sums:Vec&lt;i32&gt; = vec![0; l];\n\tsums[0] = nums[0];\n\tfor i in 1..l {\n\t\tsums[i] = sums[i-1]+nums[i];\n\t}\n\t\n\tlet mut max_ele = sums[0];\n\tlet mut min_ele = 0;\n\tfor i in sums {\n\t\tmax_ele = max_ele.max(i-min_ele);\n\t\tmin_ele = min_ele.min(i);\n\t}\n\treturn max_ele\n}\nKadane‚Äôs Algorithm for subarray with maximum sum, return sum\npub fn max_sub_array(nums: Vec&lt;i32&gt;) -&gt; i32 {\n\tlet l = nums.len();\n\t\n\tlet mut max = nums[0];\n\tlet mut sum = nums[0];\n\tfor i in 1..l{\n\t\tsum = sum.max(0) + nums[i];\n\t\tmax = max.max(sum);\n\t}\n\treturn max\n}\nTwo Sum, sum of two elements in an array is equal to target\nuse std::collections::HashMap;\n \nimpl Solution {\n    pub fn two_sum(nums: Vec&lt;i32&gt;, target: i32) -&gt; Vec&lt;i32&gt; {\n        let l = nums.len();\n        let mut pos = Vec::new();\n        let mut map = HashMap::new();\n        \n        for i in 0..l {\n            map.insert(nums[i], i);\n        }\n \n        for i in 0..l {\n            match map.get(&amp;(target-nums[i])) {\n                Some(value) =&gt; {\n                    if *value!= i {\n                        pos.push(i as i32);\n                        pos.push(*value as i32);\n                        break\n                    }\n                },\n                None =&gt; {}\n            }\n        }\n        pos\n    }\n}\nDutch National flag algorithm, Sort an array of 0‚Äôs 1‚Äôs and 2‚Äôs\npub fn sort_colors(nums: &amp;mut Vec&lt;i32&gt;) {\n\tlet l = nums.len();\n \n\tlet mut low = 0;\n\tlet mut mid = 0;\n\tlet mut high = l-1;\n \n\twhile mid&lt;=high {\n\t\tif nums[mid] == 0{\n\t\t\tnums.swap(low, mid);\n\t\t\tmid += 1;\n\t\t\tlow += 1;\n\t\t} else if nums[mid] == 1 {\n\t\t\tmid += 1;\n\t\t} else {\n\t\t\tnums.swap(mid, high);\n\t\t\tif high !=0 {\n\t\t\t\thigh -= 1;\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t} \n}\nMoore‚Äôs Voting Algorithm, majority element\npub fn majority_element(nums: Vec&lt;i32&gt;) -&gt; i32 {\n\tlet l = nums.len();\n\t\n\tlet mut ele = nums[0];\n\tlet mut cnt = 1;\n\tfor i in 1..l {\n\t\tif cnt == 0 {\n\t\t\tele = nums[i];\n\t\t\tcnt += 1;\n\t\t} else {\n\t\t\tif nums[i] == ele {\n\t\t\t\tcnt += 1;\n\t\t\t} else {\n\t\t\t\tcnt -= 1;\n\t\t\t}\n\t\t}\n\t}\n\tele\n}\nNext Permutation\nlet mut nums = take_vector_int();\nlet l = nums.len();\n \n// Step 1: Find the break point:\nlet mut ind = l + 1; // break point\nfor i in (0..l - 2).rev() {\n\tif nums[i] &lt; nums[i + 1] {\n\t\tprintln!(&quot;{}, {}&quot;, nums[i], nums[i + 1]);\n\t\tind = i;\n\t\tbreak;\n\t}\n}\n \n// If break point does not exist means we are at highest permutation:\nif ind == l+1 {\n\tnums.reverse();\n} else {\n\tprintln!(&quot;{}, {}&quot;, ind, nums[ind]);\n \n\t// Step 2: Find the next greater element\n\t//         and swap it with arr[ind]:\n\tfor i in (0..l - 1).rev() {\n\t\tif nums[i] &gt; nums[ind] {\n\t\t\tnums.swap(ind, i);\n\t\t\tprintln!(&quot;{:?}&quot;, nums);\n\t\t\tbreak;\n\t\t}\n\t}\n \n\t// Step 3: reverse the right half:\n\tnums[ind + 1..].reverse();\n}\nprintln!(&quot;{:?}&quot;, nums);\nLongest Consecutive Subsequence\nuse basics::*;\nuse std::collections::HashSet;\n \nfn main() {\n    let mut nums = take_vector_int();\n    let l = nums.len();\n \n    let mut set = HashSet::new();\n    for i in 0..l {\n        set.insert(nums[i]);\n    }\n \n    println!(&quot;{:?}&quot;, set);\n    let mut longest = 0;\n    let mut cnt = 1;\n    for &amp;i in &amp;set {\n        if !set.contains(&amp;(i-1)){\n            let mut j = i+1;\n            loop {\n                if set.contains(&amp;j) {\n                    cnt += 1;\n                    j += 1; \n                } else {\n                    longest = longest.max(cnt);\n                    cnt = 1;\n                    break\n                }\n            }\n        }\n    }\n    longest = longest.max(cnt);\n    println!(&quot;{}&quot;, longest);\n}\nRotate a square matrix\n90 = transpose + reverse row\n180 = reverse row + reverse col\n270 = transpose + reverse col\nfor 90 :\nlet mut matrix = [[5,1,9,11],[2,4,8,10],[13,3,6,7],[15,14,12,16]];\n \nlet l = matrix.len();\n// Transpose of a matrix\nfor i in 0..l {\n\tfor j in i+1..l {\n\t\tprintln!(&quot;{}, {}&quot;, i, j);\n\t\tlet temp = matrix[i][j];\n\t\tmatrix[i][j] = matrix[j][i];\n\t\tmatrix[j][i] = temp;\n\t}\n}\nprintln!(&quot;{:?}&quot;, matrix);\n \n// Reverse the rows\nfor i in 0..l/2 {\n\tlet k = l-1-i;\n\tprintln!(&quot;{}&quot;, k);\n\tfor j in 0..l {\n\t\tprintln!(&quot;{}, {} swap with {}, {}&quot;, j, i, j, k);\n\t\tlet temp = matrix[j][i];\n\t\tmatrix[j][i] = matrix[j][k];\n\t\tmatrix[j][k] = temp;\n\t}\n}\n \nprintln!(&quot;{:?}&quot;, matrix);\nSpiral matrix\n pub fn spiral_order(matrix: Vec&lt;Vec&lt;i32&gt;&gt;) -&gt; Vec&lt;i32&gt; {\n\tlet m = matrix.len();\n\tlet n = matrix[0].len();\n \n\tlet mut ans = Vec::new();\n\tlet mut top = 0;\n\tlet mut right = n-1;\n\tlet mut bottom = m-1;\n\tlet mut left = 0;\n \n\twhile top &lt;= bottom &amp;&amp; left &lt;= right {\n \n\t\tfor i in left..=right {\n\t\t\tans.push(matrix[top][i]);\n\t\t}\n\t\ttop += 1;\n \n\t\tfor i in top..=bottom {\n\t\t\tans.push(matrix[i][right]);\n\t\t}\n\t\tif right == 0 { break; }\n\t\tright -= 1;\n \n\t\tif top &lt;= bottom {\n\t\t\tfor i in (left..=right).rev() {\n\t\t\t\tans.push(matrix[bottom][i]);\n\t\t\t}\n\t\t\tif bottom == 0 { break; }\n\t\t\tbottom -= 1;\n\t\t}\n \n\t\tif left &lt;= right {\n\t\t\tfor i in (top..=bottom).rev() {\n\t\t\t\tans.push(matrix[i][left]);\n\t\t\t}\n\t\t\tleft += 1;\n\t\t}\n\t}\n \n\tans\n}\nPascal‚Äôs Triangle\npub fn generate(num_rows: i32) -&gt; Vec&lt;Vec&lt;i32&gt;&gt; {\n\tlet mut ans = Vec::&lt;Vec&lt;i32&gt;&gt;::new();\n\tfor row in 1..=num_rows as usize {\n\t\tans.push(vec![1]);\n\t\tlet mut ele = 1;\n\t\t\n\t\tfor col in 1..row {\n\t\t\tele = ele*(row-col);\n\t\t\tele = ele/col;\n\t\t\tans[row-1].push(ele as i32);\n\t\t}\n\t}\n\tans\n}\nExtended Boyer Moore‚Äôs Voting Algorithm\nuse std::i32::MIN;\n \nimpl Solution {\n    pub fn majority_element(nums: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {\n        let l = nums.len();\n        let mut ans = Vec::new();\n\t\t\n        let mut cnt1 = 0;\n        let mut cnt2 = 0;\n        let mut ele1 = MIN;\n        let mut ele2 = MIN;\n\t\t\n        for i in 0..l {\n            if cnt1==0 &amp;&amp; ele2!=nums[i] {\n                ele1 = nums[i];\n                cnt1 = 1;\n            } else if cnt2==0 &amp;&amp; ele1!=nums[i] {\n                ele2 = nums[i];\n                cnt2 = 1;\n            } else if ele1 == nums[i] {\n                cnt1+=1;\n            } else if ele2 == nums[i] {\n                cnt2+=1;\n            } else {\n                cnt1-=1;\n                cnt2-=1;\n            }\n        }\n\t\t\n        cnt1 = 0;\n        cnt2 = 0;\n\t\t\n        for i in 0..l{\n            if nums[i] == ele1 {\n                cnt1+=1;\n            }\n            if nums[i] == ele2 {\n                cnt2+=1;\n            }\n        }\n\t\t\n        if cnt1 &gt; l/3 {\n            ans.push(ele1);\n        }\n        if cnt2 &gt; l/3 {\n            ans.push(ele2);\n        }\n\t\t\n        ans\n    }\n}\n3 Sum, using 3 pointers\nlet mut nums = take_vector_int();\nlet l = nums.len();\n \nlet mut ans = Vec::&lt;Vec&lt;i32&gt;&gt;::new(); \nnums.sort();\nlet mut i = 0;\nwhile i&lt;l-2 {\n\tlet mut j = i+1;\n\tlet mut k = l-1;\n\tif i&gt;0 &amp;&amp; nums[i] == nums[i-1] {\n\t\ti += 1;\n\t} else {\n\t\twhile j&lt;k {\n\t\t\tlet sum = nums[i]+nums[j]+nums[k];\n\t\t\tif sum &lt; 0 {\n\t\t\t\tj+=1;\n\t\t\t} else if sum &gt; 0 {\n\t\t\t\tk-=1;\n\t\t\t} else {\n\t\t\t\tans.push(vec![nums[i], nums[j], nums[k]]);\n\t\t\t\tj+=1;\n\t\t\t\tk-=1;\n\t\t\t\twhile j&lt;k &amp;&amp; nums[j] == nums[j-1] {\n\t\t\t\t\tj+=1;\n\t\t\t\t}\n\t\t\t\twhile j&lt;k &amp;&amp; nums[k] == nums[k+1] {\n\t\t\t\t\tk-=1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\ti+=1;\n\t}\n}\n \nprintln!(&quot;{:?}&quot;, ans);\n4 Sum, using 4 pointer (similar to 3 Sum)\npub fn four_sum(mut nums: Vec&lt;i32&gt;, target: i32) -&gt; Vec&lt;Vec&lt;i32&gt;&gt; {\n\tlet l = nums.len();\n\tlet mut ans = Vec::&lt;Vec&lt;i32&gt;&gt;::new(); \n\t\n\tif l&lt;4 {\n\t\treturn ans;\n\t} \n\tif l == 4 {\n\t\tlet mut sum:i64 = 0;\n\t\tfor i in 0..4 {\n\t\t\tsum += nums[i] as i64;\n\t\t}\n\t\tif sum == target as i64 {\n\t\t\tans.push(vec![nums[0], nums[1], nums[2], nums[3]]);\n\t\t}\n\t\treturn ans;\n\t}\n\t\n\tnums.sort();\n\tlet mut i = 0;\n\twhile i&lt;l-3 {\n\t\tlet mut j = i+1;\n\t\tif i&gt;0 &amp;&amp; nums[i] == nums[i-1]{\n\t\t\ti+=1;\n\t\t} else {\n\t\t\twhile j &lt; l-2 {\n\t\t\t\tlet mut k = j+1;\n\t\t\t\tlet mut m = l-1;\n\t\t\t\tif j&gt;i+1 &amp;&amp; nums[j] == nums[j-1] {\n\t\t\t\t\tj += 1;\n\t\t\t\t} else {\n\t\t\t\t\twhile k&lt;m {\n\t\t\t\t\t\tlet sum:i64 = (nums[i]+nums[j]+nums[k]+nums[m]) as i64;\n\t\t\t\t\t\tif sum &lt; target as i64 {\n\t\t\t\t\t\t\tk+=1;\n\t\t\t\t\t\t} else if sum &gt; target as i64 {\n\t\t\t\t\t\t\tm-=1;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tans.push(vec![nums[i], nums[j], nums[k], nums[m]]);\n\t\t\t\t\t\t\tk+=1;\n\t\t\t\t\t\t\tm-=1;\n\t\t\t\t\t\t\twhile k&lt;m &amp;&amp; nums[k] == nums[k-1] {\n\t\t\t\t\t\t\t\tk+=1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\twhile k&lt;m &amp;&amp; nums[m] == nums[m+1] {\n\t\t\t\t\t\t\t\tm-=1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tj+=1;\n\t\t\t\t}\n\t\t\t}\n\t\t\ti+=1;\n\t\t}\n\t}\n \n\tans\n}\nLength of the longest subarray with zero Sum\nuse basics::*;\nuse std::collections::HashMap;\n \nfn main() {\n    let mut nums = take_vector_int();\n    let l = nums.len();\n \n    let mut max = 0;\n    let mut sum = 0;\n    let mut map = HashMap::&lt;i32, usize&gt;::new();\n    \n    for i in 0..l{\n        sum += nums[i];\n        if sum == 0 {\n            max = i+1;\n        } else {\n            if let Some(&amp;idx) = map.get(&amp;sum) {\n                max = max.max(i-idx);\n            } else {\n                map.insert(sum, i);\n            }\n        }\n    }\n \n    println!(&quot;{}&quot;, max);\n}\nCount the number of subarrays with given xor K\nlet mut arr = take_vector_int();\nlet mut k = take_int();\n \nlet l = arr.len();\n \nlet mut map = HashMap::&lt;i32, usize&gt;::new();\nlet mut cnt = 0;\nlet mut x = 0;\n \nfor i in 0..l {\n\tx ^= arr[i];\n\tif x == k {\n\t\tcnt+=1;\n\t} else {\n\t\tif let Some(&amp;c) = map.get(&amp;(x^k)) {\n\t\t\tcnt+=c;\n\t\t} else {\n\t\t\t*map.entry(x).or_insert(0) += 1;\n\t\t}\n\t}\n}\n \nprintln!(&quot;{}&quot;, cnt);\nXOR Queries of a Subarray\npub fn xor_queries(arr: Vec&lt;i32&gt;, queries: Vec&lt;Vec&lt;i32&gt;&gt;) -&gt; Vec&lt;i32&gt; {\n\tlet l = arr.len();\n \n\tlet mut x = Vec::&lt;i32&gt;::new();\n\tx.push(arr[0]);\n \n\tfor i in 1..l {\n\t\tx.push(x[i-1]^arr[i]);\n\t}\n \n\tlet mut ans = Vec::new();\n \n\tfor q in queries {\n\t\tif q[0] == 0 {\n\t\t\tans.push(x[q[1] as usize]);\n\t\t} else {\n\t\t\tans.push( x[q[1] as usize]^x[(q[0]-1) as usize] )\n\t\t}\n\t}\n\t\n\tans\n}"},"DSA_CP/index":{"slug":"DSA_CP/index","filePath":"DSA_CP/index.md","title":"index","links":["/"],"tags":[],"content":"Home"},"Ethical-Hacking":{"slug":"Ethical-Hacking","filePath":"Ethical Hacking.md","title":"Ethical Hacking","links":["/"],"tags":[],"content":"Home\nOverTheWire: Wargames\nEthical Hacking :\nEthical hacking techniques - DEV Community\nTypes :\nWhat Are The Five Steps Of Ethical Hacking? - DEV Community\n\n\nSocial engineering : exploit human psychology, rather than technical security gaps to gain access to data and applications. They trick legitimate users into submitting their passwords or installing malicious software that grants them access to network machines and services.\n\n\nWeb application hacking :\nVulnerabilities that manipulate the application :\n\nCross-Site Scripting\nCross-Site Request Forgery\nInsecure configuration\nInjection attacks\n\n\n\nHacking wireless networks\n\n\nSystem hacking (hacking personal computer and servers)\n\n\n¬†Crashtest Security¬†offers a comprehensive suite of testing tools that help you identify threats within your application.\nMethods :\nEthical hacking techniques - DEV Community\n\npredictive analytics models is one of the main uses of AI and ML in cybersecurity. These models look for trends and abnormalities that can point to a potential security problem by analyzing data from a range of sources, including network traffic, user behaviour, and system logs.\nInternet of Things testing‚Äôs objective is to identify any security flaws in IoT hardware, communication protocols, and the networks they use by network mapping, device identification, firmware analysis, penetration testing, and vulnerability scanning.\nSocial engineering attacks, such as phishing and pretexting\nRed teaming involves simulating a real-world attack scenario to identify potential vulnerabilities and test an organization‚Äôs incident response capabilities.\nBug bounty programs allow organizations to incentivize ethical hackers to identify potential vulnerabilities in their systems and report them in exchange for a reward.\n\nSteps :\n\n\nReconnaissance : hacker documents the organization‚Äôs request, finds valuable configuration and login information of the system, and probes the networks.\nInformations such as :\n\nNaming conventions\nServices on the network\nServers handling workloads in the network\nIP Addresses\nNames and Login credentials of users connected to the network\nPhysical location of target machine\n\n\n\nPenetration testing :\n\nNetwork Mapping : This involves discovering the network topology, including host information, servers, routers, and firewalls within the host network. Once mapped, white hat hackers can visualize and strategize the next steps of the ethical hacking process.\nPort Scanning : Ethical hackers use automated tools to identify any open ports on the network. This makes it an efficient mechanism to enumerate the services and live systems in a network, and how to establish a connection with these components.\nVulnerability Scanning : The use of automated tools to detect weaknesses that can be exploited to orchestrate attacks.\nTools for scanning :\n\nSNMP Sweepers\nPing sweeps\nNetwork mappers\nVulnerability scanners\n\n\n\n\n\nGaining Access : Attempting to send a malicious payload to the application through the network, an adjacent subnetwork, or physically using a connected computer.\nTools to simulate attempted unauthorized access,\n\nBuffer overflows\nPhishing\nInjection attacks\nXML External Entity processing\nUsing components with known vulnerabilities.\n\nIf the attacks are successful, the hacker has control of the whole or part of the system and may simulate further attacks such as data¬†breaches¬†and Distributed Denial of Service (DDoS).\n\n\nMaintaining Access : ¬†involves processes used to ensure the hacker can access the application for future use. A white-hat hacker continuously exploits the system for further vulnerabilities and¬†escalates privileges¬†to understand how much control attackers can gain once they get past security clearance. Some attackers may also try to hide their identity by removing any evidence of an attack and installing a backdoor for future access.\n\n\nClearing Tracks : To avoid any evidence that leads back to their malicious activity, hackers perform tasks that erase all traces of their actions.\nThis includes :\n\nUninstalling scripts/applications used to carry out attacks\nModifying registry values\nClearing logs\nDeleting folders created during the attack\nFor those hackers looking to maintain undetected access, they tend to hide their identity using techniques such as :\nTunneling\nStenography\n\n\n"},"GitHub":{"slug":"GitHub","filePath":"GitHub.md","title":"GitHub","links":["/"],"tags":[],"content":"Home\nGitHub\n\ngit reset HEAD~1: To unstage local change (only 1) from commits\n\nReadme:\n\nDiagrams: stan-smith.github.io/FossFLOW/\nuithub: file structure for readme\ngitmvp: a prompt that reverse engineer the repo in form of mvps\n"},"Literature-Notes/C++-Design-Patterns-for-Low-latency-Applications-Including-High-frequency-Trading-(2309.04259v1)":{"slug":"Literature-Notes/C++-Design-Patterns-for-Low-latency-Applications-Including-High-frequency-Trading-(2309.04259v1)","filePath":"Literature Notes/C++ Design Patterns for Low-latency Applications Including High-frequency Trading (2309.04259v1).md","title":"C++ Design Patterns for Low-latency Applications Including High-frequency Trading","links":["Literature-Notes/"],"tags":[],"content":"Research Papers Home"},"Literature-Notes/index":{"slug":"Literature-Notes/index","filePath":"Literature Notes/index.md","title":"index","links":[],"tags":[],"content":""},"MATLAB":{"slug":"MATLAB","filePath":"MATLAB.md","title":"MATLAB","links":["/"],"tags":[],"content":"Home\nBasics :\nYou can save variables that are accessible to any script(.m) or livescript(.mlx) in a .mat file and access it anywhere.\n% save var1, var2, to a .mat file:\nsave(&#039;datafile.mat&#039;, &#039;var1&#039;, &#039;var2&#039;, ....);\n \n% save all variables in workspace to .mat file:\nsave datafile.mat;\n \n% Append new variable to the file:\nsave(&#039;datafile.mat&#039;, &#039;varNew&#039;, &#039;-append&#039;);\n \n% load variables form .mat file:\nload datafile;\n \n% load a specific variable from a mat file:\nload(&#039;datafile.mat&#039;, &#039;variableName&#039;);\n\nArray :\n% generate numbers in a range with specific amount of break btwn 2 elements:\nx = [start_element:break_btwn_2_elements:end_element];\n \n \n% generate n random numbers in a range:\nx = linspace(start_element, end_element, number_of_elements);\n \n \nx = [1:5]\n% generates x = [1,2,3,4,5];\nx = x&#039; \n% generates x = [1\n%                2\n%                3\n%                4\n%                5]\n \n \ny = rand(row,col)\n% generates [row x col] matrix with random values from range 0 to 1, values are taken from uniform distribution\n \n \nz = zeros(row,col)\n% generate [row x col] matrix of all elements as &#039;0&#039;\n \n \nz = ones(row,col)\n% generate [row x col] matrix of all elements as &#039;1&#039;\n \n \nz = data(end-1,3)\ny = data(end,3)\n% gives back last row 3rd column element of data matrix\n \n \nx = A(:,1)\n% returns an array of all row elements in column 1\n \n \nvolumes = data(:,end-1:end)\n% returns last two columns of data matrix\n \n \nvr = round(va);\n% round off a value\n \n \nmass = density.*va ;\n% element-wise multiplication\n \n \n[row, col] = size(data)\n% returns numbers of elements in row and col\n \n \n[vMax, ivMax] = max(v2);\n% returns the maximum element and its index in an array\n \n \nz = v1(v1 &lt; 4)\n% returns all elements less than 4 in v1\n \n \na = sample(v1 &lt; 4)\n% contains the elements of¬†sample¬†corresponding to where¬†v1¬†is less than¬†4.\n\nPlot :\nplot(sample, mass2, &quot;r *&quot;)\n% plot a graph with sample on x-axis and mass2 on y-axis\n% and r ==&gt; red line\n% &quot; &quot; ==&gt; space in between means don&#039;t drae line just plot points\n% * ==&gt; means point co-ordinnates with * mark\n \n \nplot(x,y,&quot;r--o&quot;)\n% plots a red (`r`) dashed (`--`) line with circle (`o`) markers\n \n \nplot(x1,y1)  \nhold on  \nplot(x2,y2)\n% plots both points on same graph\n \n \nhold¬†off\n% removes the hold on a graph so a new graph can be made\n \n \ntitle(&quot;Plot Title&quot;)\n% add title to plot\n \n \nylabel(&quot;Y-Axis Label&quot;)\n% add label to y axis\n \n \nlegend(&quot;Exp A&quot;,&quot;Exp B&quot;)\n% add legend to show which line/point represent which value of data\n"},"ML/Hands-on-Machine-Learning-with-ScikitLearn,-Keras--and--TensorFlow":{"slug":"ML/Hands-on-Machine-Learning-with-ScikitLearn,-Keras--and--TensorFlow","filePath":"ML/Hands on Machine Learning with ScikitLearn, Keras & TensorFlow.md","title":"Hands on Machine Learning with ScikitLearn, Keras & TensorFlow","links":["ML/"],"tags":[],"content":"index\nSources\n\nGreat for learning concepts, functions and different methods - Hands on Machine Learning with ScikitLearn, Keras &amp; TensorFlow\n\nResearch Articles\n\nHow Deepseek used MultiToken Prediction\nInformer (this channel discuss and implement a lot of ML models)\nUnderstanding the difficulty of training deep feedforward neural networks\nA DISCIPLINED APPROACH TO NEURAL NETWORK HYPER-PARAMETERS\nBitwise Neural Networks\naman.ai/primers/ai/top-30-papers/\n\nFine Tuning\nHyperparameters ‚áí Variables that are constant throughout the training for example, Neural Net architecture (number of layers, neuron in layers etc‚Ä¶), Learning Rate, batch size, Loss function, Optimizers, Activation functions, number of iterations etc..\nParameters ‚áí variables that are fine tuned during training weights and biasis\nHyperparameters fine tuning\nNumber of Hidden Layers\n\nfor complex problems, deep networks have a much higher parameter efficiency than shallow ones. They can model complex functions using exponentially fewer neurons than shallow nets, allowing them to reach much better performance with the same amount of training data.\n\nNumber of Neurons per Hidden Layer\n\nusing the same number of neurons in all hidden layers performs just as well in most cases, or even better; plus, there is only one hyperparameter to tune, instead of one per layer.\ndepending on the dataset, it can sometimes help to make the first hidden layer bigger than the others.\na layer with two neurons can only output 2D data, so if it processes 3D data, some information will be lost\nIn general you will get better performance by increasing the number of layers instead of the number of neurons per layer.\n\nLearning rate\n\nlearning rate is too small, then the algorithm will have to go through many iterations to converge\nlearning rate is too high, you might jump across the minimum value and end up on the other side, possibly even higher up than you were before\nThe curve of the Mean Squared Error (MSE) cost function for linear regression is¬†typically a convex shape, which means it has no local minima, just one global minimum.\neliminate models that take too long to converge\nstarting with a very low learning rate (e.g., 10-5) and gradually increasing it up to a very large value (e.g., 10).\nThis is done by multiplying the learning rate by a constant factor at each iteration (e.g., by exp(log(10^6 )/500) to go from 10^-5 to 10 in 500 iterations).\nIf you plot the loss as a function of the learning rate (using a log scale for the learning rate), you should see it dropping at first. But after a while, the learning rate will be too large, so the loss will shoot back up: the optimal learning rate will be a bit lower than the point at which the loss starts to climb (typically about 10 times lower than the turning point).\n\nNumber of Iterations\n\nset a very large number of iterations but to interrupt the algorithm when the gradient vector becomes tiny that is, when its norm becomes smaller than a tiny number œµ (called the tolerance)‚Äîbecause this happens when Gradient Descent has (almost) reached the minimum\nit can take O(1/œµ) iterations to reach the optimum within a range of œµ, depending on the shape of the cost function\n\nLoss functions\n\nRoot Mean Square Error (RMSE) is generally the preferred performance measure for regression tasks, in some contexts you may prefer to use another function. For example, suppose that there are many outlier districts. In that case, you may consider using the Mean Absolute Error (MAE)\n\nRoot Mean Square Error (RMSE) corresponds to the Euclidean norm ‚Üí shortest distance between two points calculated using Pythagoras‚Äô theorem. The square of the total distance between two objects is the sum of the squares of the distances along each perpendicular co-ordinate.\nMean Absolute Error (MAE) corresponds to Manhattan norm ‚Üí sum of absolute differences between points across all the dimensions calculated using sum of the absolute differences of their Cartesian coordinates. Total sum of the difference between the x-coordinates and y-coordinates.\n\n\nHamming Distance: Used to Calculate the distance between binary vectors.\nMinkowski Distance: Generalization of Euclidean and Manhattan distance.\nCosine distance: measures the¬†similarity¬†between two vectors of an inner product space.\n\nAccuracy / Cross Validation\n\nConfusion Matrix: count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the fifth row and third column of the confusion matrix.\n\nPrecision: true positives / (true positives + false positives)\nRecall (sensitivity): true positives / (true positives + false negatives). Precision is typically used along with another metric named recall, also called sensitivity or the true positive rate (TPR). This is the ratio of positive instances that are correctly detected by the classifier.\nboth precision and recall can be calculated from confusion matrix\n\n\nF1 score is the harmonic mean of precision and recall\nBinary classifiers ‚áí Receiver Operating Characteristic (ROC) curve are used that plots true positive rate / false positive rate i.e. sensitivity (recall) versus 1 ‚Äì specificity, where Sensitivity is true negative rate.\nOne way to compare classifiers is to measure the Area Under the Curve (AUC). A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5\nyou should prefer the PR curve whenever the positive class is rare or when you care more about the false positives than the false negatives. Otherwise, use the ROC curve.\n\nActivation functions\n\nbiological neurons ‚áí roughly sigmoid activation functions, but not good for artificial neurons\ndifferent layers may learn at widely different speeds.\nthis is mostly caused by activation functions (logistic sigmoid) and the weight initialization techniques (i.e., a normal distribution with a mean of 0 and a standard deviation of 1)\nvanishing gradients problem (gradients grow smaller and smaller)\n\ngradients often get smaller and smaller as the back propagation algorithm progresses down to the lower layers\n\n\nexploding gradients problem (gradients grow larger and larger)\nGlorot and He Initialization:\n\nvariance of the outputs of each layer to be equal to the variance of its inputs\nnumber of inputs in a layer = fan-in\nnumber of neuron in a layer = fan-out\nGlorot initialization or Xavier initialization\n\nfan-avg = (fan-in + fan-out) / 2\nNormal distribution with mean 0 and variance¬†œÉ^2 = 1 / fan-avg\nOr a uniform distribution between¬†‚àír¬†and¬† + r, with¬†r = sqrt( 3 / fan-avg )\n\n\nLeCun initialization\n\nwhen fan-avg = fan-in is used in Glorot initialization\nNormal distribution with mean 0 and variance¬†œÉ^2 = 1 / fan-in\nOr a uniform distribution between¬†‚àír¬†and¬† + r, with¬†r = sqrt( 3 / fan-in )\n\n\nHe initialization (initialization of ReLU layers and it‚Äôs variants)\n\nNormal distribution with mean 0 and variance¬†œÉ^2 = 2 / fan-in\n\n\n\n\n\nInitialization parameters for each type of activation function:\n\nfor the uniform distribution, just compute r = sqrt ( 3 * œÉ^2 )\n\nReLU better than sigmoid function but suffers from dying ReLU where they only output 0, never activating that side of neural network\nUse Leaky ReLU-Œ± (z) = max(Œ±z, z) instead\n\nŒ± = 0.2 (a huge leak) better than Œ± = 0.01 (a small leak)\n\n\nRandomized Leaky ReLU (RReLU)\n\nŒ± is picked randomly in a given range during training and is fixed to an average value during testing\n\n\nParametric Leaky ReLU (PReLU)\n\nŒ± is authorized to be learned during training\nmaking Œ± an parameter instead of hyperparameter\ngood for large dataset\n\n\nExponential Linear Unit (ELU) (good but heavy to compute so use Leaky instead)\n\nELU-Œ± (z) = Œ± * (e^z ‚àí 1)       if z &lt; 0\n\n                 z                         if z ‚â• 0\n\n\nŒ± = 1 is a good start\n\n\nScaled ELU (SELU) (conditional best)\n\nSELU-Œ± (z) = Œª* Œ± * (e^z ‚àí 1)       if z &lt; 0\n\n\n           Œª * z                         if z ‚â• 0\n\n\nŒ± = Œª = 1 is a good start\n\n\nnetwork will self-normalize: the output of each layer will tend to preserve a mean of 0 and standard deviation of 1 during training only if:\n\ninput features must be standardized (mean 0 and standard deviation 1)\nLeCun normal initialization is done\nnetwork‚Äôs architecture must be sequential\n\n\n\n\nSELU &gt; ELU &gt; leaky ReLU (and its variants) &gt; ReLU &gt; tanh &gt; logistic\nBatch Normalization\n\nzero-centers and normalizes each input, then scales and shifts the result using two new parameter vectors per layer: one for scaling, the other for shifting.\n\nHere x are inputs of that layer and z are output x-hat is normalized vector\nTo sum up, four parameter vectors are learned in each batch-normalized layer: Œ≥ (the output scale vector) and Œ≤ (the output offset vector) are learned through regular backpropagation, and Œº (the final input mean vector) and œÉ (the final input standard deviation vector) are estimated using an exponential moving average.\nclip the gradients during backpropagation so that they never exceed some threshold. This is called Gradient Clipping.\n\nideal is to clip for -1 to 1 after normalizing the values i.e. the vector (0.9, 100.0) will be clipped to (0.00899964, 0.9999595)\n\n\n\n\n\nOptimizers\n\nMomentum Optimization: Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start out slowly, but it will quickly pick up momentum until it eventually reaches terminal velocity (if there is some friction or air resistance).\n\nGradient Descent: Œ∏ = Œ∏ ‚Äì Œ∑ * ‚àáŒ∏(J(Œ∏))\n\ngradient of the cost function J(Œ∏) with regard to the weights (‚àáŒ∏(J(Œ∏)))\n\n\nMomentum algorithm:\n\nm = Œ≤m - Œ∑ * ‚àáŒ∏(J(Œ∏))\nŒ∏ = Œ∏ + m\nhere m is momentum vector (initially all 0).\nŒ≤ is momentum which must be set between 0 (high friction) and 1 (no friction), 0.9 mostly used.\n\n\n\n\nNesterov Accelerated Gradient: measures the gradient of the cost function not at the local position Œ∏ but slightly ahead in the direction of the momentum, at Œ∏ + Œ≤m\n\nm = Œ≤m ‚àí Œ∑ * ‚àáŒ∏(J(Œ∏ + Œ≤m))\nŒ∏ = Œ∏ + m\n\n\nAdaGrad: Consider the elongated bowl problem again: Gradient Descent starts by quickly going down the steepest slope, which does not point straight toward the global optimum, then it very slowly goes down to the bottom of the valley. It would be nice if the algorithm could correct its direction earlier to point a bit more toward the global optimum. The AdaGrad algorithm achieves this correction by scaling down the gradient vector along the steepest dimensions.\n\noften stops too early when training neural networks so don‚Äôt use this\ns = s + ‚àáŒ∏(J(Œ∏)) ‚äó ‚àáŒ∏(J(Œ∏))\nŒ∏ = Œ∏ ‚àí Œ∑ * ‚àáŒ∏(J(Œ∏)) ‚äò sqrt(s + Œµ)\n‚äó means element-wise multiplication, ‚äò means element-wise division\nŒµ is a smoothing term to avoid division by zero, typically set to 10^(‚Äì10)\nthis algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes\nThis is called an adaptive learning rate.\n\n\nRMSProp: fix for AdaGrad slowing down a bit too fast and never converging to the global optimum. RMSProp algorithm fixes this by accumulating only the gradients from the most recent iterations (as opposed to all the gradients since the beginning of training). It does so by using exponential decay in the first step.\n\ns = Œ≤s + (1-Œ≤) * ( ‚àáŒ∏(J(Œ∏)) ‚äó ‚àáŒ∏(J(Œ∏)) )\nŒ∏ = Œ∏ ‚àí Œ∑ * ‚àáŒ∏(J(Œ∏)) ‚äò sqrt(s + Œµ)\nThe decay rate Œ≤ is typically set to 0.9\nŒµ is a smoothing term to avoid division by zero, typically set to 10^(-7) or 10^(‚Äì10)\n\n\nAdam Optimization (adaptive moment estimation): momentum optimization (exponentially decaying average of past gradients) + RMSProp (exponentially decaying average of past squared gradients)\n\nm = (Œ≤1 * m) ‚àí (1-Œ≤1) * ‚àáŒ∏(J(Œ∏))\ns = (Œ≤2 * s) + (1-Œ≤2) * ( ‚àáŒ∏(J(Œ∏)) ‚äó ‚àáŒ∏(J(Œ∏)) )\nm-hat = m / (1 - (Œ≤1^t))\ns-hat = s / (1 - (Œ≤2^t))\nŒ∏ = Œ∏ + Œ∑ * (m-hat ‚äò sqrt(s-hat + Œµ))\nt represents the iteration number (starting at 1)\nŒ≤1 is typically initialized to 0.9, Œ≤2 is often initialized to 0.999\nŒµ is a smoothing term to avoid division by zero, typically set to 10^(‚Äì7) or 10^(-10)\ntwo variants of Adam:\n\nAdaMax Optimization:\n\nm = (Œ≤1 * m) ‚àí (1-Œ≤1) * ‚àáŒ∏(J(Œ∏))\ns = max(   (Œ≤2 * s)   ,   ‚àáŒ∏(J(Œ∏))   )\nm-hat = m / (1 - (Œ≤1^t))\nŒ∏ = Œ∏ + Œ∑ * (m-hat ‚äò s)\n\n\nNadam Optimization:\n\nAdam + Nesterov Accelerated Gradient\n\n\n\n\n\n\nAll the optimization techniques discussed so far only rely on the first-order partial derivatives (Jacobians). The optimization literature also contains amazing algorithms based on the second-order partial derivatives (the Hessians, which are the partial derivatives of the Jacobians). Unfortunately, these algorithms are very hard to apply to deep neural networks because there are n 2 Hessians per output (where n is the number of parameters), as opposed to just n Jacobians per output. Since DNNs typically have tens of thousands of parameters, the second-order optimization algorithms often don‚Äôt even fit in memory, and even when they do, computing the Hessians is just too slow.\nRMSProp ~ Nadam &gt; AdaMax &gt; Adam &gt; Nestrov &gt; Momentum &gt; SGD &gt; GD\n\nClassifiers\n\nSome algorithms (such as SGD classifiers, Random Forest classifiers, and naive Bayes classifiers) are capable of handling multiple classes natively.\nOthers (such as Logistic Regression or Support Vector Machine classifiers) are strictly binary classifiers.\n\nAvoiding Overfitting Through Regularization\nEarly stopping\nstops training when the model‚Äôs performance on a validation set starts to degrade, even if training loss is still decreasing.\nl1 (Lasso Regression)\nLasso (Least Absolute Shrinkage and Selection Operator) Regression adds a penalty proportional to the absolute value of the weights\n\nlossl1 = original_loss + Œª * (‚àë ‚à£w(i)‚à£)   where w(i) = ith weight\nEncourages sparsity, it pushes some weights exactly to zero.\nSo it‚Äôs good for feature selection, it selects only the most important features.\nŒª = 0.01 is a good value\n\nl2 (Ridge Regression)\nRidge Regression adds a penalty proportional to the square of the weights\n\nlossl2 = original_loss + Œª * (‚àë w(i)^2 )     where w(i) = ith weight\nEncourages weights to be small, but not zero\nSmooths the model and helps generalization, but doesn‚Äôt eliminate features\n\nElastic Net\nmix l1 &amp; l2 regularization\n\nloss =  original_loss + Œª * (‚àë ‚à£w(i)‚à£) + Œª * (‚àë w(i)^2 )     where w(i) = ith weight\nEncourage spare and stable model\n\nDropout\nat every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability p of being temporarily ‚Äúdropped out,‚Äù meaning it will be entirely ignored during this training step, but it may be active during the next step.\nThe hyperparameter p is called the dropout rate\n\nand it is typically set between 10% and 50%\ncloser to 20‚Äì 30% in RNN,\ncloser to 40‚Äì50% in CNN\n\nIn practice, you can usually apply dropout only to the neurons in the top one to three layers (excluding the output layer).\nSuppose p = 50%, in which case during testing a neuron would be connected to twice as many input neurons as it would be (on average) during training. To compensate for this fact, we multiply outputs with 1 / (1-p)\nFinal Deep Neural Network Configs\n\n\n\n\nCNN\nInstead of 1 weight per pixel, CNN uses same kernel (for example a 3x3 kernel ‚áí 9 weights) over the feature map\nFourier Series\nRepresent a periodic function as a sum of sinusoids (sines and cosines)\nFourier Transform\ntransform the signal/waveform from time domain to frequency domain\nfrequency domain have representation tells which frequencies were used to generate that signal/waveform\nRepresent any function (even aperiodic) as an integral of sinusoids\nFourier Transform(f(t)) ‚áí F(œâ) = ‚à´ f(t) * e^(-iœât) dt\ne^(-iœât) ‚áí cos(œât) - i * sine(œât)\nInverse Fourier Transform\nf(t) =  (1/ 2œÄ) * ‚à´ F(œâ) * e^(iœât) dœâ\nLaplace Transform\ngeneralized fourier transform\nLaplace Transform(f(t)) ‚áí F(s) = ‚à´ f(t) * e^(-(a+iœâ)t) dt\nwhere s = a+iœâ\ntake s so that as F(s) ‚Üí 0 as t ‚Üí infinity\nuseful to solve ordinary differential equations (ODEs), analyzing linear time-invariant (LTI) systems, and working with control systems\nInverse Laplace Transform\nf(t) =  (1/ i2œÄ) * ‚à´ F(s) * e^st) ds\nConvolution\nflipping, sliding, integrating\n\nTime-domain convolution ‚Üî Frequency-domain multiplication\nTime-domain multiplication ‚Üî Frequency-domain convolution\n\nA neuron located in row i, column j of a given layer is connected to the outputs of the neurons in the previous layer located in rows i to i + fh ‚Äì 1, columns j to j + fw ‚Äì 1, where fh and fw are the height and width of the receptive field.\nIn order for a layer to have the same height and width as the previous layer, it is common to add zeros around the inputs, as shown in the diagram. This is called zero padding.\nIt is also possible to connect a large input layer to a much smaller layer by spacing out the receptive fields. This shift from one receptive field to the next is called the stride.\nA neuron located in row i, column j in the upper layer is connected to the outputs of the neurons in the previous layer located in rows i √ó sh to i √ó sh + fh ‚Äì 1, columns j √ó sw to j √ó sw + fw ‚Äì 1, where sh and sw are the vertical and horizontal strides.\nFilters / Kernels\nA neuron‚Äôs weights in a receptive decide the filter property and which feature of the image is focused on.\noutputs of filters / kernels are called feature maps.\nn CNNs, the model learns kernels values / weights as part of training, instead of using fixed ones.\nbut here are some common ones for understanding\n\n\nEdge Detection Filters\n\nSobel filter (horizontal / vertical edges)\n\nvertical edges example:\n\n[ 0.25  0  -0.25 ]\n[ 0.50  0  -0.50 ]\n[ 0.25  0  -0.25 ]\n\n\nhorizontal edges example:\n\n[ 0.25   0.50  0.25 ]\n[   0      0     0  ]\n[ -0.25 -0.50 -0.25 ]\n\n\n\n\nPrewitt filter\nLaplacian filter (second-order edges)\n\n\n\nSharpening Filters: Emphasize fine details and edges\n\n[ 0 -1  0 ]\n[-1  5 -1 ]\n[ 0 -1  0 ]\n\n\n\nBlurring / Smoothing Filters: Reduce noise, remove detail\n\nGaussian blur (assign weights from gaussian curve)\nAverage blur (every weights is 1 / number of neurons in a kernel)\n\n\n\nLearned Filters in CNNs: in modern CNNs (like ResNet, VGG, etc.)\n\n\nDepthwise Separable Filters: Used in MobileNet and other lightweight models\n\n\nDilated (Atrous) Filters\n\n\nTransposed Convolution Filters: Used in upsampling, e.g., in decoders (GANs, autoencoders).\n\n\nInput images are also composed of multiple sublayers, one per color channel.\n\n\nThere are typically three channels: red, green, and blue (RGB).\n\n\nGrayscale images have just one channel.\n\n\nPooling Layers\nsubsample (i.e., shrink) the input image in order to reduce the computational load, the memory usage, and the number of parameters (thereby limiting the risk of overfitting).\ntypes:\n\nMax Pooling: (most common)\n\ntake maximum of inputs in kernel\n\n\nAverage Pooling:\n\ntake average of all inputs in kernel\n\n\nGlobal Pooling: (Global Average/Max Pooling)\n\nTakes the average or max over the entire feature map.\nOften used at the end of CNNs instead of fully connected layers.\n\n\n\nBy inserting a max pooling layer every few layers in a CNN, it is possible to get some level of translation invariance at a larger scale.\nNote that max pooling and average pooling can be performed along the depth dimension (across same layer feature maps) rather than the spatial dimensions (same feature map), although this is not as common.\nCNN Architectures\n\ninput ‚Üí convolutional layers (each one generally followed by a ReLU layer) ‚Üí pooling layer ‚Üí  convolutional layers (each one generally followed by a ReLU layer) ‚Üí pooling ‚Ä¶ ‚Üí FNN + ReLUs ‚Üí Softmax\nAlexNet introduced competitive normalization step immediately after the ReLU called local response normalization (LRN)\n\nIf a neuron fires very strongly compared to its neighbors, it suppresses them.\nThis makes the network more selective and helps it generalize better.\n"},"ML/Neural-Network-in-Rust":{"slug":"ML/Neural-Network-in-Rust","filePath":"ML/Neural Network in Rust.md","title":"Neural Network in Rust","links":["ML/"],"tags":[],"content":"index\nResources:\ntowardsdatascience.com/the-ultimate-ndarray-handbook-mastering-the-art-of-scientific-computing-with-rust-ef5ab767212a/\nrust-lang-nursery.github.io/rust-cookbook/intro.html\n\n\n\n\n\n\n\nüîß Dependencies\n\nndarray (store 2d array of data)\nndarray-rand (generate intial random weights(w) and biases(b))\npolars (to read write data in csv)\n\nüß† Model Overview\n\ninput layer, 1 hidden layer, output layer\nInput: 784-dimensional MNIST images\nHidden layer: 10 neurons with ReLU as activation function\nOutput layer: 10 neurons with softmax as activation function for multi-class classification\n"},"ML/Reinforcement-learning-for-high-frequency-trading":{"slug":"ML/Reinforcement-learning-for-high-frequency-trading","filePath":"ML/Reinforcement learning for high frequency trading.md","title":"Reinforcement learning for high frequency trading","links":["ML/"],"tags":[],"content":"index\nDeep Reinforcement Learning for Active High Frequency Trading\nC++ design patterns for low-latency applications including high-frequency trading\ngithub.com/ZhengyaoJiang/PGPortfolio"},"ML/Supervised-Learning":{"slug":"ML/Supervised-Learning","filePath":"ML/Supervised Learning.md","title":"Supervised Learning","links":["ML/"],"tags":[],"content":"index\nSupervised Learning Algorithms:\nLinear Regression :\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n \n# Input data\ntime_studied = np.array([20, 50, 32, 65, 23, 43, 10, 5, 22, 35, 29, 5, 56]).reshape(-1, 1)\nscores = np.array([56, 83, 47, 93, 47, 82, 45, 78, 55, 67, 57, 4, 12]).reshape(-1, 1)\n \n# Create and train the model\nmodel = LinearRegression()\nmodel.fit(time_studied, scores)\n \n# Predict the score for a specific value\nprint(model.predict(np.array([56]).reshape(-1,1)))  \n \n# Plotting\nplt.scatter(time_studied, scores)\nplt.plot(np.linspace(0, 70, 100).reshape(-1, 1), model.predict(np.linspace(0, 70, 100).reshape(-1, 1)), &#039;r&#039;)\nplt.ylim(0, 100)\nplt.show()\n\nNote :\nThe LinearRegression model expects input in a 2D array format for prediction.\n\n\nExplanation :\n\n\nnp.linspace(0, 70, 100):\n\nFunction: Generates 100 evenly spaced values between 0 and 70.\n\n\n.reshape(-1, 1):\n\nFunction: Reshapes the 1D array into a 2D array with 100 rows and 1 column.\n\n\nmodel.predict(...):\n\nFunction: Uses the trained LinearRegression model to predict the scores for the generated values.\n\n\nplt.plot(..., ..., &#039;r&#039;):\n\nFunction: Plots the input values against the predicted scores.\nFirst Argument: The x-values for the plot, which are the evenly spaced values between 0 and 70.\nSecond Argument: The y-values for the plot, which are the predicted scores.\nThird Argument (&#039;r&#039;): Specifies the color and style of the plot line. &#039;r&#039; means a red line.\n\n\n\n\nOutput :\n\n[[68.22055244]]\n\n\n\nTesting :\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn. linear_model import LinearRegression \nfrom sklearn.model_selection import train_test_split \n \n# Input data\ntime_studied = np.array([20, 50, 32, 65, 23, 43, 10, 5, 22, 35, 29, 5, 56]).reshape(-1, 1)\nscores = np.array([56, 83, 47, 93, 47, 82, 45, 78, 55, 67, 57, 4, 12]).reshape(-1, 1)\n \n# randomly split both np array into 70% , 30% \n# as test_size = 0.3 which means 30%\ntime_train, time_test, score_train, score_test = train_test_split(time_studied, scores, test_size = 0.3)\n \nmodel = LinearRegression()\nmodel.fit(time_train, score_train)\n \n# Printing accuray\nprint(model.score(time_test, score_test))\n \nplt.scatter(time_train, score_train) \nplt.plot(np.linspace(0,70,100).reshape(-1,1), model.predict(np.linspace(0,70,100).reshape(-1,1)), &#039;r&#039;)\nplt.show()\nLogistic Regression :\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n \n# Example data\nX = np.array([20, 10, 3, 6, 39, 43, 55, 44, 75, 35]).reshape(-1, 1)\ny = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n \n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n \n# Initialize and train the logistic regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n \n# Print accuracy\nprint(model.score(X_test, y_test))\n \n# Predict on new data\nnew_data = np.array([22, 9]).reshape(-1, 1)\npredictions = model.predict(new_data)\nprint(f&quot;Predictions for new data: {predictions}&quot;)\n \n# Plotting\nplt.scatter(X_train, y_train)\nplt.plot(np.linspace(0, 75, 100).reshape(-1, 1), model.predict(np.linspace(0, 75, 100).reshape(-1, 1)), &#039;r&#039;)\nplt.show()\n \n\nNOTE : the target array y should be a 1D array rather than a 2D column vector when passed to the fit method of LogisticRegression\n\n\nNOTE : random_state is an fixed state of when shuffled so u get same accuracy for same random_state\n\n\nOUTPUT :\n\n1.0\nPredictions for new data: [0 0]\n\n\nK-Nearest Neighbors (KNN) :\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n \ndata = load_breast_cancer()\n \nprint(data.feature_names)\nprint(data.target_names)\n# print(data.data)\n# print(data.target)\n \nx_train, x_test, y_train, y_test = train_test_split(np.array(data.data), np.array (data.target), test_size=0.2, random_state=42)\n \nclf = KNeighborsClassifier(n_neighbors=3)\nclf.fit(x_train, y_train)\nprint(clf.score(x_test, y_test))\n\nNOTE : K-Nearest Neighbors algo checks nearest K number of points in graph and then predict the group/cluster/class of unknown value.\n\n\nn_neighbors = 3 means it checks for 3 neighbors for unknown points.\n\n\nOUTPUT :\n\n[&#039;mean radius&#039; &#039;mean texture&#039; &#039;mean perimeter&#039; &#039;mean area&#039; &#039;mean smoothness&#039; &#039;mean compactness&#039; &#039;mean concavity&#039; &#039;mean concave points&#039; &#039;mean symmetry&#039; &#039;mean fractal dimension&#039; &#039;radius error&#039; &#039;texture error&#039; &#039;perimeter error&#039; &#039;area error&#039; &#039;smoothness error&#039; &#039;compactness error&#039; &#039;concavity error&#039; &#039;concave points error&#039; &#039;symmetry error&#039; &#039;fractal dimension error&#039; &#039;worst radius&#039; &#039;worst texture&#039; &#039;worst perimeter&#039; &#039;worst area&#039; &#039;worst smoothness&#039; &#039;worst compactness&#039; &#039;worst concavity&#039; &#039;worst concave points&#039; &#039;worst symmetry&#039; &#039;worst fractal dimension&#039;] \n[&#039;malignant&#039; &#039;benign&#039;] \n0.9298245614035088\n\nSupport Vector Machines (SVM) :\n\n\nAssume we have 2 features (F1 and F2) and 2 groups (red and blue) of data\nSVM uses vectors and find a line (as in above example we have a 2D graph)\n\n\n\nAssume we have only 2 features but as shown above data is clearly unseparable\nSo we make a new feature using F1 and F2 called Kernel\nSo now as we have 3D space graph we will find a ‚Äô PLANE ‚Äô\n\n\n\nSoft Margin : we allow some imperfections in our data like above we set soft margin of 2 allowing both circled imperfect data to be ignored.\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n \ndata = load_breast_cancer()\nX = data.data\nY = data.target\n \nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n \nclf = SVC(kernel=&#039;linear&#039;, C=3) # C is soft margin\nclf.fit(x_train, y_train)\n \nprint(clf.score(x_test, y_test))\n\nHere C == soft margin\n"},"ML/Tensorflow.js":{"slug":"ML/Tensorflow.js","filePath":"ML/Tensorflow.js.md","title":"Tensorflow.js","links":["ML/"],"tags":[],"content":"index\nTensorflow.js :\nm.youtube.com/playlist\n\nNarrow AI : trained to do specific thing like or even better than humans.\n\n\nMachine Learning : An approach to AI where system learns from patterns.\n\n\nDeep Learning : A technique to implement Machine Learning.\n\n\nReinforcement Learning : try to take actions to maximize its reward.\n\n\nTransfer Learning : retrain existing models with new data.\n\nHow to train ML model :\n\nFeatures and Attributes (color shape size weight position etc.)\nVisualizing features\nChoose an algorithm\n\nTensoFlow.js :\nTensorflow.js is high level Layers API (like Keras(high level layers API for python)) which was build after deeplearn.js which was a low level mathematical Ops API which required more knowledge of ML and Math to run a model on browser.\n\nBoth Python and JavaScript code for Tensorflow.js are simply build on top of C++ core with the help of C/C++ bindings.\n\nModels in Tensorflow.js can run on both client and server side.\nClient side our hardware have many options and execution time of ML model is based on hardware of client.\nWhile on server side hardware is fix and mostly of better quality and better scalability options\n\nClient Side hardware options :\n\n\nTensors :\nThere are 6 dimensions / rank 6 tensors supported in Tensorflow.js\nif you have 4 values in an array then an vector is 4d but tensor is 1d with 4 values in it therefore tensor is of rank 1.\n\n0 dimensions / Rank 0 tensor :\n// vanilla js\nlet values = 6;\n \n// tensorflow.js\nlet tensor = tf.scalar(6)\n\n1 dimension / Rank 1 tensor : (Example: a single coordinate in 3d space)\n// vanilla js\nlet values = [1,2,3];\n \n// tensorflow.js\nlet tensor = tf.tensor1d([1,2,3]);\n\n2 dimension / Rank 2 tensor : (Example: a 2 dimensional grayscale image (0-255))\n// vanilla js\nlet values = [\n\t[2,0,67],\n\t[0,7,5],\n\t[9,5,25]\n][]()\n \n// tensorflow.js\nlet tensor = tf.tensor2d([\n\t[2,0,67],\n\t[0,7,5],\n\t[9,5,25]\n]);\nThe shape of the tensor for a grayscale image is typically :\n(Height,¬†Width) = 0-255 value\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n \n# grayscale_image_tensor = tf.zeros((256, 256), dtype=tf.uint8);\n# image_array = grayscale_image_tensor.numpy()\n \nimage_tensor = tf.random.uniform((256, 256), minval=0, maxval=255, dtype=tf.int32)\nimage_array = image_tensor.numpy()\n \n# example image_array = \n#   x ---&gt;\n# y [[122, 169, 17, .... , 117],\n# |  [....],\n# |  [....],\n# |  [....],\n# v  ...]\n \nplt.imshow(image_array, cmap=&#039;gray&#039;)\nplt.axis(&#039;off&#039;)\nplt.title(&quot;Random grayscale Image&quot;)\nplt.show()\n\n3 dimension / Rank 3 tensor : (Example: a regular RGB image)\n// vanilla js\nlet values = [\n\t[\n\t\t[114 191 105], [198 1 153], [235 84 213] ... [223 193 167]\n\t],\n\t[\n\t\t[162 33 214], [203 75 221], [ 95 105 80] ... [115 62 254]\n\t],\n\t......\n]\n \n// tensorflow.js\nlet tensor = tf.tensor3d([\n\t[\n\t\t[114 191 105], [198 1 153], [235 84 213] ... [223 193 167]\n\t],\n\t[\n\t\t[162 33 214], [203 75 221], [ 95 105 80] ... [115 62 254]\n\t],\n\t......\n]);\nData Layout for RGB image, the tensor stores pixel data as:\n\nimage_tensor[h][w][0] ‚Üí Red value of the pixel at height h and width w.\nimage_tensor[h][w][1] ‚Üí Green value of the pixel at height h and width w.\nimage_tensor[h][w][2] ‚Üí Blue value of the pixel at height h and width w.\n\n# import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n  \n# grayscale_image_tensor = tf.zeros((256, 256), dtype=tf.uint8);\n# image_array = grayscale_image_tensor.numpy()\n \nimage_tensor = tf.random.uniform((256, 256, 3), minval=0, maxval=1)\nimage_array = image_tensor.numpy()\ngray_array = tf.image.rgb_to_grayscale(image_array)\n \nplt.figure(figsize=(8,8))\n \nplt.subplot(1,2,1)\nplt.imshow(gray_array, cmap=&#039;gray&#039;)\nplt.axis(&#039;off&#039;)\nplt.title(&quot;Random grayscale Image&quot;)\n \nplt.subplot(1,2,2)\nplt.imshow(image_array)\nplt.axis(&#039;off&#039;)\nplt.title(&quot;Random rgb Image&quot;)\nplt.show()\nLoad an image and convert it to grayscale:\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n \nimage = tf.io.read_file(&#039;./test.png&#039;)\nimage = tf.image.decode_image(image, channels=3) # convert image to RGB\ngray_image = tf.image.rgb_to_grayscale(image)\n \nplt.figure(figsize=(12, 6))\n \n# Original image\nplt.subplot(1, 2, 1)\nplt.imshow(image.numpy())\nplt.title(&quot;Original Image&quot;)\nplt.axis(&#039;off&#039;)\n \n# Grayscale image\nplt.subplot(1, 2, 2)\nplt.imshow(gray_image.numpy(), cmap=&#039;gray&#039;)\nplt.title(&quot;Grayscale Image&quot;)\nplt.axis(&#039;off&#039;)\n \nplt.tight_layout()\nplt.show()\n\n4 dimension / Rank 4 tensor : (Example: a video where we have series of rank 3 tensor RGB images and 4th dimension is time)\n5 dimension / Rank 5 tensor : (Example: a batch of videos, Minecraft)\nIn 3d games like Minecraft data is called voxel (volume element in a 3D space), where each voxel, so each voxel can have composition of ((r,g,b), x, y, z, time) as a rank 5 tensor\n6 dimension / Rank 6 tensor : (Example: a batch of voxel, like a batch a voxel with animations(6th dimension))\n\nAttributes of a tensor :\n\nData Types (DType, dtype)\n\nint8 === char stores 0-255\nint16 === short stores 0-2^16 - 1\nint32 === int stores 0-2^32 - 1\nint64 === int stores 0-2^64 - 1\n\n\nShape\nNumber of elements in each of dimension / axis\nExample: A Rank 3 with [4,5,8] will have\n1st dimension will have 4 values in array\n2nd dimension will have 5 values in array\n3rd dimension will have 8 values in array\nRank / Axis\nRank is simply the number of axis / dimension in an tensor\nSize\nits the total number of elements an tensor can hold\nExample: a rank 3 tensor of [4,5,8] can hold 4 * 5 * 8 = 160 elements\n"},"ML/index":{"slug":"ML/index","filePath":"ML/index.md","title":"ML","links":["/"],"tags":[],"content":"Home\nRoadmap\nMachine Learning Roadmap 2020 (whimsical.com)\nProject ideas\nMachine Learning Projects - YouTube\nGrind-75 ML version\nproducts.123ofai.com/qnalab/problems\nMathematics\nThe Complete Mathematics of Neural Networks and Deep Learning (youtube.com)\nMachine Learning\n\nMLU-Explainis an education initiative from Amazon designed to teach machine learning theory and practical application.\nGreat for learning concepts, functions and different methods - Hands on Machine Learning with ScikitLearn, Keras &amp; TensorFlow\nMachine Learning University (MLU)¬†\nTeaching library¬†for machine learning engineers MiniTorch\nDetailed and clear explanation of ML distill.pub/\nA work-in-progress to catalog the state of¬†machine learning in Rust: www.arewelearningyet.com/\n\nDeep Learning\ncourse.fast.ai/\nGenAI :\ngenieincodebottle/generative-ai: Comprehensive resources on Generative AI, including a detailed roadmap, projects, use cases, interview preparation, and coding preparation. (github.com)\nCourses :\nPython code for ML , only main implementation and basic idea\nCS50‚Äôs Introduction to Artificial Intelligence with Python 2023\nMachine Learning by StatQuest with Josh Starmer\n(not prefered) Machine Learning Playlist by Krish Naik Hindi\nMachine Learning with Python and Scikit-Learn ‚Äì Free Code Camp\n== Maths ==\nHarvardX: Introduction to Probability | edX\nUTAustinX: Linear Algebra - Foundations to Frontiers | edX\nMatrix Algebra for Engineers | Coursera\n== ML/ DL ==\n\nMachine Learning | Coursera\n\nSupervised Machine Learning: Regression and Classification - Week 1: Introduction to Machine Learning - Week 1 | Coursera\nAdvanced Learning Algorithms - Neural Networks - Week 1 | Coursera\nUnsupervised Learning, Recommenders, Reinforcement Learning - Unsupervised learning - Week 1 | Coursera\n\n\nNeural¬†Networks:¬†Zero¬†to¬†Hero¬†¬†\nDeep Learning | Coursera\nIntroduction - Hugging Face NLP Course\n\nThe spelled-out intro to neural networks and backpropagation: building micrograd (youtube.com)\nDeploy Flask Application on Google Cloud:\nwww.youtube.com/watch\nEvery Algorithm in ML\nSupervised Learning Algorithms:\n\nLinear Regression\nLogistic Regression\nDecision Trees\nRandom Forest\nGradient Boosting Machines (GBM)\nSupport Vector Machines (SVM)\nK-Nearest Neighbors (KNN)\nNaive Bayes\nNeural Networks (Multilayer Perceptron)\nEnsemble Methods (AdaBoost, Bagging)\n\nSemi-Supervised Learning Algorithms:\n\nSelf-Training\n\n\nCo-Training\n\n\nLabel Propagation\n\nUnsupervised Learning Algorithms:\n\nK-Means Clustering\nHierarchical Clustering\nDBSCAN\nGaussian Mixture Models (GMM)\nSelf-Organizing Maps (SOM)\nPrincipal Component Analysis (PCA)\nIndependent Component Analysis (ICA)\nAutoencoders\n\nOther Learning Algorithms:\n\nAnt Colony Optimization\nGenetic Algorithms\nParticle Swarm Optimization\nBayesian Networks\nMarkov Decision Processes\n\nReinforcement Learning Algorithms:\n\nQ-Learning\nDeep Q-Networks (DQN)\nPolicy Gradient Methods\nActor-Critic Methods\nTemporal Difference Learning (TD-Learning)\n\nNatural Language Processing (NLP) Specific Algorithms:\n\nTF-IDF\nWord2Vec\nDoc2Vec\nSequence Models (RNNS, LSTM, GRU)\nTransformer Models (BERT, GPT)\n\nHarvesting social media sentiment analysis to enhance stock market prediction using deep learning [PeerJ]\nwww.nytimes.com/interactive/2020/11/21/science/artificial-intelligence-fake-people-faces.html\nBanana ripeness stage identifications :\nlink.springer.com/article/10.1007/s12652-021-03267-w"},"OOPs":{"slug":"OOPs","filePath":"OOPs.md","title":"OOPs","links":["/"],"tags":[],"content":"Home\n4 Pillars:\n\nEncapsulation ‚áí encapsulating functions and variable having same objective into a single unit (often function or object)\nAbstraction ‚áí Showing only relevant data / functions and hiding implementations (like private and public functions and data)\nInheritance ‚áí eliminate redundant code by reusing code (creating a prototype)\nPolymorphism ‚áí using same symbol to represent multiple functionalities\n\nclass ‚áí user defined datatypes\nprivate, protected, public ‚áí access modifiers\ndynamic dispatch ‚áí runtime, heap allocation\nstatic dispatch ‚áí compile time, stack allocation, not in the same stack frame as local variables"},"OS-in-three-pieces":{"slug":"OS-in-three-pieces","filePath":"OS in three pieces.md","title":"OS in three pieces","links":["OS"],"tags":[],"content":"OS\nVon Neumann architecture\n\nboth data and instructions are kept in the same memory\n\nVirtualization\n\nOS transform physical resources (processors, memory, disk space) into virtual form that is utilize by programs\nOS ‚áí Virtual Machine, Resource manager\n\n"},"OS":{"slug":"OS","filePath":"OS.md","title":"OS","links":["/"],"tags":[],"content":"Home\n\nPhysical Cores vs Logical Cores\n"},"Online-Courses":{"slug":"Online-Courses","filePath":"Online Courses.md","title":"Online Courses","links":["/"],"tags":[],"content":"Home\nPy Torch (ZTM 2023):\nPy Torch For Deep Learning In 2023 Zero To Mastery : Free Download, Borrow, and Streaming : Internet Archive\nMain Course Videos :\nt.me/machine_learning_courses (first from top course in group)\nML and DATA SCIENCE (ZTM 2020):\nComplete Machine Learning And Data Science Zero To Mastery : Free Download, Borrow, and Streaming : Internet Archive\nMain Course Videos :\nt.me/machine_learning_courses (second from top course in group)\nRUST (ZTM 2022):\nZero To Mastery Rust Programming The Complete Developers Guide : Free Download, Borrow, and Streaming : Internet Archive\nWeb Security¬†&amp; Bug Bounty: Learn Penetration Testing in 2023 (ZTM 2023) :\nrb.gy/3v4r0\nETHICAL HACKING (ZTM 2021):\nFree Course Site.com Udemy Complete Ethical Hacking Bootcamp 2021 Zero To Mastery : Free Download, Borrow, and Streaming : Internet Archive\nFree Course Site.com Udemy Complete Ethical Hacking Bootcamp 2021 Zero To Mastery : Free Download, Borrow, and Streaming : Internet Archive\nFree Course Site.com Udemy Complete Ethical Hacking Bootcamp 2021 Zero To Mastery : Free Download, Borrow, and Streaming : Internet Archive\nDEV-OPS (ZTM 2022):\n[ NNMClub.to] [ Zero To Mastery] Dev Ops Bootcamp Learn Linux &amp; Become A Linux Sysadmin [ En] : Free Download, Borrow, and Streaming : Internet Archive\nVUE DEVELOPER\nGet Free Courses. Co Udemy Complete Vue Developer 2023 Zero To Mastery ( Pinia, Vitest) : vue course 3q : Free Download, Borrow, and Streaming : Internet Archive\nFIGMA (ZTM 2022):\nCourse Club. Me Academy Zero To Mastery Motion Design With Figma Animations, Motion Graphics, UXUI : me : Free Download, Borrow, and Streaming : Internet Archive\nThreeJS (Simon Bruno):\nthree.js journey : simon bruno : Free Download, Borrow, and Streaming : Internet Archive\nWEB_GL :\nProcedural Mesh Animation with Three.js and React using react-three-fiber : Alvan Caleb Arulandu : Free Download, Borrow, and Streaming : Internet Archive\nNEXT.JS (ZTM 2023):\ngiga-course.-com-udemy-complete-next.js-developer-in-2023-zero-to-mastery directory listing (archive.org)\nRUST (ZTM):\nZero To Mastery Rust Programming The Complete Developers Guide : Free Download, Borrow, and Streaming : Internet Archive\nNODE JS (ZTM 2022):\nzero-to-mastery-complete-node-js-developer-in-2022-graph-ql-mongo-db-plus-more directory listing (archive.org)\nAll kind of tech stuff\nCode evolution playlists\nCourses to learn Data Science in 2024:\nüü©Join for Free Data analytics &amp; Job Updates &lt;&gt; bit.ly/3xoSXuk\nüü©Join telegram channel for free coding Resources and notes - lnkd.in/d2MKFf-Q\n1Ô∏è‚É£ IBM Data Science Professional Certificate\nlnkd.in/dVcsQ7Ja\n2Ô∏è‚É£ Python\nlnkd.in/dtqu38qZ\n3Ô∏è‚É£ R\nlnkd.in/duvf64E3\n4Ô∏è‚É£ PowerBI\nlnkd.in/d5uX4whn\n5Ô∏è‚É£ Mathematics\nlnkd.in/d8_raWbu\n6Ô∏è‚É£ Tableau\nlnkd.in/dd3wywyA\n7Ô∏è‚É£ Excel and PowerBI\nlnkd.in/d7Mx-MYm\n8Ô∏è‚É£ Probability\nlnkd.in/dKDRn3-r\n9Ô∏è‚É£ Statistics\nlnkd.in/d8nZSUZq\nüîü Linear Algebra\nlnkd.in/dVyUXSZ2\n\n\nMachine Learning\nlnkd.in/dJhg_95W\n\n\nDeep Learning\nlnkd.in/d6cWvJ_9\n\n\nData Analysis\nlnkd.in/d4vGqmQZ\n\n\nData Visualization\nlnkd.in/dbhkYBBi\n\n\nSQL\nlnkd.in/dN3nPaqr\n\n"},"Optimizations-in-Rust-or-Cpp":{"slug":"Optimizations-in-Rust-or-Cpp","filePath":"Optimizations in Rust or Cpp.md","title":"Optimizations in Rust or Cpp","links":["Rust","OS"],"tags":[],"content":"Rust\nOS\nRust optimizations / Advance Rust\n\nMeasure Rust Performance - Let‚Äôs Get Rusty YT\nAdvance Rust Techniques - GOTO conf\n\nSIMD (Single Instruction Multiple Data)\n[linebender.org/blog/towards-fearless-simd/]\nThe Future of SIMD, with Raph Levien\nSIMD = Single Instruction Multiple Data\nIn GPU we have SIMT i.e. Single Instruction Multiple Threads (32 threads per wrap/group), where each thread can access same or different data\nlet‚Äôs say we have a if statement if A else B then, a SIMT compiler will map that to a predication/predicate mask(a bitmask or a set of boolean values). Each value of predication mask represents a case where condition is true or false according to the boolean value it holds.\ntrue or 1 means operation proceeds\nfalse or 0 means operation is skipped\nLayout biases measurement\n\n‚ÄúPerformance Matters‚Äù by Emery Berger\n"},"QT/index":{"slug":"QT/index","filePath":"QT/index.md","title":"QT","links":["/"],"tags":[],"content":"Home\n\nIn Qt, when you attempt to open a resource file (indicated by the :/ prefix), you cannot open it for writing (QIODevice::ReadWrite). Resource files are typically compiled into your application‚Äôs binary and are read-only by default. Therefore, attempting to open a resource file for writing will fail, resulting in the error you encountered.\n\n\nTo set equal portions in Layout :\n\n\nCreate a¬†QHBoxLayout¬†container.\nAdd your two widgets (let‚Äôs call them¬†widget1¬†and¬†widget2) to this layout.- Set the¬†stretch factor¬†for both widgets to 1 (equal parts).\nThe widgets will automatically share the available horizontal space equally.\n\nHow to deploy QT your project on windows\n\nopen Qt 6.7.0 (MinGW 11.2.0 64-bit) application\ncd then full project release file path\nRun   windeployqt.exe --quick .   command .\nDONE .\n\nYOUTUBE for full setup : How to Create Executable &amp; Installer (.Exe) File for QT Project (youtube.com)"},"Quant/Orderbook-in-Rust":{"slug":"Quant/Orderbook-in-Rust","filePath":"Quant/Orderbook in Rust.md","title":"Orderbook in Rust","links":["Quant/"],"tags":[],"content":"index\nlobsterdata.com/\nwww.kaggle.com/datasets/freemanone/fi2010\nan orderbook is a store of buy(bid) and sell(ask) orders for a specific asset/financial instrument usually organized by price-time priority.\ninshort: It shows who wants to buy or sell, how much, and at what price.\nOrder Book Levels\nThe different ‚Äúlevels‚Äù of order book data represent how much information is being shown or used.\n\nLevel 1 (L1) - Top of the book\nBest Bid Offer (BBO),\nbest ask ‚áí minimum ask somebody is willing to accept\nbest bid ‚áí highest someone is willing to pay\nLevel 2 (L2) ‚Äì Market Depth\nMarket by Price (MBP),\nShows multiple prices, their quantity, number of asks/bids\nWith L2, you can answer: ‚ÄúHow much could I buy without moving the market too much?‚Äù\nLevel 3 (L3) ‚Äì Full Depth / Raw Orders\nMarket by Order(MBO),\nShows every individual order.\n\nOrder Matching Algorithms:\n\nPrice-Time Priority (FIFO): maintain a Priority Queue of asks/bids, FIFO as queue works on it. Match best price first. For equal price, oldest order wins.\nPro-Rata Matching: priority to high quantity at best price. Orders at the same price level are matched proportionally based on their sizes.\nSize-Time Priority (Hybrid model): larger orders which came ahead of others get matched first if prices are equal. Orders are sorted first by size(like prorata), then by time within same size(like fifo).\n\nOrder Types:\n\ncancel-on-disconnect (COD): open orders to be canceled if we lose connection to the market in order to reduce risk.\n\n\nRust details:\n\nBox&lt;T&gt; ‚Äì Single Owner, Heap Allocation\nRc&lt;T&gt; ‚Äì Multiple Owners (Single Thread) - Rc docs\nArc&lt;T&gt; ‚Äì Multiple Owners (Multi-Thread) -\n\nIf you want mutability inside Rc or Arc, wrap your type:\n\nRc&lt;RefCell&lt;T&gt;&gt; for single-threaded mutable access\nArc&lt;Mutex&lt;T&gt;&gt; for multi-threaded mutable access\n"},"Quant/World-Quant":{"slug":"Quant/World-Quant","filePath":"Quant/World Quant.md","title":"World Quant","links":["Quant/"],"tags":[],"content":"index\n1,20,000 data fields\nnational rounds - mumbai\ninternational rounds - 2025 - singapore\ndaily max limit (by submitting 1-2 alphas) - 2000\nfeature that tells you your alpha is +ve score or not - only team members that qualify\nmain score (unlocks after qualifying) -\nqualifying score - 10,000\ndon‚Äôt submit from 19th May to 27th May\nafter qualifying you are invited to become conditional(background check) research consultant.\nthere are 300 stocks (300 alpha weights)\nwe need to generate  alpha matrix to generate alpha weights for each stock on each date\nalpha weight - ratio of what amount of your portfolio(total money) you buy on that day in that stock.\nWorld Quant - equity(stocks) long-short market neutral strategy.\nUS region\n16 datasets\nuniverse -\n\ntop 3000 - top 3000 market capitalization stocks in terms of there size\n\ndelay -\n\ndelay 1 - uses yesterdays closing\n\ndecay -\n\nmoving average of the value(5 == last 4 days moving average)\n\nstd deviation of returns ‚Üí risk\nturnover ‚Üí average of returns\n\nIdea:¬†Operating earning yield (OEY) refers to the amount of earnings from operating activities an investor can obtain for each dollar invested. Higher OEY implies higher returns for the same amount of invested capital thus representing an investment opportunity.¬†¬†\nSuggested data field:¬†operating_income, cap, industry\nSuggested operator: ts_rank, group_rank, group_mean\n\nexamples: platform.worldquantbrain.com/learn/documentation/create-alphas/19-alpha-examples\nwww.quantconnect.com/\n\nFinance Basics\nStock Market: place where buyers and sellers trade shares/stock of publicly listed companies\nShare/Stock: each share/stock represents a small portion of ownership in a company\nHedge Firms: investment vehicles that utilize a range of strategies to seek to generate returns for their investors.\nHedge Firms are different amongst investment companies in the following ways:\n\nLeverage: involves borrowing money that is used to deploy investment ideas\nShorting: when investor borrows and sells shares hoping to buy them back when prices are low.\nLong position: buying the stock, and making money when it increase in value\nVolume: Volume is the amount of an asset or security that changes hands over some period of time, often over the course of a day. For instance, stock trading volume could refer to the number of shares of a security traded between its daily open and close.\n\nIf a company‚Äôs stock has high volume, it means that many people are buying and selling the stock.\nQuant Hedge Firms: firms that use advanced mathematical models, algorithms and statistical techniques for their investment decisions.\nAlphas\nmathematical models that seek to predict future price movements of various financial instruments.\nAlphas seek to capture an inefficiency in the market which is the applied to a chosen group of stocks called our Alpha Universe.\nAlpha is therefore a vector of predicted values of stocks in universe.\neach value can change daily and is change is defined by it‚Äôs direction and magnitude.\ndirection determine if we should long or short the stock\nmagnitude represent the proportion of total capital that is allocated to that stock\nLong-Short Neutrality: we aim to balance estimated returns with downside protection\nBacktesting: testing put alpha against past years market.\nLook Ahead Bias: pitfall where future information accidentally influences the historical data analysis.\nPerformance related metrics:\n\nSharpe: measure of risk adjusted returns earned by alphas (higher is better)\nTurnover: percentage of capital that alpha trade each day\nDrawdown: percentage of the largest loss incurred during a year during backtesting\nreturn/drawdown &gt; 1 (higher is better)\nCorrelation: should be low unless we see much higher performance as compared to the correlated alphas\nWeight: check if performance is contributed by diverse set of stocks, weight test ensures alpha weight is evenly distributed across stocks and not concentrated on few.\nSub-universe:  check if performance is contributed by diverse set of stocks, sub-universe test check if alpha‚Äôs performance in the immediate smaller set of tradable stocks, or sub-universe exceeds a required threshold.\n\nReturns is defined by WorldQuant as the return on capital traded:\nAnnualReturn = AnnualizedPnL / HalfofCapitalTraded\nProfit and Loss (PnL)\nBasic Alpha Idea:\nPrice Reversion: buy stocks at lower prices expecting it to rise to historical average price and, for the stocks that whose prices are rising we short them expecting the will decline.\nImplementation on BRAIN\nWeights: market data being a matrix, with each row representing one date and each column representing one stock.\nThe role of the Alpha expression is to transform the input matrix to an output vector of weights, with each weight corresponding to one of the stocks, where it‚Äôs value range from -1 to 1, -ve meaning short(sell) and +ve meaning long(buy).\nOnce we have got the weights of the stock from the Alpha expression, the next step is to get each day‚Äôs profit and loss (PnL).\nthe amount of money we have got to invest is called the ‚Äúbook size‚Äù. Suppose our book size is 100 USD. So I calculate the money I want to invest in each of the stocks:\nmoney_A = 0.2 * 100 USD = 20 USD Long\nmoney_B = -0.5 * 100 USD = 50 USD Short\nmoney_C = 0.3 * 100 USD = 30 USD Long\n\nNote: In BRAIN, we use constant book size for all the days, regardless of whether your portfolio makes money or loses money.\n\nThis is repeated for each day in the simulation period to calculate and plot the cumulative PnL.\nResults:\nA good Alpha tends to ideally have\n\nconsistently increasing PnL,\nhigh Annual Return,\nand more importantly, few fluctuations in the cumulative profit graph.\n\nIf the standard deviation is low, there tends to be lesser fluctuations in the graph.\nIf the graph shows high fluctuations/volatility, despite the returns being high, the Alpha will not be deemed good enough.\nEquity long-short market neutral strategy is used commonly by hedge funds, with the goal of minimizing exposure to the market and profit from the changes in the spread between two stocks.\nDatasets and Data Fields:\nDatasets are a collection of data fields.\nFor example, ‚Äòopen price‚Äô and ‚Äòclose price‚Äô can be found in the price volume dataset"},"Quant/Zerodha-Varsity":{"slug":"Quant/Zerodha-Varsity","filePath":"Quant/Zerodha Varsity.md","title":"Zerodha Varsity","links":["Quant/"],"tags":[],"content":"index\nInvest in Assest Classes:\n\n\nReal Estate\nCommercial or Residential\nTwo ways to earn ‚Üí Rental Income or Capital Appreciation\n\n\nFixed Income (We receive a fixed interest on some principal investment), gives about 5% returns\n\nGovernment Bonds\nFixed Deposit account in bank\nCorporate Bonds\n\n\n\nCommodities (precious metals)\nMost popular ‚Üí Gold and Silver ‚Üí invest in jewelry, Exchange Traded Funds(ETF), or Sovereign Gold Bonds(SGBs)\nIn simple words, government sovereign gold bond scheme is where instead of having¬†physical gold sitting idle in your house, you can invest in gold bonds.\n\n\nEquity (shares/stocks of any company)\nTwo Indian Stock Exchange markets: NSE(National Stock Exchange) and BSE(Bombay Stock Exchange)\nNifty ‚Üí weightage average of top 50 stocks\n\n\nJourney of a Trade:\n\nBroker (like Zerodha Kite) ‚Üí place an order through an broker, which is a corporate entity registered as a trading member with Stock Exchange. Broker holds a stockbroking license through which our orders are placed in actual market. Broker follows SEBI guidelines. Broker charges Brokerage / fee for it‚Äôs servvice.\nStock Exchange (BSE, NSE) ‚Üí bid and asks are listed, if they match trade is executed. This is an orderbook\nClearing Corporation (NSCCL(NSE), ICCL(BSE)) ‚Üí where the trade is cleared, make sure buyer pays and trader transfer shares.\nDepository (NSDL(NSE), CDSL(BSE)) ‚Üí digital place where all stocks details are stored. Brokers are usually connected directly to this Depository by Depository Participants to show it‚Äôs users their stock infos.\n\nIPO, why companies list their stocks ?\nOrigins of a a Business:\nSuppose a person want‚Äôs to start it‚Äôs company for which he needs intial investment, which is generally raised by friends / family / network or Angel Investors in exchange of some shares of that company, these is Seed Round funding. The money raised in seed round is also called Initial Share Capital.\nNow after initial success he wants to add more production units therefore needs more money, so he goes to Venture Capitals(VCs), which specialized in investing startups, and in exchange gives VCs company stocks, note that this stocks are not from existing pool rather new stocks are issued as company has grown.\nAfter this, person can go on multiple funding rounds called Series A, Series B and so on‚Ä¶\nNow after few years of huge successes he want to expand let‚Äôs say globally, so a very large investment is required. For this there are few ways to raise this money and one of them is Initial public offering (IPO) where companies stocks are publically listed on Stock Exchanges.\nInitial public offering (IPO) process:\n\nAppoint a Merchant Banker: he make sure company is following all rules\nApproval from SEBI: Merchant Banker and company go and apply to SEBI with a registration statement which contains all information about company health, financial conditions, departments and managements.\nDraft Red Herring Prospectus (DRHP): all information about company health, financial conditions, departments and managements, their estimated risks and return formated in a single document.\nMarket the IPO: spread awareness about companies going public through IPO.\nBook Building: Company fixes a price band which is range for initial bids.\nClosure: According to median bids in book building stage initial price of stock in Stock Market is finalized\nListing day : when company share/stocks are listed and tradable on stock exchanges.\n\nStock Market:\nthe stock market is an electronic marketplace. Buyers and sellers electronically express their points of view in terms of trade.\nnews or events about company causes fluctuation in market.\nStock Market Index:\nOrder Types:\n\nLimit ‚Üí we specify the bid/ask price and if it‚Äôs lower(for bids) or higher(for asks) than LTP (Last Traded Price) then trade is just registered in orderbook.\nMarket ‚Üí we are matched with best price i.e. lowest(asks) or highest (bids).\n"},"Quant/index":{"slug":"Quant/index","filePath":"Quant/index.md","title":"index","links":["/"],"tags":[],"content":"Home\nHistory of Market and trading: youtu.be/DLg5tyxmXqQ\nA Practicle guide to Quantitative finance Interviews by Xinfeng zhou\nwww.hackerrank.com/contests/gs-india-hackathon-2024/challenges/quant-option-pricing-model\nIMC Lauchpad Program: www.imc.com/in/careers/students-graduates/programs/launchpad\nResearch Papers/Articles:\n\nApr 2019: ABIDES: TOWARDS HIGH-FIDELITY MARKET SIMULATION FOR AI RESEARCH\nSep 2023: C++ design patterns for low-latency applications including high-frequency trading\nHRT Summer Interns projects: www.hudsonrivertrading.com/hrtbeat/intern-spotlight-software-engineering-summer-projects/\n\nwww.hudsonrivertrading.com/hrtbeat/intern-spotlight-hrt-ai-labs-project/\n\nThe empirical work presented in the blogpost is very interesting (congrats to all involved). I want to add to the discussion by mentioning that diffusion models will always under-characterize tail probabilities when your target (e.g. equity returns) is heavy-tailed. This is a mathematical result proven in our recent paper (Tam and Dunson arxiv.org/abs/2501.07763)\n\n\n\n\n\nVarsity by Zerodha\nzerodha.com/varsity/\nIMC Masterclass on Youtube:\nyoutu.be/DgowLNC4X_k\nBasics GK\nData are of two types Quantitative and Qualitative\n\nQuantitative ‚áí you can measure ‚áí Finance is all about numbers ‚áí Quant Finance ‚áí Data-driven, analytical, model-based\nImportant considering factor for Venture capitals, Investors etc.\nQualitative ‚áí  subjective factors like management quality, brand value, regulatory risks, and macroeconomic trends\nImportant considering factor for Private equity, Risk management, HFT, asset pricing etc.\n"},"Random":{"slug":"Random","filePath":"Random.md","title":"Random","links":["/"],"tags":[],"content":"Home\nRandom\n\nLinux wallpapers: wallhaven.cc/hot\nTo make README easily\noverapi CHEATSHEATS\nquickref CHEATSHEATS\nTo make flowcharts (Excalidraw)\nTo make flowcharts (Lucidchart)\ndeepanshu1422/List-Of-Open-Source-Internships-Programs: A curated list of all the open-source internships/Programs (github.com)\nZtype - typing speed\nMarkdown Crash Course (webdevsimplified.com)\nCreating a game in Three.js - LogRocket Blog\nText to stories for socials\nsearch word to get some movie clip\nHacking : www.hacksplaining.com/lessons\n"},"Research":{"slug":"Research","filePath":"Research.md","title":"Research","links":["/"],"tags":[],"content":"Home\nBioTech Research: Futurehouse\nwww.connectedpapers.com/https://hal.science/\nwww.findmypapers.ai/search\nhal.science/\n1Ô∏è‚É£ How to Do Research\nMindset, habits, tools, writing, productivity, and advice.\nüîólnkd.in/e-sjMbwf\n2Ô∏è‚É£ How to Review Scientific Papers\nWhat makes a good review? This guide compiles best practices from ICML, ICLR, CVPR, and other leading conferences.\nüîólnkd.in/efNzn7fz\n3Ô∏è‚É£ How to Write Academic Papers\nA practical checklist-driven guide on writing with clarity, rigor, and reproducibility. Inspired by ICML‚Äôs best practices and more.\nüîólnkd.in/eTtQwn7a\nHope these help you as much as they‚Äôve helped me.\nüìöFeel free to share, bookmark, and contribute here (lnkd.in/eKKM4mKX)!"},"Rust":{"slug":"Rust","filePath":"Rust.md","title":"Rust","links":["/"],"tags":[],"content":"Home\n70% of errors listed in MISRA rules for C++ to avoid error are avoided by RUST by default.\nUse static dispatch instead of dynamic dispatch and don‚Äôt use OOP‚Äôs as much as possible and in case of a vector of trait that is implemented by multiple structs use enum\nexample: youtu.be/0XFq9K7N9o4\nLearning Resources\n\n A 10-minute lightning talk taking you from zero to Rust!\n A half-hour to learn Rust\n Rust Ownership Visualizer\n\nBasics\nRust is a¬†statically typed¬†language, which means that it must know the types of all variables at compile time.\nRust uses the term¬†panicking¬†when a program exits with an error\nRust is an expression-based language.\nIn Rust, projects are typically classified into binary and library projects.\nBinary Project\n\nProduces an executable program,\noutput is a compiled binary file (e.g., .exe, ELF, or Mach-O)\nLibrary Project\nProduces reusable code (a library),\noutput is a .rlib (Rust library) or .so/.dll (dynamic library)\n\n// to make a new binary project :\ncargo init\n\n\n// to run code :\ncargo run\n\n\nfn main() {\n    // Statements here are executed when the compiled binary is called.\n    // Print text to the console.\n    println!(&quot;Hello World!&quot;);\n}\nmacro_rules!\nmacro system that allows meta programming. Instead of generating a function call, macros are expanded into source code that gets compiled with the rest of the program\n// This is a simple macro named `say_hello`.\nmacro_rules! say_hello {\n    // `()` indicates that the macro takes no argument.\n    () =&gt; {\n        // The macro will expand into the contents of this block.\n        println!(&quot;Hello!&quot;)\n    };\n}\n \nfn main() {\n    // This call will expand into `println!(&quot;Hello!&quot;)`\n    say_hello!()\n}\nconditional :\nfn main() {\n\tprintln!(&quot;{}&quot;, is_even(10));\n}\n  \nfn is_even(num: i32) -&gt; bool{\n\tif num%2 == 0 {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}\n\nNote: by default variables in rust are immutable therefore we are require to add mut to make them mutable i.e. variable\n\nloop :\nfn main() {\n\tprintln!(&quot;{}&quot;, fib(5));\n}\n \nfn fib(num: i32) -&gt; i32 {\n\tlet mut first= 0;\n\tlet mut second= 1;\n\t\n\tif num == 1 {\n\t\treturn 0;\n\t}\n\tif num == 2 {\n\t\treturn 1;\n\t}\n\t\n\tfor i in 0..(num-1) {\n\t\tlet temp = second;\n\t\tsecond = second + first;\n\t\tfirst = temp;\n\t}\n\treturn second;\n}\nStrings :\nfn main(){\n\tlet str = String::from(&quot;hello&quot;);\n\tprintln!(&quot;{}&quot;, get_len_of_str(str));\n}\n \nfn get_len_of_str(s: String) -&gt; usize {\n\ts.chars().count()\n}\n\nuse std::io;\n  \nfn main() {\n\tprintln!(&quot;Guess the number!&quot;);\n\t\n\tprintln!(&quot;Please input your guess.&quot;);\n\t\n\tlet mut guess: String = String::new();\n\t\n\tio::stdin()\n\t\t.read_line(&amp;mut guess)\n\t\t.expect(&quot;Failed to read line&quot;);\n\t\n\tprintln!(&quot;You guessed: {}&quot;, guess);\n}\nI/O :\nuse std::io;\n \nfn main(){\n\tprintln!(&quot;Enter a number: &quot;);\n\tlet mut number:String = String::new();\n\t\n\tio::stdin()\n\t\t.read_line(&amp; mut number)\n\t\t.expect(&quot;Failed to read line&quot;);\n\t\n\tprintln!(&quot;You entered: {}&quot;, number);\n}\nThe¬†::¬†syntax in the¬†::new¬†line indicates that¬†new¬†is an associated function of the¬†String¬†type. An¬†associated function is a function that‚Äôs implemented on a type.\nread_line¬†puts whatever the user enters into the string we pass to it, but it also returns a¬†Result¬†value.¬†Result¬†is an¬†enumeration, often called an¬†enum enums give you a way of saying a value is one of a possible set of values. enums give you a way of saying a value is one of a possible set of values.\n\nExample:\n\nuse std::io;\nuse std::cmp::Ordering;\nuse rand::Rng;\n \nfn main(){\n\tprintln!(&quot;Enter a number: &quot;);\n\tlet mut guess:String = String::new();\n\t\n\tio::stdin()\n\t.read_line(&amp;mut guess)\n\t.expect(&quot;Failed to read line&quot;);\n\t\n\t// Shadowing guess\n\tlet guess:u32 = guess.trim().parse().expect(&quot;Please type a number!&quot;);\n\t\n\tprintln!(&quot;You entered: {}&quot;, guess);\n\t\n\tlet mut rng = rand::rng();\n\tlet secret_number = rng.random_range(1..=10);\n\tprintln!(&quot;Random number: {}&quot;, secret_number);\n\t\n\tmatch guess.cmp(&amp;secret_number) {\n\t\tOrdering::Less =&gt; println!(&quot;Too small!&quot;),\n\t\tOrdering::Greater =&gt; println!(&quot;Too big!&quot;),\n\t\tOrdering::Equal =&gt; println!(&quot;You win!&quot;),\n\t}\n}\nShadowing¬†lets us reuse the¬†guess¬†variable name rather than forcing us to create two unique variables, such as¬†guess_str¬†and¬†guess\nData Types (fixed sized, stored in stack) :\nShadowing example:\nfn main() { \n\tlet x = 5; \n\tlet x = x + 1; \n\t\n\t{ \n\t\tlet x = x * 2; \n\t\tprintln!(&quot;The value of x in the inner scope is: {x}&quot;); \n\t} \n\t\n\tprintln!(&quot;The value of x is: {x}&quot;); \n}\n \n// OUTPUT\n// The value of x in the inner scope is: 12 \n// The value of x is: 6\nThe types covered below are of a known size, can be stored on the stack and popped off the stack when their scope is over, and can be quickly and trivially copied to make a new, independent instance if another part of code needs to use the same value in a different scope.\nInteger Types:\n¬†the¬†isize¬†and¬†usize¬†types depend on the architecture of the computer your program is running on, which is denoted in the table as ‚Äúarch‚Äù: 64 bits if you‚Äôre on a 64-bit architecture and 32 bits if you‚Äôre on a 32-bit architecture.\n¬†\n¬†&gt; Integer Literal Notations:\nlet decimal = 42;        // Decimal (Base-10) \nlet hex = 0x2A;          // Hexadecimal (0x prefix) \nlet octal = 0o52;        // Octal (0o prefix) \nlet binary = 0b101010;   // Binary (0b prefix) \nlet byte = b&#039;A&#039;;         // Byte literal (ASCII value of &#039;A&#039; is 65)\n \nprintln!(&quot;Decimal: {}&quot;, decimal); \nprintln!(&quot;Hex: {}&quot;, hex); \nprintln!(&quot;Octal: {}&quot;, octal); \nprintln!(&quot;Binary: {}&quot;, binary); \nprintln!(&quot;Byte: {}&quot;, byte);\n \n// Decimal: 42\n// Hex: 42\n// Octal: 42\n// Binary: 42\n// Byte: 65\nWhen you‚Äôre compiling in release mode with the¬†--release¬†flag, Rust does¬†not¬†include checks for integer overflow that cause panics. Instead, if overflow occurs, Rust performs¬†two‚Äôs complement wrapping. In short, values greater than the maximum value the type can hold ‚Äúwrap around‚Äù to the minimum of the values the type can hold. In the case of a¬†u8, the value 256 becomes 0, the value 257 becomes 1, and so on.\nFloating-Point Types:\nAll floating-point types are signed.\nfn main() {\n    let x = 2.0; // f64\n    let y: f32 = 3.0; // f32\n}\nBoolean Type:\nBooleans are one byte in size.\nfn main() {\n    let t = true;\n    let f: bool = false; // with explicit type annotation\n}\nCharacter Type:\nRust‚Äôs¬†char¬†type is four bytes in size\nfn main() {\n    let c = &#039;z&#039;;\n    let z: char = &#039;‚Ñ§&#039;; // with explicit type annotation\n    let heart_eyed_cat = &#039;üòª&#039;;\n}\nCompound Types:\nRust has two primitive compound types: tuples and arrays.\n\n\nTuple Type: number of values with a variety of types into one compound type\nTuples have a fixed length: once declared, they cannot grow or shrink in size.\nThe tuple without any values has a special name,¬†unit\nfn main() { \n\tlet tup: (i32, f64, u8) = (500, 6.4, 1);\n}\ndestructuring tuple values:\nfn main() {\n    let tup = (500, 6.4, 1);\n\t\n    let (x, y, z) = tup;\n\t\n    println!(&quot;The value of y is: {y}&quot;);\n\t\n\tlet five_hundred = x.0; \n\tlet six_point_four = x.1; \n\tlet one = x.2;\n}\n\n\nArray Type: multiple values of same data type\nfn main() {\n    let a = [1, 2, 3, 4, 5];\n    let a: [i32; 5] = [1, 2, 3, 4, 5];\n    \n    let a = [3; 5]; \n    // let a = [3, 3, 3, 3, 3];\n}\nAccessing memory out of bound would result Rust to panic and would just exit the program instead of accessing random memory like C.\n\n\nFunctions :\nIn function signatures, you¬†must¬†declare the type of each parameter\n\n\nStatements¬†are instructions that perform some action and do not return a value.\nStatements do not return values.\nFunction definitions are also statements\nCreating a variable and assigning a value to it with the¬†let¬†keyword is a statement.\nfn main() {\n    let x = (let y = 6);\n}\n// let y = 6 doesn&#039;t return anything\n// in C assignment return the value (like 6 here)\n \n// This is different from what happens in other languages, \n// such as C and Ruby, where the assignment returns the value\n// of the assignment. In those languages, you can write¬†\n// `x = y = 6`¬†and have both¬†`x`¬†and¬†`y`¬†have the value¬†`6`; \n// that is not the case in Rust.\n\n\nExpressions¬†evaluate to a resultant value. Let‚Äôs look at some examples.\ncalling¬†a function is an expression as it return a value\nCalling a function is an expression.\nCalling a macro is an expression.\nA new scope block created with curly brackets is an expression.\nfn main() {\n    let y = {\n        let x = 3;\n        x + 1\n    };\n \n    println!(&quot;The value of y is: {y}&quot;);\n}\n \n// The value of y is: 4\nNote that the¬†x + 1¬†line doesn‚Äôt have a semicolon at the end, which is unlike most of the lines you‚Äôve seen so far. Expressions do not include ending semicolons. If you add a semicolon to the end of an expression, you turn it into a statement, and it will then not return a value.\nfn main() {\n    let x = plus_one(5);\n    println!(&quot;The value of x is: {x}&quot;);\n}\n \nfn plus_one(x: i32) -&gt; i32 {\n    x + 1;\n}\n \n// The definition of the function¬†`plus_one`¬†says that it will \n// return an¬†`i32`, but statements don‚Äôt evaluate to a value, \n// which is expressed by¬†`()`, the unit type. Therefore, nothing \n// is returned, which contradicts the function definition and \n// results in an error\n\n\nControl Flow :\nBlocks of code associated with the conditions in¬†if¬†expressions are sometimes called¬†arms, just like the arms in¬†match¬†expressions\nfn main() {\n    let number = 3;\n\t\n    if number {\n        println!(&quot;number was three&quot;);\n    }\n}\n \n// In C/C++ this would turn true but in Rust it\n// results in an error as condition mustbe of a bool \nBecause¬†if¬†is an expression, we can use it on the right side of a¬†let¬†statement to assign the outcome to a variable\nfn main() {\n    let condition = true;\n    let number = if condition { 5 } else { 6 };\n    \n    println!(&quot;The value of number is: {number}&quot;);\n}\n\nfn main() {\n    let condition = true;\n    let number = if condition { 5 } else { &quot;six&quot; };\n    println!(&quot;The value of number is: {number}&quot;);\n}\n \n// Would turn into an ERROR as number should have a fix data type\n// as Rust can&#039;t have multiple hypothetical types\nloop:\nfn main(){\n\tlet counter = 0;\n\tlet result = loop {\n\t\tcounter +=1;\n\t\t\n\t\tif counter == 10 {\n\t\t\tbreak counter*2;\t\n\t\t}\n\t}\n\tprintln!(&quot;The result is {result}&quot;);\n}\n \n// OUTPUT: The result is 20\n// value after break statement is returned when break is encountered\nLoop Labels:\nIf you have loops within loops,¬†break¬†and¬†continue¬†apply to the innermost loop at that point. You can optionally specify a¬†loop label¬†on a loop that you can then use with¬†break¬†or¬†continue\nLoop labels must begin with a single quote.\nfn main() {\n    let mut count = 0;\n    &#039;counting_up: loop {\n        println!(&quot;count = {count}&quot;);\n        let mut remaining = 10;\n\t\t\n        loop {\n            println!(&quot;remaining = {remaining}&quot;);\n            if remaining == 9 {\n                break;\n            }\n            if count == 2 {\n                break &#039;counting_up;\n            }\n            remaining -= 1;\n        }\n\t\t\n        count += 1;\n    }\n    println!(&quot;End count = {count}&quot;);\n}\n \n// OUPTUT:\n// count = 0\n// remaining = 10\n// remaining = 9\n// count = 1\n// remaining = 10\n// remaining = 9\n// count = 2\n// remaining = 10\n// End count = 2\nwhile:\nfn main() {\n    let mut number = 3;\n\t\n    while number != 0 {\n        println!(&quot;{number}!&quot;);\n        number -= 1;\n    }\n\t\n    println!(&quot;LIFTOFF!!!&quot;);\n}\nfor:\nfn main() {\n    let a = [10, 20, 30, 40, 50];\n\t\n    for element in a {\n        println!(&quot;the value is: {element}&quot;);\n    }\n}\n\nfn main() {\n    for number in (1..4).rev() {\n        println!(&quot;{number}!&quot;);\n    }\n    println!(&quot;LIFTOFF!!!&quot;);\n}\n \n// 3!  \n// 2!  \n// 1!  \n// LIFTOFF!!!\nOwnership\nyoutu.be/usJDUSrcwqI\nStack: All data stored on the stack must have a known, fixed size\nHeap: When you put data on the heap, you request a certain amount of space. The memory allocator finds an empty spot in the heap that is big enough, marks it as being in use, and returns a¬†pointer, which is the address of that location.\n\nA processor can do its job better if it works on data that‚Äôs close to other data (as it is on the stack) rather than farther away (as it can be on the heap).\n\nOwnership rules :\n\nEach value in Rust has an¬†owner.\nThere can only be one owner at a time.\nWhen the owner goes out of scope, the value will be dropped.\n\n\nSo string literals are stored in stack, therefore even if a string literal is mutable it cannot be modified as it is stored in stack, but a mutable String type, which is used to store unknown size values like values entered during the runtime, is stored in heap and therefore can be modified. In the case of a string literal, we know the contents at compile time, so the text is hardcoded directly into the final executable. This is why string literals are fast and efficient. But these properties only come from the string literal‚Äôs immutability.\n\nTo allocate variable memory from heap for runtime values:\n\nThe memory must be requested from the memory allocator at runtime.\nWe need a way of returning this memory to the allocator when we‚Äôre done with our¬†String (most languages either use Garbage Collector that keep looking for disconnected node or ask us to manually free the memory).\n\n\nRust takes a different path: the memory is automatically returned once the variable that owns it goes out of scope\n\n{\n\tlet s = String::from(&quot;hello&quot;); // s is valid from this point forward\n\t// do stuff with s\n}                                  // this scope is now over, and s is no\n\t\t\t\t\t\t\t\t   // longer valid\n\nWhen a variable goes out of scope, Rust calls drop function, which works like free in C i.e. it frees the allocated space from memory.\n\ndouble free¬†error :\n    let s1 = String::from(&quot;hello&quot;);\n    let s2 = s1;\n\nRust automatically calls the¬†drop¬†function and cleans up the heap memory for variable that goes out of scope. This is a problem: when¬†s2¬†and¬†s1¬†go out of scope, they will both try to free the same memory. This is known as a¬†double free¬†error and is one of the memory safety bugs. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities.\nRust, to ensure memory safety, after the line¬†let s2 = s1;, considers¬†s1¬†as no longer valid.\nThis is process is somewhat like a shallow copying but as original string is no longer valid it‚Äôs called move.\n\nRust will never automatically create ‚Äúdeep‚Äù copies of your data. Therefore, any¬†automatic copying can be assumed to be inexpensive in terms of runtime performance.\n\nWhen you assign a completely new value to an existing variable, Rust will call¬†drop¬†and free the original value‚Äôs memory immediately. Consider this code, for example:\n    let mut s = String::from(&quot;hello&quot;);\n    s = String::from(&quot;ahoy&quot;);\n \n    println!(&quot;{s}, world!&quot;);    // ahoy, world!\nbut what if we don‚Äôt want to invalidate the original string/variable. We make a clone i.e. a deep copy of that variable. To make a clone is expensive\n    let s1 = String::from(&quot;hello&quot;);\n    let s2 = s1.clone();\n \n    println!(&quot;s1 = {s1}, s2 = {s2}&quot;);\nCopy Trait :\nRust has a special annotation called the¬†Copy¬†trait that we can place on types that are stored on the stack (directly only and not indirectly)\nIncase of variable size like a Vectors (Vec&lt;i32&gt;) their pointers are stored but that doesn‚Äôt mean they have Copy trait as actual data is stored in heap\nA type with Drop trait can never have Copy trait\nDrop Trait :\nRust annotation that tells compiler that a type has custom drop function.\nOwnership in Functions :\nPassing a variable to a function will move or copy, just as assignment does.\nfn main() {\n    let s1 = gives_ownership();         // gives_ownership moves its return\n                                        // value into s1\n                                        \n    let s2 = String::from(&quot;hello&quot;);     // s2 comes into scope\n    \n    let s3 = takes_and_gives_back(s2);  // s2 is moved into\n                                        // takes_and_gives_back, which also\n                                        // moves its return value into s3\n} // Here, s3 goes out of scope and is dropped. s2 was moved, so nothing\n\t// happens. s1 goes out of scope and is dropped.\n\t\nfn gives_ownership() -&gt; String {             // gives_ownership will move its\n                                             // return value into the function\n                                             // that calls it\n\t\n    let some_string = String::from(&quot;yours&quot;); // some_string comes into scope\n\t\n    some_string                              // some_string is returned and\n                                             // moves out to the calling\n                                             // function\n}\n\t\n\t// This function takes a String and returns one\nfn takes_and_gives_back(a_string: String) -&gt; String { // a_string comes into\n                                                      // scope\n    a_string  // a_string is returned and moves out to the calling function\n}\nBut we can‚Äôt taking ownership and then returning ownership with every function is a bit tedious. Rust has a feature for using a value without transferring ownership, called¬†references.\nReferences and Borrowing\nA reference is like a pointer in that it‚Äôs an address we can follow to access the data stored at that address; that data is owned by some other variable. Unlike a pointer, a reference is guaranteed to point to a valid value of a particular type for the life of that reference.\nfn calculate_length(s: &amp;String) -&gt; usize { // s is a reference to a String\n    s.len()\n} // Here, s goes out of scope. But because s does not have ownership of what\n  // it refers to, the value is not dropped.\nThe scope in which the variable¬†s¬†is valid is the same as any function parameter‚Äôs scope, but the value pointed to by the reference is not dropped when¬†s¬†stops being used, because¬†s¬†doesn‚Äôt have ownership.\nWe call the action of creating a reference borrowing.\nJust as variables are immutable by default, so are¬†references.\nBorrowing rules :\n\n\nAt any given time you can either have one mutable reference or any number of immutable reference\nThe benefit of having this restriction is that Rust can prevent data races at compile time. A data race is similar to a race condition and happens when these three behaviors occur:\n\nTwo or more pointers access the same data at the same time.\nAt least one of the pointers is being used to write to the data.\nThere‚Äôs no mechanism being used to synchronize access to the data.\n\nlet mut s = String::from(&quot;hello&quot;);\n \nlet r1 = &amp;mut s;\nlet r2 = &amp;mut s;\n \nprintln!(&quot;{},¬†{}&quot;,¬†r1,¬†r2);\n  |\n4 |     let r1 = &amp;mut s;\n  |              ------ first mutable borrow occurs here\n5 |     let r2 = &amp;mut s;\n  |              ^^^^^^ second mutable borrow occurs here\n6 |\n7 |     println!(&quot;{}, {}&quot;, r1, r2);\n  |                        -- first borrow later used here\nWe also cannot have a mutable reference while we have an immutable one to the same value.\nUsers of an immutable reference don‚Äôt expect the value to suddenly change out from under them! However, multiple immutable references¬†are¬†allowed.\nlet mut s = String::from(&quot;hello&quot;);\n \nlet r1 = &amp;s; // no problem\nlet r2 = &amp;s; // no problem\nlet r3 = &amp;mut s; // BIG PROBLEM\n \nprintln!(&quot;{}, {}, and {}&quot;, r1, r2, r3);\n\nNote that a reference‚Äôs scope starts from where it is introduced and continues through the last time that reference¬†is¬†used.\n\nlet mut s = String::from(&quot;hello&quot;);\n \nlet r1 = &amp;s; // no problem\nlet r2 = &amp;s; // no problem\nprintln!(&quot;{r1} and {r2}&quot;);\n// variables r1 and r2 will not be used after this point\n \nlet r3 = &amp;mut s; // no problem\nprintln!(&quot;{r3}&quot;);\n\n\nReference must always be valid (i.e. referenced value must have long enough¬†lifetime)\nIn Rust, the compiler guarantees that references will never be dangling references: if you have a reference to some data, the compiler will ensure that the data will not go out of scope before the reference to¬†the¬†data¬†does.\nfn main() {\n    let reference_to_nothing = dangle();\n}\n \nfn dangle() -&gt; &amp;String { // dangle returns a reference to a String\n    let s = String::from(&quot;hello&quot;); // s is a new String\n    &amp;s // we return a reference to the String, s\n} // Here, s goes out of scope, and is dropped. Its memory goes away.\n¬†¬†//¬†Danger!\n\n\nSlice Type :\nSlices¬†let you reference a contiguous sequence of elements in a¬†collection¬†rather than the whole collection. A slice is a kind of reference, so it does not have ownership.\nUnlike the built-in array and tuple types, the data these collections point to is stored on the heap, which means the amount of data does not need to be known at compile time and can grow or shrink as the¬†program¬†runs.\ncollection example vector, string, hash¬†maps\n// Example 1:\nfn first_word(s: &amp;String) -&gt; usize {\n    let bytes = s.as_bytes();\n    for (i, &amp;item) in bytes.iter().enumerate() {\n        if item == b&#039; &#039; {\n            return i;\n        }\n    }\n    s.len()\n}\n \nfn main() {\n    let mut s = String::from(&quot;hello world&quot;);\n    let word = first_word(&amp;s); // word will get the value 5\n    s.clear(); // this empties the String, making it equal to &quot;&quot;\n    // `word` still has the value `5` here, but `s` no longer has any content\n    // that we could meaningfully use with the value `5`, so `word` is now\n    // totally invalid!\n}\nThis program compiles without any errors and would also do so if we used¬†word¬†after calling¬†s.clear(). Because¬†word¬†isn‚Äôt connected to the state of¬†s¬†at all,¬†word¬†still contains the value¬†5. We could use that value¬†5¬†with the variable¬†s¬†to try to extract the first word out, but this would be a bug because the contents of¬†s¬†have changed since we saved¬†5¬†in¬†word.\nHaving to worry about the index in¬†word¬†getting out of sync with the data in¬†s¬†is tedious and error prone!\nRust has a solution to this problem: string slices.\nString Slices :\nA string slice is a value that is made up of a reference to the starting point of the slice and the number of elements in the slice.\nlet s = String::from(&quot;hello world&quot;);\n \nlet hello = &amp;s[0..5];\nlet world = &amp;s[6..11];\nlet s = String::from(&quot;hello&quot;);\n \nlet slice1 = &amp;s[0..2];  \nlet slice2 = &amp;s[..2];    // both slice1 and slice2 are same\n \nlet len = s.len();\n \nlet slice3 = &amp;s[3..len];  \nlet slice4 = &amp;s[3..];    // both slice3 and slice4 are same\n// Rewrite Example 1 first_word function to return a slice\nfn first_word(s: &amp;String) -&gt; &amp;str {\n    let bytes = s.as_bytes();\n \n    for (i, &amp;item) in bytes.iter().enumerate() {\n        if item == b&#039; &#039; {\n            return &amp;s[0..i];\n        }\n    }\n \n    &amp;s[..]\n}\nSo as string literals are can point to any String &amp;String can be written as &amp;str and this is better because, &amp;str can hold both String and string literal i.e. string slices\nStructs\nA¬†struct, or¬†structure, is a custom data type that lets you package together and name multiple related values that make up a meaningful group.\nstruct User {\n    active: bool,\n    username: String,\n    email: String,\n    sign_in_count: u64,\n}\n \nfn main() {\n    let mut user1 = User {\n        active: true,\n        username: String::from(&quot;someusername123&quot;),\n        email: String::from(&quot;someone@example.com&quot;),\n        sign_in_count: 1,\n    };\n    user1.email = String::from(&quot;anotheremail@example.com&quot;);\n}\n \nfn build_user(email: String, username: String) -&gt; User {\n    User {\n        active: true,\n        username,\n        email,\n        sign_in_count: 1,\n    }\n}\nfn main() {\n    // --snip--\n    let user2 = User {\n        active: user1.active,\n        username: user1.username,\n        email: String::from(&quot;another@example.com&quot;),\n        sign_in_count: user1.sign_in_count,\n    };\n}\n \n// struct update syntax:\nfn main() {\n    // --snip--\n    let user2 = User {\n        email: String::from(&quot;another@example.com&quot;),\n        ..user1\n    };\n}\n\nNote that the entire instance must be mutable; Rust doesn‚Äôt allow us to mark only certain fields as mutable. As with any expression, we can construct a new instance of the struct as the last expression in the function body to implicitly return that new instance.\n\nIn this example, we can no longer use¬†user1¬†as a whole after creating¬†user2¬†as active and sign_in_count have Copy trait they won‚Äôt be dropped, but the¬†String¬†in the¬†username¬†field of¬†user1¬†was moved into¬†user2.\nTuple Struct :\nTuple structs have the added meaning the struct name provides but don‚Äôt have names associated with their fields; rather, they just have the types of the fields.\nstruct Color(i32, i32, i32);\nstruct Point(i32, i32, i32);\n \nfn main() {\n    let black = Color(0, 0, 0);\n    let origin = Point(0, 0, 0);\n}\nNote that the¬†black¬†and¬†origin¬†values are different types because they‚Äôre instances of different tuple structs. Each struct you define is its own type, even though the fields within the struct might have the same types. For example, a function that takes a parameter of type¬†Color¬†cannot take a¬†Point¬†as an argument, even though both types are made up of three¬†i32¬†values.\nUnit-like Structs :\nstructs that don‚Äôt have any fields, they behave similarly to¬†(). Unit-like structs can be useful when you need to implement a trait on some type but don‚Äôt have any data that you want to store in the type itself.\nstruct AlwaysEqual;\n \nfn main() {\n    let subject = AlwaysEqual;\n}\n\nNote that accessing fields of a borrowed struct instance does not move the field values, which is why you often see borrows of structs\n\nAdding Derived Traits :\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n \nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n \n    println!(&quot;rect1 is {}&quot;, rect1);\n}\n \n// OUTPUT: error[E0277]: `Rectangle` doesn&#039;t implement `std::fmt::Display`\nThe println! macro can do many kinds of formatting, and by default, the curly brackets {} tell println! to use formatting known as Display trait: output intended for direct end user consumption. The primitive types we‚Äôve seen so far implement Display by default\nBut with structs, the way println! should format the output is less clear because there are more display possibilities: Do you want commas or not? Do you want to print the curly brackets? Should all the fields be shown?\nPutting the specifier :? inside the curly brackets tells println! we want to use an output format called Debug. The Debug trait enables us to print our struct in a way that is useful for developers so we can see its value while we‚Äôre debugging our code.\nRust does include functionality to print out debugging information, but we have to explicitly opt in to make that functionality available for our struct. To do that, we add the outer attribute #[derive(Debug)] just before the struct definition\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n \nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n \n    println!(&quot;rect1 is {rect1:?}&quot;);\n}\nAnother way to print out a value using the Debug format is to use the dbg! macro, which takes ownership of an expression (as opposed to println!, which takes a reference), prints the file and line number of where that dbg! macro call occurs in your code along with the resultant value of that expression, and returns ownership of the value.\n\nNote: Calling the dbg! macro prints to the standard error console stream (stderr), as opposed to println!, which prints to the standard output console stream (stdout).\n\nMethod\nMethods are similar to functions: we declare them with the fn keyword and a name, they can have parameters and a return value, and they contain some code that‚Äôs run when the method is called from somewhere else. Unlike functions, methods are defined within the context of a struct (or an enum or a trait object), and their first parameter is always self, which represents the instance of the struct the method is being called on.\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n \nimpl Rectangle {\n    fn area(&amp;self) -&gt; u32 {\n        self.width * self.height\n    }\n}\n \nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n \n    println!(\n        &quot;The area of the rectangle is {} square pixels.&quot;,\n        rect1.area()\n    );\n}\nEverything within this impl (implementation) block will be associated with the Rectangle type.\nThe method syntax goes after an instance: we add a dot followed by the method name, parentheses, and any arguments.\nIn the signature for area, we use &amp;self instead of rectangle: &amp;Rectangle. The &amp;self is actually short for self: &amp;Self. Within an impl block, the type Self is an alias for the type that the impl block is for. Methods must have a parameter named self of type Self for their first parameter.\nIf we wanted to change the instance that we‚Äôve called the method on as part of what the method does, we‚Äôd use &amp;mut self as the first parameter.\nOften, but not always, when we give a method the same name as a field we want it to only return the value in the field and do nothing else. Methods like this are called Getters, and Rust does not implement them automatically for struct fields as some other languages do.\nExample on how to handle more than one parameters in a method :\nimpl Rectangle {\n    fn area(&amp;self) -&gt; u32 {\n        self.width * self.height\n    }\n \n    fn can_hold(&amp;self, other: &amp;Rectangle) -&gt; bool {\n        self.width &gt; other.width &amp;&amp; self.height &gt; other.height\n    }\n}\n \nfn main() {\n    let rect1 = Rectangle {\n        width: 30,\n        height: 50,\n    };\n    let rect2 = Rectangle {\n        width: 10,\n        height: 40,\n    };\n    let rect3 = Rectangle {\n        width: 60,\n        height: 45,\n    };\n \n    println!(&quot;Can rect1 hold rect2? {}&quot;, rect1.can_hold(&amp;rect2));\n    println!(&quot;Can rect1 hold rect3? {}&quot;, rect1.can_hold(&amp;rect3));\n}\nAssociated functions:\nAll functions defined within an impl block are called associated functions because they‚Äôre associated with the type named after the impl\nAssociated functions that have self as their first parameter are called Methods because they use self.\nAssociated functions that aren‚Äôt methods are often used for constructors that will return a new instance of the struct.\nTo call this associated function, we use the :: syntax with the struct name.\n// here square is a constructor\nimpl Rectangle {\n    fn square(size: u32) -&gt; Self {\n        Self {\n            width: size,\n            height: size,\n        }\n    }\n}\n \nfn main(){\n\tlet sq = Rectangle::square(3);\n}\nEnum (enumerations)\nEnums allow you to define a type by enumerating its possible variants (value is one of a possible set of values).\n// Instead of this:\nenum IpAddrKind {\n\tV4,\n\tV6,\n}\n \nstruct IpAddr {\n\tkind: IpAddrKind,\n\taddress: String,\n}\n \nlet home = IpAddr {\n\tkind: IpAddrKind::V4,\n\taddress: String::from(&quot;127.0.0.1&quot;),\n};\n \nlet loopback = IpAddr {\n\tkind: IpAddrKind::V6,\n\taddress: String::from(&quot;::1&quot;),\n};\n \n// Use this:\nenum IpAddr {\n\tV4(String),\n\tV6(String),\n}\n \nlet home = IpAddr::V4(String::from(&quot;127.0.0.1&quot;));\n \nlet loopback = IpAddr::V6(String::from(&quot;::1&quot;));\njust as we‚Äôre able to define methods on structs using impl, we‚Äôre also able to define methods on enums.\nenum Message {\n    Quit,\n    Move { x: i32, y: i32 },\n    Write(String),\n    ChangeColor(i32, i32, i32),\n}\n \nimpl Message {\n\tfn call(&amp;self) {\n\t\t// method body would be defined here\n\t}\n}\n \nlet m = Message::Write(String::from(&quot;hello&quot;));\nm.call();\n\nNull References: The Billion Dollar Mistake,‚Äù Tony Hoare, the inventor of null, has this to say, It was a billion dollar mistake\n\nHowever, the concept that null is trying to express is still a useful one: a null is a value that is currently invalid or absent for some reason. Therefore Rust use enum Option&lt;T&gt; which represent a value that might be present (Some(T)) or might be absent (None).\nenum Option&lt;T&gt; {\n    Some(T), // ‚úÖ Holds a value of type T\n    None,    // ‚ùå Represents no value\n}\n    let some_number = Some(5);\n    let some_char = Some(&#039;e&#039;);\n    \n    let absent_number: Option&lt;i32&gt; = None;\nfn main() {\n\tlet x: i8 = 5;\n\tlet y: Option&lt;i8&gt; = Some(5);\n\t\n\tlet sum = x + y;\n\tprintln!(&quot;sum is {sum}&quot;);\n}\n// Error :\n// no implementation for i8 + Option&lt;i8&gt;\n \n// Rust doesn‚Äôt understand how to add an i8 and an Option&lt;i8&gt;,\n// because they‚Äôre different types.\n \nfn main() {\n    let x: i8 = 5;\n\tlet y: Option&lt;i8&gt; = Some(5);\n    \n    match y {\n        Some(x) =&gt; println!(&quot;{} is equal to&quot;, x, y),\n        None =&gt; println!(&quot;No value found!&quot;),\n    }\n}\n \nfn main() {\n    let x: i8 = 6;\n\tlet y: Option&lt;i8&gt; = Some(5);\n    \n    match y {\n        Some(val) =&gt; \n        {\n            if val == x {\n                println!(&quot;{} is equal to {}&quot;, val, x);\n            } else {\n                println!(&quot;{} is not equal to {}&quot;, val, x);\n            }\n        },\n        None =&gt; println!(&quot;No value found!&quot;),\n    }\n}\n \n// OUTPUT:\n// 5 is not equal to 6\nfn main() {\n    let number = Some(42);\n    \n    if let Some(n) = number {\n        println!(&quot;The number is: {}&quot;, n);\n    }\n}\nControl Flow Constructs\nmatch :\ncompare a value against a series of patterns and then execute code based on which pattern matches\ncompiler confirms that all possible cases are handled.\nvalues go through each pattern in a match, and at the first pattern the value ‚Äúfits,‚Äù the value falls into the associated code block to be used during execution.\nenum Coin {\n    Penny,\n    Nickel,\n    Dime,\n    Quarter,\n}\n \nfn value_in_cents(coin: Coin) -&gt; u8 {\n    match coin {\n        Coin::Penny =&gt; 1,\n        Coin::Nickel =&gt; 5,\n        Coin::Dime =&gt; 10,\n        Coin::Quarter =&gt; 25,\n    }\n}\nmatch arms. An arm has two parts: a pattern and some code. The first arm here has a pattern that is the value Coin::Penny and then the =&gt; operator that separates the pattern and the code to run\nThe code associated with each arm is an expression, and the resultant value of the expression in the matching arm is the value that gets returned for the entire match expression.\nCatch all arm:\n    let dice_roll = 9;\n    match dice_roll {\n        3 =&gt; add_fancy_hat(),\n        7 =&gt; remove_fancy_hat(),\n        other =&gt; move_player(other),\n    }\n    \n    fn add_fancy_hat() {}\n    fn remove_fancy_hat() {}\n    fn move_player(num_spaces: u8) {}\n    \n// This code compiles, even though we haven‚Äôt listed all the possible values a `u8` can have, because the last pattern (a variable named other) will match all values not specifically listed.\n \n// here other iss catch all arm\nRust default catch all pattern : _\n    let dice_roll = 9;\n    match dice_roll {\n        3 =&gt; add_fancy_hat(),\n        7 =&gt; remove_fancy_hat(),\n        _ =&gt; reroll(),\n    }\n    \n    fn add_fancy_hat() {}\n    fn remove_fancy_hat() {}\n    fn reroll() {}\nif let (Concise Control Flow)\nmatch one pattern while ignoring the rest.\nenum Coin {\n    Penny,\n    Nickel,\n    Dime,\n    Quarter,\n}\n \nfn main() {\n    let acoin: Coin = Coin::Nickel;\n    \n    if let Coin::Penny = acoin {\n        println!(&quot;It&#039;s a Penny!&quot;);\n    } else {\n        println!(&quot;It&#039;s not a Penny&quot;);\n    }\n}\n \n// OUTPUT: \n// It&#039;s not a Penny\n\nWhy we use = instead of == in if let?\n\nif let does not assign values‚Äîit matches patterns.\nif let Coin::Penny = acoin {}\nChecks if acoin is Coin::Penny and destructures the value if it matches.\n\n\nPackages, Crates and Modules\nA package can contain multiple binary crates and optionally one library crate\n\nPackages: A Cargo feature that lets you build, test, and share crates\nCrates: A tree of modules that produces a library or executable\nModules and use: Let you control the organization, scope, and privacy of paths\nPaths: A way of naming an item, such as a struct, function, or module\n\nA crate is the smallest amount of code that the Rust compiler considers at a time.\nBinary Project\n\nProduces an executable program,\nEach must have a function called main that defines what happens when the executable runs,\noutput is a compiled binary file (e.g., .exe, ELF, or Mach-O)\nLibrary Project\nProduces reusable code (a library),\nLibrary crates don‚Äôt have a main function, and they don‚Äôt compile to an executable,\noutput is a .rlib (Rust library) or .so/.dll (dynamic library)\n\nThe crate root is a source file that the Rust compiler starts from and makes up the root module of your crate\nA package is a bundle of one or more crates that provides a set of functionality.\nIn the crate root file, you can declare new modules; say you declare a ‚Äúgarden‚Äù module with mod garden;\nThe compiler will look for the module‚Äôs code in these places:\n\nInline, within curly brackets that replace the semicolon following mod garden\nIn the file src/garden.rs\nIn the file src/garden/mod.rs\nFor example, an Asparagus type in the garden vegetables module would be found at crate::garden::vegetables::Asparagus.\n\nCode within a module is private from its parent modules by default. To make a module public, declare it with pub mod instead of mod. To make items within a public module public as well, use pub before their declarations.\nbackyard\n‚îú‚îÄ‚îÄ Cargo.lock\n‚îú‚îÄ‚îÄ Cargo.toml\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ garden\n    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ vegetables.rs\n    ‚îú‚îÄ‚îÄ garden.rs\n    ‚îî‚îÄ‚îÄ main.rs\nWithin a scope, the use keyword creates shortcuts to items to reduce repetition of long paths. Note that use only creates the shortcut for the particular scope in which the use occurs.\nAdding use and a path in a scope is similar to creating a symbolic link in the filesystem.\n// main.rs :\nuse crate::garden::vegetables::Asparagus;\n \npub mod garden;\n \nfn main() {\n    let plant = Asparagus {};\n    println!(&quot;I&#039;m growing {plant:?}!&quot;);\n}\n// garden.rs\npub mod vegetables;\n// vegetables.rs\n#[derive(Debug)]\npub struct Asparagus {}\npaths :\nTo show Rust where to find an item in a module tree, we use a path. A path can take two forms:\n\nAn absolute path is the full path starting from a crate root; for code from an external crate, the absolute path begins with the crate name, and for code from the current crate, it starts with the literal crate.\nA relative path starts from the current module and uses self, super, or an identifier in the current module.\n\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n \npub fn eat_at_restaurant() {\n    // Absolute path\n    crate::front_of_house::hosting::add_to_waitlist();\n    \n    // Relative path\n    front_of_house::hosting::add_to_waitlist();\n}\nWe can construct relative paths that begin in the parent module, rather than the current module or the crate root, by using super at the start of the path.\n// instead of this :\nuse std::cmp::Ordering;\nuse std::io;\n \n// code this :\nuse std::{cmp::Ordering, io};\n \n \n \n// and instead of this :\nuse std::io;\nuse std::io::Write;\n \n// code this :\nuse std::io::{self, Write};\nMaking structs and enums Public :\nIf we use pub before a struct definition, we make the struct public, but the struct‚Äôs fields will still be private, unless we explicitly specify.\nmod back_of_house {\n    pub struct Breakfast {\n        pub toast: String,\n        seasonal_fruit: String,\n    }\n    \n    impl Breakfast {\n        pub fn summer(toast: &amp;str) -&gt; Breakfast {\n            Breakfast {\n                toast: String::from(toast),\n                seasonal_fruit: String::from(&quot;peaches&quot;),\n            }\n        }\n    }\n}\n \npub fn eat_at_restaurant() {\n    // Order a breakfast in the summer with Rye toast\n    let mut meal = back_of_house::Breakfast::summer(&quot;Rye&quot;);\n    // Change our mind about what bread we&#039;d like\n    meal.toast = String::from(&quot;Wheat&quot;);\n    println!(&quot;I&#039;d like {} toast please&quot;, meal.toast);\n    \n    // The next line won&#039;t compile if we uncomment it; we&#039;re not allowed\n    // to see or modify the seasonal fruit that comes with the meal\n    // meal.seasonal_fruit = String::from(&quot;blueberries&quot;);\n}\nIn contrast, if we make an enum public, all of its variants are then public.\nmod back_of_house {\n    pub enum Appetizer {\n        Soup,\n        Salad,\n    }\n}\n \npub fn eat_at_restaurant() {\n    let order1 = back_of_house::Appetizer::Soup;\n    let order2 = back_of_house::Appetizer::Salad;\n}\nuse and super keyword :\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n \nuse crate::front_of_house::hosting;\n \nmod customer {\n    pub fn eat_at_restaurant() {\n        hosting::add_to_waitlist();\n    }\n}\n \n// COMPILE TIME ERROR\n// eat_at_restaurant function into a new child module\n// named customer, which is then a different scope than\n// the `use` statement, so the function body won‚Äôt compile.\n \n// To fix this error we can either use `super`:\nmod customer {\n    pub fn eat_at_restaurant() {\n        super::hosting::add_to_waitlist();\n    }\n}\n \n// or use `pub use`:\npub use crate::front_of_house::hosting;\nas keyword :\nsolution to the problem of bringing two types of the same name into the same scope with use: after the path, we can specify as and a new local name, or alias, for the type.\nuse std::fmt::Result;\nuse std::io::Result as IoResult;\n \nfn function1() -&gt; Result {\n    // --snip--\n}\n \nfn function2() -&gt; IoResult&lt;()&gt; {\n    // --snip--\n}\nglob operator :\nIf we want to bring all public items defined in a path into scope, we can specify that path followed by the * glob operator:\nuse std::collections::*;\nCollections\nVectors (works as stack) :\n// here we specify the data type and create \n// new empty vector \nlet v: Vec&lt;i32&gt; = Vec::new();\n \n// here Rust infer the type from `vec!` macro\nlet mut v = vec![1, 2, 3];\n// the push pop functions works as Stack\nv.push(5);\nv.push(6);\nv.push(7);\nv.push(8);\nmatch v.pop() {\n\tSome(num) =&gt; println!(&quot;{num}&quot;),\n\tNone =&gt; println!(&quot;its empty&quot;)\n}\nThere are two ways to reference a value stored in a vector: via indexing or by using the get method.\nlet v = vec![1, 2, 3, 4, 5];\n \n// using indexing :\nlet third: &amp;i32 = &amp;v[2];\nprintln!(&quot;The third element is {third}&quot;);\n \n// using `get` :\nlet third: Option&lt;&amp;i32&gt; = v.get(2);\nmatch third {\n\tSome(third) =&gt; println!(&quot;The third element is {third}&quot;),\n\tNone =&gt; println!(&quot;There is no third element.&quot;),\n}\nWhen we run this code, the first [] method will cause the program to panic because it references a nonexistent element. This method is best used when you want your program to crash if there‚Äôs an attempt to access an element past the end of the vector.\nWhen the get method is passed an index that is outside the vector, it returns None without panicking. You would use this method if accessing an element beyond the range of the vector may happen occasionally under normal circumstances.\nIterating over vectors :\nlet v = vec![100, 32, 57];\nfor i in &amp;v {\n\tprintln!(&quot;{i}&quot;);\n}\n \n// using mutable referencex :\nlet mut v = vec![100, 32, 57];\nfor i in &amp;mut v {\n\t*i += 50;\n}\n// To change the value that the mutable reference \n// refers to, we have to use the `*` dereference\n// operator to get to the value in `i` before we \n// can use the `+=` operator.\nStrings :\nRust has only one string type in the core language, which is the string slice str that is usually seen in its borrowed form &amp;str.\nString           ‚áí Heap allocated, mutable\nstring literal ‚áí Stack allocated, immutable\nstring slices ‚áí reference to String or string literal\nlet data = &quot;initial contents&quot;;\nlet s = data.to_string();\n// the method also works on a literal directly:\nlet s = &quot;initial contents&quot;.to_string();\n \n// or better  \nlet s = String::from(&quot;initial contents&quot;);\nlet s1 = String::from(&quot;Hello, &quot;);\nlet s2 = String::from(&quot;world!&quot;);\nlet s3 = s1 + &amp;s2; // note s1 has been moved here and can no longer be used\nlet s1 = String::from(&quot;tic&quot;);\nlet s2 = String::from(&quot;tac&quot;);\nlet s3 = String::from(&quot;toe&quot;);\n \nlet s = format!(&quot;{s1}-{s2}-{s3}&quot;);\n \n// This code also sets `s` to `tic-tac-toe`. \n// The `format!` macro works like `println!`, but \n// instead of printing the output to the screen, \n// it returns a `String` with the contents.\nString slices :\nlet hello = String::from(&quot;Hola&quot;);\nlet h = &amp;hello[0..2];\nprintln!(&quot;{h}&quot;);\n \n// OUTPUT : Ho\nIterating over Strings :\nfor c in &quot;Hola&quot;.chars() {\n    println!(&quot;{c}&quot;);\n}\n \n// OUTPUT :\n// H\n// o\n// l\n// a\nHash Maps :\nThe type HashMap&lt;K, V&gt; stores a mapping of keys of type K to values of type V using a hashing function, which determines how it places these keys and values into memory.\nuse std::collections::HashMap;\n \nlet mut scores = HashMap::new();\n \nscores.insert(String::from(&quot;Blue&quot;), 10);\nscores.insert(String::from(&quot;Yellow&quot;), 50);\n \nlet team_name = String::from(&quot;Blue&quot;);\nlet score = scores.get(&amp;team_name).copied().unwrap_or(0);\n \nfor (key, value) in &amp;scores {\n        println!(&quot;{key}: {value}&quot;);\n    }\nhash maps are homogeneous: all of the keys must have the same type, and all of the values must have the same type.\nuse std::collections::HashMap;\n \nlet field_name = String::from(&quot;Favorite color&quot;);\nlet field_value = String::from(&quot;Blue&quot;);\n \nlet mut map = HashMap::new();\nmap.insert(field_name, field_value);\n// field_name and field_value are invalid at this point\n// We aren‚Äôt able to use the variables `field_name` and \n// `field_value` after they‚Äôve been moved into the hash \n// map with the call to `insert`.\nOverwriting a value :\nuse std::collections::HashMap;\n \nlet mut scores = HashMap::new();\nscores.insert(String::from(&quot;Blue&quot;), 10);\nscores.insert(String::from(&quot;Blue&quot;), 25);\nprintln!(&quot;{scores:?}&quot;);\n \n// OUTPUT : \n// {&quot;Blue&quot;: 25}\nAdding a Key and Value Only If a Key Isn‚Äôt Present :\nHash maps have a special API for this called entry that takes the key you want to check as a parameter. The return value of the entry method is an enum called Entry that represents a value that might or might not exist. Let‚Äôs say we want to check whether the key for the Yellow team has a value associated with it. If it doesn‚Äôt, we want to insert the value 50, and the same for the Blue team.\nuse std::collections::HashMap;\n \nlet mut scores = HashMap::new();\nscores.insert(String::from(&quot;Blue&quot;), 10);\n \nscores.entry(String::from(&quot;Yellow&quot;)).or_insert(50);\nscores.entry(String::from(&quot;Blue&quot;)).or_insert(50);\n \nprintln!(&quot;{scores:?}&quot;);\n \n// OUTPUT : \n// {&quot;Yellow&quot;: 50, &quot;Blue&quot;: 10}\nUpdating a Value based on Old Value :\nuse std::collections::HashMap;\n \nlet text = &quot;hello world wonderful world&quot;;\nlet mut map = HashMap::new();\n \nfor word in text.split_whitespace() {\n\tlet count = map.entry(word).or_insert(0);\n\t*count += 1;\nby }\nprintln!(&quot;{map:?}&quot;);\n \n// OUTPUT :\n// {&quot;world&quot;: 2, &quot;hello&quot;: 1, &quot;wonderful&quot;: 1}\n\nBy default, HashMap uses a hashing function called SipHash that can provide resistance to denial-of-service (DoS) attacks involving hash tables.\n\nError Handling\nRust groups errors into two major categories: recoverable and unrecoverable errors. For a recoverable error, such as a file not found error, we most likely just want to report the problem to the user and retry the operation. Unrecoverable errors are always symptoms of bugs, such as trying to access a location beyond the end of an array, and so we want to immediately stop the program.\nMost languages don‚Äôt distinguish between these two kinds of errors and handle both in the same way, using mechanisms such as exceptions. Rust doesn‚Äôt have exceptions. Instead, it has the type Result&lt;T, E&gt; for recoverable errors and the panic! macro that stops execution when the program encounters an unrecoverable error.\nUnrecoverable Errors with panic! :\nBy default, when a panic occurs the program starts unwinding, which means Rust walks back up the stack and cleans up the data from each function it encounters. However, walking back and cleaning up is a lot of work. Rust, therefore, allows you to choose the alternative of immediately aborting, which ends the program without cleaning up.\nMemory that the program was using will then need to be cleaned up by the operating system. If in your project you need to make the resultant binary as small as possible, you can switch from unwinding to aborting upon a panic by adding panic = &#039;abort&#039; to the appropriate [profile] sections in your Cargo.toml file. For example, if you want to abort on panic in release mode, add this:\n[profile.release]\npanic = &#039;abort&#039;\nfn main() {\n    panic!(&quot;crash and burn&quot;);\n}\nWhen you run the program, you‚Äôll see something like this:\n$ cargo run\n   Compiling panic v0.1.0 (file:///projects/panic)\n    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.25s\n     Running `target/debug/panic`\nthread &#039;main&#039; panicked at src/main.rs:2:5:\ncrash and burn\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nThe note: line tells us that we can set the RUST_BACKTRACE environment variable to get a backtrace of exactly what happened to cause the error. A backtrace is a list of all the functions that have been called to get to this point.\nIn order to get backtraces with this information, debug symbols must be enabled. Debug symbols are enabled by default when using cargo build or cargo run without the --release flag.\nRecoverable Errors with Result :\nResult enum is defined as having two variants, Ok and Err\nenum Result&lt;T, E&gt; {\n    Ok(T),\n    Err(E),\n}\nuse std::fs::File;\n \nfn main() {\n    let greeting_file_result = File::open(&quot;hello.txt&quot;);\n \n    let greeting_file = match greeting_file_result {\n        Ok(file) =&gt; file,\n        Err(error) =&gt; panic!(&quot;Problem opening the file: {error:?}&quot;),\n    };\n}\nThe return type of File::open is a Result&lt;T, E&gt;. The generic parameter T has been filled in by the implementation of File::open with the type of the success value, std::fs::File, which is a file handle. The type of E used in the error value is std::io::Error. This return type means the call to File::open might succeed and return a file handle that we can read from or write to. The function call also might fail: for example, the file might not exist, or we might not have permission to access the file. The File::open function needs to have a way to tell us whether it succeeded or failed and at the same time give us either the file handle or error information. This information is exactly what the Result enum conveys.\nHowever, we want to take different actions for different failure reasons. If File::open failed because the file doesn‚Äôt exist, we want to create the file and return the handle to the new file. If File::open failed for any other reason we want the code to panic!\nuse std::fs::File;\nuse std::io::ErrorKind;\n \nfn main() {\n    let greeting_file_result = File::open(&quot;hello.txt&quot;);\n \n    let greeting_file = match greeting_file_result {\n        Ok(file) =&gt; file,\n        Err(error) =&gt; match error.kind() {\n            ErrorKind::NotFound =&gt; match File::create(&quot;hello.txt&quot;) {\n                Ok(fc) =&gt; fc,\n                Err(e) =&gt; panic!(&quot;Problem creating the file: {e:?}&quot;),\n            },\n            other_error =&gt; {\n                panic!(&quot;Problem opening the file: {other_error:?}&quot;);\n            }\n        },\n    };\n}\nsame above code using closures :\nuse std::fs::File;\nuse std::io::ErrorKind;\n \nfn main() {\n    let greeting_file = File::open(&quot;hello.txt&quot;).unwrap_or_else(|error| {\n        if error.kind() == ErrorKind::NotFound {\n            File::create(&quot;hello.txt&quot;).unwrap_or_else(|error| {\n                panic!(&quot;Problem creating the file: {error:?}&quot;);\n            })\n        } else {\n            panic!(&quot;Problem opening the file: {error:?}&quot;);\n        }\n    });\n}\nunwrap :\nThe unwrap method is a shortcut method implemented just like the match expression\nIf the Result value is the Ok variant, unwrap will return the value inside the Ok. If the Result is the Err variant, unwrap will call the panic! macro for us.\nuse std::fs::File;\n \nfn main() {\n    let greeting_file = File::open(&quot;hello.txt&quot;).unwrap();\n}\nIf we run this code without a hello.txt file, we‚Äôll see an error message from the panic! call that the unwrap method makes:\nthread &#039;main&#039; panicked at src/main.rs:4:49:\ncalled `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: &quot;No such file or directory&quot; }\nthe expect method lets us also choose the panic! error message. Using expect instead of unwrap and providing good error messages can convey your intent and make tracking down the source of a panic easier.\nuse std::fs::File;\n \nfn main() {\n    let greeting_file = File::open(&quot;hello.txt&quot;)\n        .expect(&quot;hello.txt should be included in this project&quot;);\n}\nA Shortcut for Propagating Errors: the ? Operator :\nuse std::fs::File;\nuse std::io::{self, Read};\n \nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    let username_file_result = File::open(&quot;hello.txt&quot;);\n \n    let mut username_file = match username_file_result {\n        Ok(file) =&gt; file,\n        Err(e) =&gt; return Err(e),\n    };\n \n    let mut username = String::new();\n \n    match username_file.read_to_string(&amp;mut username) {\n        Ok(_) =&gt; Ok(username),\n        Err(e) =&gt; Err(e),\n    }\n}\nfunction is returning a value of the type Result&lt;T, E&gt;, i.e. we are propagating the Error / Success to the calling function\nfunction succeeds ‚áí calling function receives String- the username\nfunction encounters error ‚áí returns Error of type io::Error\n\nShortcut ? operator :\n\nuse std::fs::File;\nuse std::io::{self, Read};\n \nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    let mut username_file = File::open(&quot;hello.txt&quot;)?;\n    let mut username = String::new();\n    username_file.read_to_string(&amp;mut username)?;\n    Ok(username)\n}\nThe ? placed after a Result value is defined to work in almost the same way as the match expressions we defined to handle the Result values in above example;\n\n? only works if the return type of the function is Result or Option so that it‚Äôs compatible with this return of ? operator.\n\nOR EVEN BETTER just chain them:\nuse std::fs::File;\nuse std::io::{self, Read};\n \nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    let mut username = String::new();\n \n    File::open(&quot;hello.txt&quot;)?.read_to_string(&amp;mut username)?;\n \n    Ok(username)\n}\n\nDifference Between match and ? :\n\nerror values that have the ? operator called on them go through the from function, defined in the From trait in the standard library, which is used to convert values from one type into another. When the ? operator calls the from function, the error type received is converted into the error type defined in the return type of the current function. This is useful when a function returns one error type to represent all the ways a function might fail, even if parts might fail for many different reasons.\n// We can just read from a file diretly using read_to_string too\n \nuse std::fs;\nuse std::io;\n \nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    fs::read_to_string(&quot;hello.txt&quot;)\n}\nThis code doesn‚Äôt work because ? operator returns an Result but main doesn‚Äôt have any return type\nuse std::fs::File;\n \nfn main() {\n    let greeting_file = File::open(&quot;hello.txt&quot;)?;\n}\nThis works because we defined return type of main function\nuse std::error::Error;\nuse std::fs::File;\n \nfn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let greeting_file = File::open(&quot;hello.txt&quot;)?;\n \n    Ok(())\n}\nBox&lt;dyn Error&gt; mean ‚Äúany kind of error.‚Äù\nWhen a main function returns a Result&lt;(), E&gt;, the executable will exit with a value of 0 if main returns Ok(()) and will exit with a nonzero value if main returns an Err value.\nUsing Error Handling in Guess Game :\nuse std::io;\nuse std::cmp::Ordering;\nuse rand::Rng;\n \nstruct Guess {\n    num: u32\n}\n \nimpl Guess {\n    pub fn check_range(num:u32) -&gt; Guess {\n        if num&lt;1 || num&gt;10 {\n            panic!(&quot;Enter the number in 1 to 10 range&quot;);\n        }\n        Guess {num}\n    }\n}\n \nfn main(){\n\tprintln!(&quot;Enter a number: &quot;);\n\tlet mut guess:String = String::new();\n\t\n\tio::stdin()\n\t.read_line(&amp;mut guess)\n\t.expect(&quot;Failed to read line&quot;);\n\t\n\t// Shadowing guess\n\tlet guess:u32 = guess.trim().parse().expect(&quot;Please type a number!&quot;);\n\t\n    let guess = Guess::check_range(guess);\n \n\tprintln!(&quot;You entered: {}&quot;, guess.num);\n\t\n\tlet mut rng = rand::rng();\n\tlet secret_number = rng.random_range(1..=10);\n\tprintln!(&quot;Random number: {}&quot;, secret_number);\n\t\n\tmatch guess.num.cmp(&amp;secret_number) {\n\t\tOrdering::Less =&gt; println!(&quot;Too small!&quot;),\n\t\tOrdering::Greater =&gt; println!(&quot;Too big!&quot;),\n\t\tOrdering::Equal =&gt; println!(&quot;You win!&quot;),\n\t}\n}\nGeneric Types\nWe want to find largest number and character in a Vector\nbut we have to write same logic for both :\nfn largest_i32(list: &amp;[i32]) -&gt; &amp;i32 {\n    let mut largest = &amp;list[0];\n \n    for item in list {\n        if item &gt; largest {\n            largest = item;\n        }\n    }\n\t\n    largest\n}\n \nfn largest_char(list: &amp;[char]) -&gt; &amp;char {\n    let mut largest = &amp;list[0];\n\t\n    for item in list {\n        if item &gt; largest {\n            largest = item;\n        }\n    }\n\t\n    largest\n}\n \nfn main() {\n    let number_list = vec![34, 50, 25, 100, 65];\n\t\n    let result = largest_i32(&amp;number_list);\n    println!(&quot;The largest number is {result}&quot;);\n    \n    let char_list = vec![&#039;y&#039;, &#039;m&#039;, &#039;a&#039;, &#039;q&#039;];\n    \n    let result = largest_char(&amp;char_list);\n    println!(&quot;The largest char is {result}&quot;);\n}\nSo we can just make parameter of function to find largest a Generic type with some constraint on data types that have a particular Traits can only be allowed.\nfn get_largest&lt;T: PartialOrd + Copy&gt;(list: Vec&lt;T&gt;) -&gt; T {\n\tlet mut largest:T = list[0];\n\tfor n:T in list {\n\t\tif n &gt; largest {\n\t\t\tlargest = n;\n\t\t}\n\t}\n\tlargest\n}\nhere we have to add PartialOrd(data types that can be ordered by some kind of comparison) and Copy traits because we are copying(let mut largest:T = list[0];) and comparing(n &gt; largest)\nGenerics in Method Definitions :\nstruct Point&lt;T&gt; {\n    x: T,\n    y: T,\n}\n \nimpl&lt;T&gt; Point&lt;T&gt; {\n    fn x(&amp;self) -&gt; &amp;T {\n        &amp;self.x\n    }\n}\n \nfn main() {\n    let p = Point { x: 5, y: 10 };\n\t// Note here haven&#039;t define a fn on y \n\t// so we can&#039;t access y() because it doesn&#039;t exist\n    println!(&quot;p.x() = {}&quot;, p.x());\n\tprintln!(&quot;p.y = {}&quot;,p.y);\n}\nstruct Point&lt;X1, Y1&gt; {\n    x: X1,\n    y: Y1,\n}\n \nimpl&lt;X1, Y1&gt; Point&lt;X1, Y1&gt; {\n    fn mixup&lt;X2, Y2&gt;(self, other: Point&lt;X2, Y2&gt;) -&gt; Point&lt;X1, Y2&gt; {\n        Point {\n            x: self.x,\n            y: other.y,\n        }\n    }\n}\n \nfn main() {\n    let p1 = Point { x: 5, y: 10.4 };\n    let p2 = Point { x: &quot;Hello&quot;, y: &#039;c&#039; };\n\t\n    let p3 = p1.mixup(p2);\n\t\n    println!(&quot;p3.x = {}, p3.y = {}&quot;, p3.x, p3.y);\n}\n \n// OUTPUT : \n// p3.x = 5, p3.y = c\nTraits(define behavior)\nA type‚Äôs behavior consists of the methods we can call on that type. Different types share the same behavior if we can call the same methods on all of those types. Trait definitions are a way to group method signatures together to define a set of behaviors necessary to accomplish some purpose.\n\nExample: NewsArticles and Tweets both have a trait / behavior / method where we want to summarize the post\n\npub trait Summary {\n    fn summarize(&amp;self) -&gt; String;\n}\n \npub struct NewsArticle {\n    pub headline: String,\n    pub location: String,\n    pub author: String,\n    pub content: String,\n}\n \nimpl Summary for NewsArticle {\n    fn summarize(&amp;self) -&gt; String {\n        format!(&quot;{}, by {} ({})&quot;, self.headline, self.author, self.location)\n    }\n}\n \npub struct Tweet {\n    pub username: String,\n    pub content: String,\n    pub reply: bool,\n    pub retweet: bool,\n}\n \nimpl Summary for Tweet {\n    fn summarize(&amp;self) -&gt; String {\n        format!(&quot;{}: {}&quot;, self.username, self.content)\n    }\n}\nWe can also have default functions for traits, these are overwritten when we declare the same function in the implementation of that trait on a type. For Example:\npub trait Summary {\n    fn summarize_author(&amp;self) -&gt; String;\n    \n    fn summarize(&amp;self) -&gt; String {\n\t\tformat!(&quot;(Read more from {}...)&quot;, self.summarize_author())\n    }\n}\n// here for tweets we have overwritten the default \n// `summarize_author` function defined above\nimpl Summary for Tweet {\n    fn summarize_author(&amp;self) -&gt; String {\n        format!(&quot;@{}&quot;, self.username)\n    }\n}\nTraits as parameters :\npub fn notify(item: &amp;impl Summary) {\n    println!(&quot;Breaking news! {}&quot;, item.summarize());\n}\n \n// the above function is a syntax sugar for \n// trait bound syntax :\npub fn notify&lt;T: Summary&gt;(item: &amp;T) {\n    println!(&quot;Breaking news! {}&quot;, item.summarize());\n}\n \n// for multiple parameters with common traits, trait \n// bound syntax is better \nfn some_function&lt;T: Display + Clone, U: Clone + Debug&gt;(t: &amp;T, u: &amp;U) -&gt; i32 {\n\t// ---- code ----\n}\n// but the above some_function has too many trait bounds\n// and looks cluttered so use `where` clause\nfn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32\nwhere\n    T: Display + Clone,\n    U: Clone + Debug,\n{\n\t// ---- code ----\n}\nReturning types that implement Traits :\nfn returns_summarizable() -&gt; impl Summary {\n    Tweet {\n        username: String::from(&quot;horse_ebooks&quot;),\n        content: String::from(\n            &quot;of course, as you probably already know, people&quot;,\n        ),\n        reply: false,\n        retweet: false,\n    }\n}\n\nNote that below code won‚Äôt work because of how impl is implemented in compiler :\n\nfn returns_summarizable(switch: bool) -&gt; impl Summary {\n    if switch {\n        NewsArticle {\n            headline: String::from(\n                &quot;Penguins win the Stanley Cup Championship!&quot;,\n            ),\n            location: String::from(&quot;Pittsburgh, PA, USA&quot;),\n            author: String::from(&quot;Iceburgh&quot;),\n            content: String::from(\n                &quot;The Pittsburgh Penguins once again are the best \\\n                 hockey team in the NHL.&quot;,\n            ),\n        }\n    } else {\n        Tweet {\n            username: String::from(&quot;horse_ebooks&quot;),\n            content: String::from(\n                &quot;of course, as you probably already know, people&quot;,\n            ),\n            reply: false,\n            retweet: false,\n        }\n    }\n}\nUsing Trait Bounds to Conditionally Implement Methods :\nuse std::fmt::Display;\n \nstruct Pair&lt;T&gt; {\n    x: T,\n    y: T,\n}\n \nimpl&lt;T&gt; Pair&lt;T&gt; {\n    fn new(x: T, y: T) -&gt; Self {\n        Self { x, y }\n    }\n}\n \nimpl&lt;T: Display + PartialOrd&gt; Pair&lt;T&gt; {\n    fn cmp_display(&amp;self) {\n        if self.x &gt;= self.y {\n            println!(&quot;The largest member is x = {}&quot;, self.x);\n        } else {\n            println!(&quot;The largest member is y = {}&quot;, self.y);\n        }\n    }\n}\nLifetimes\n// Error: x don&#039;t live long enough\nfn main() {\n    let r;\n    {\n        let x = 5;\n        r = &amp;x;\n    } // x is dropped here \n    println!(&quot;r: {r}&quot;); // r becomes dangling pointer so code doesn&#039;t compile\n}\nSo just code this:\nfn main() {\n    let x = 5;            // ----------+-- &#039;b\n                          //           |\n    let r = &amp;x;           // --+-- &#039;a  |\n                          //   |       |\n    println!(&quot;r: {r}&quot;);   //   |       |\n}                         // --+-------+\nx has the lifetime ‚Äòb, which in this case is larger than lifetime of r i.e. ‚Äòa\nGeneric lifetimes in functions :\n// Error: lifetime of return type of longest is not defined \nfn main() {\n    let string1 = String::from(&quot;abcd&quot;);\n    let string2 = &quot;xyz&quot;;\n\t\n    let result = longest(string1.as_str(), string2);\n    println!(&quot;The longest string is {result}&quot;);\n}\n \nfn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n// here we didn&#039;t specify the lifetime for return type\n// and as x and y can have different lifetimes \n// borrow checker don&#039;t know how long would returned value\n// will exist\n \n// Corrected code with lifetimes:\nfn main() {\n    let string1 = String::from(&quot;abcd&quot;);\n    let string2 = &quot;xyz&quot;;\n\t\n    let result = longest(string1.as_str(), string2);\n    println!(&quot;The longest string is {result}&quot;);\n}\n \nfn longest&lt;&#039;a&gt;(x: &amp;&#039;a str, y: &amp;&#039;a str) -&gt; &amp;&#039;a str {\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n\nNote: How to define lifetime ‚áí\n\n&amp;i32        // a reference\n&amp;&#039;a i32     // a reference with an explicit lifetime\n&amp;&#039;a mut i32 // a mutable reference with an explicit lifetime\n// Error: `string2` does not live long enough\n// Here we have both string to have different lifetimes \n// so the return type will have lifetime of shortest of \n// both lifetimes, which here is string2 \n// so `println!` line don&#039;t have `result` as it was dropped \n// with `string2` \n// This is done because if `string2` is returned then\n// we will have a dangling pointer\nfn main() {\n    let string1 = String::from(&quot;long string is long&quot;);\n    let result;\n    {\n        let string2 = String::from(&quot;xyz&quot;);\n        result = longest(string1.as_str(), string2.as_str());\n    }\n    println!(&quot;The longest string is {result}&quot;);\n}\n \nfn longest&lt;&#039;a&gt;(x: &amp;&#039;a str, y: &amp;&#039;a str) -&gt; &amp;str {\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n\nNote: we always have to tie lifetime of return type with one of its parameter\n\n// Error: return value referenceing to local variable\n// because the local varible is dropped with the end \n// of function\nfn longest&lt;&#039;a&gt;(x: &amp;str, y: &amp;str) -&gt; &amp;&#039;a str {\n    let result = String::from(&quot;really long string&quot;);\n    result.as_str()\n}\n \n// This code will work as we are returning our own type\n// and the ownership is transfered \nfn longest&lt;&#039;a&gt;(x: &amp;str, y: &amp;str) -&gt; String {\n    let result = String::from(&quot;really long string&quot;);\n    result\n}\nStruct lifetimes :\nWhen we use reference in a struct definition we need to use lifetimes\n// Here we are saying struct lifetime is till the lifetime \n// of `part` and vice versa\nstruct ImportantExcerpt&lt;&#039;a&gt; {\n    part: &amp;&#039;a str,\n}\n \nfn main() {\n    let novel = String::from(&quot;Call me Ishmael. Some years ago...&quot;);\n    let first_sentence = novel.split(&#039;.&#039;).next().unwrap();\n    let i = ImportantExcerpt {\n        part: first_sentence,\n    };\n}\nLifetime Elision :\n\nDefault Rules that functions follow:\n\nEach parameter that is a reference gets its own lifetime parameter\nIf there is exactly one input lifetime parameter, that lifetime is assigned to all output lifetime parameters\nIf there are multiple input lifetime parameters, but one of them is &amp;self or &amp;mut self, the lifetimes of self is assigned to all output lifetimes parameters.\n\n\n// like here we didn&#039;t need to define lifetimes still\n// fucntion compiles and works as intended because \n// there is only one parameter\nfn first_word(s: &amp;str) -&gt; &amp;str {\n    let bytes = s.as_bytes();\n\t\n    for (i, &amp;item) in bytes.iter().enumerate() {\n        if item == b&#039; &#039; {\n            return &amp;s[0..i];\n        }\n    }\n\t\n    &amp;s[..]\n}\n \n// by folloeing the default rules function becomes :\nfn first_word&lt;&#039;a&gt;(s: &amp;&#039;a str) -&gt; &amp;&#039;a str {\nLifetime annotations in Method definitions :\nstruct ImportantExcerpt&lt;&#039;a&gt; {\n    part: &amp;&#039;a str,\n}\n \n// here we have &amp;self so all outputs will have self lifetime\n// by default\nimpl&lt;&#039;a&gt; ImportantExcerpt&lt;&#039;a&gt; {\n    fn announce_and_return_part(&amp;self, announcement: &amp;str) -&gt; &amp;str {\n        println!(&quot;Attention please: {announcement}&quot;);\n        self.part\n    }\n}\n \nfn main() {\n    let novel = String::from(&quot;Call me Ishmael. Some years ago...&quot;);\n    let first_sentence = novel.split(&#039;.&#039;).next().unwrap();\n    let i = ImportantExcerpt {\n        part: first_sentence,\n    };\n}\nStatic lifetime :\nStatic lifetime means can live throughout the duration of program\nAll string literals have static lifetimes as they are stored in binary.\nExample of Generic, Traits and Lifetimes\nuse std::fmt::Display;\n \nfn longest_with_an_announcement&lt;&#039;a, T&gt;(\n    x: &amp;&#039;a str,\n    y: &amp;&#039;a str,\n    ann: T,\n) -&gt; &amp;&#039;a str\nwhere\n    T: Display,\n{\n    println!(&quot;Announcement! {ann}&quot;);\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n \n \nfn main() {\n    let string1 = String::from(&quot;abcd&quot;);\n    let string2 = &quot;xyz&quot;;\n\t\n    let result = longest_with_an_announcement(\n        string1.as_str(),\n        string2,\n        &quot;Today is someone&#039;s birthday!&quot;,\n    );\n    println!(&quot;The longest string is {result}&quot;);\n}\nWriting Tests in Rust\n\nNote: All test in Rust are ran in different threads (i.e. test run parallel) and then when thread dies / stops Rust test conclude\n\nCreate a new library to generate a lib file which by default has test\ncargo new adder --lib\n\nassert! ‚Üí Checks if a condition is true\nassert_eq! ‚Üí Checks if two values are equal\nassert_ne! ‚Üí Checks if two values are NOT equal\n\n\nNote the use super::*; line inside the tests module.\n\n#[derive(Debug)]\nstruct Rectangle {\n    width: u32,\n    height: u32,\n}\n \nimpl Rectangle {\n    fn can_hold(&amp;self, other: &amp;Rectangle) -&gt; bool {\n        self.width &gt; other.width &amp;&amp; self.height &gt; other.height\n    }\n}\n \n#[cfg(test)]\nmod tests {\n\tuse super::*;\n\t\n    #[test]\n    fn larger_can_hold_smaller() {\n        let larger = Rectangle {\n            width: 8,\n            height: 7,\n        };\n        let smaller = Rectangle {\n            width: 5,\n            height: 1,\n        };\n\t\t\n        assert!(larger.can_hold(&amp;smaller));\n    }\n}\nCustom Message in assertions :\npub fn greeting(name: &amp;str) -&gt; String {\n    String::from(&quot;Hello!&quot;)\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn greeting_contains_name() {\n        let result = greeting(&quot;Carol&quot;);\n        assert!(\n            result.contains(&quot;Carol&quot;),\n            &quot;Greeting did not contain name, value was `{}`&quot;, \n            result\n        );\n    }\n}\nshould_panic :\npub struct Guess {\n    value: i32,\n}\n \nimpl Guess {\n    pub fn new(value: i32) -&gt; Guess {\n        if value &lt; 1 || value &gt; 100 {\n            panic!(&quot;Guess value must be between 1 and 100, got {value}.&quot;);\n        }\n        \n        Guess { value }\n    }\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    \n    #[should_panic]\n    fn greater_than_100() {\n        Guess::new(200);\n    }\n}\nThe above code works but it don‚Äôt constrain exactly why code was panicked, to do that we can use expected :\npub struct Guess {\n    value: i32,\n}\n \nimpl Guess {\n    pub fn new(value: i32) -&gt; Guess {\n        if value &lt; 1 {\n            panic!(\n                &quot;Guess value must be greater than or equal to 1, got {value}.&quot;\n            );\n        } else if value &gt; 100 {\n            panic!(\n                &quot;Guess value must be less than or equal to 100, got {value}.&quot;\n            );\n        }\n \n        Guess { value }\n    }\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n \n    #[test]\n    #[should_panic(expected = &quot;less than or equal to 100&quot;)]\n    fn greater_than_100() {\n        Guess::new(200);\n    }\n}\n \n// pass 200 test passes\n// pass -20 test failes\nTest that return Result type:\npub fn add(left: u64, right: u64) -&gt; u64 {\n    left + right\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn it_works() -&gt; Result&lt;(), String&gt; {\n        let result = add(2, 2);\n        \n        if result == 4 {\n            Ok(())\n        } else {\n            Err(String::from(&quot;two plus two does not equal four&quot;))\n        }\n    }\n}\nControlling how test are run:\nyou list the arguments that go to cargo test followed by the separator -- and then the ones that go to the test binary\nthe --test-threads flag and the number of threads you want to use to the test binary.\n$ cargo test -- --test-threads=1\nWe set the number of test threads to 1, telling the program not to use any parallelism.\nshowing function output:\n\nif we call println! in a test and the test passes, we won‚Äôt see the println! output in the terminal; we‚Äôll see only the line that indicates the test passed. If a test fails, we‚Äôll see whatever was printed to standard output with the rest of the failure message.\n\nfn prints_and_returns_10(a: i32) -&gt; i32 {\n    println!(&quot;I got the value {a}&quot;);\n    10\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn this_test_will_pass() {\n        let value = prints_and_returns_10(4);\n        assert_eq!(value, 10);\n    }\n    \n    #[test]\n    fn this_test_will_fail() {\n        let value = prints_and_returns_10(8);\n        assert_eq!(value, 5);\n    }\n}\n$ cargo test\n   Compiling silly-function v0.1.0 (file:///projects/silly-function)\n    Finished `test` profile [unoptimized + debuginfo] target(s) in 0.58s\n     Running unittests src/lib.rs (target/debug/deps/silly_function-160869f38cff9166)\n \nrunning 2 tests\ntest tests::this_test_will_fail ... FAILED\ntest tests::this_test_will_pass ... ok\n \nfailures:\n \n---- tests::this_test_will_fail stdout ----\nI got the value 8\nthread &#039;tests::this_test_will_fail&#039; panicked at src/lib.rs:19:9:\nassertion `left == right` failed\n  left: 10\n right: 5\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n \n \nfailures:\n    tests::this_test_will_fail\n \ntest result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n \nerror: test failed, to rerun pass `--lib`\nBut we don‚Äôt see I got the value 4 because that test case is passed. If we want to see printed values for passing tests as well, use --show-output\nrunning a subset of test cases:\nYou can choose which tests to run by passing cargo test the name of the test(s) you want to run as an argument.\nTo run multiple tests, we can specify part of a test name, and any test whose name matches that value will be run.\npub fn add_two(a: usize) -&gt; usize {\n    a + 2\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn add_two_and_two() {\n        let result = add_two(2);\n        assert_eq!(result, 4);\n    }\n    \n    #[test]\n    fn add_three_and_two() {\n        let result = add_two(3);\n        assert_eq!(result, 5);\n    }\n    \n    #[test]\n    fn one_hundred() {\n        let result = add_two(100);\n        assert_eq!(result, 102);\n    }\n}\nThis runs only one_hundred test:\ncargo test one_hundred\nThis runs both add_two_and_two and add_three_and_two:\ncargo test add_\nignoring test case/s:\nthe ignore attribute to exclude a test\npub fn add(left: u64, right: u64) -&gt; u64 {\n    left + right\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn it_works() {\n        let result = add(2, 2);\n        assert_eq!(result, 4);\n    }\n    \n    #[test]\n    #[ignore]\n    fn expensive_test() {\n        // code that takes an hour to run\n    }\n}\n \n// Now when we run our tests, `it_works` runs, \n// but `expensive_test` doesn‚Äôt\nIf we want to run only the ignored tests, we can use cargo test -- --ignored\nIf you want to run all tests whether they‚Äôre ignored or not, you can run cargo test -- --include-ignored.\nTest Organization:\ntwo main categories: unit tests and integration tests.\nUnit tests are small and more focused, testing one module in isolation at a time, and can test private interfaces.\nIntegration tests are entirely external to your library and use your code in the same way any other external code would, using only the public interface and potentially exercising multiple modules per test.\nUnit tests are in same file as main code:\npub fn add_two(a: usize) -&gt; usize {\n    internal_adder(a, 2)\n}\n \nfn internal_adder(left: usize, right: usize) -&gt; usize {\n    left + right\n}\n \n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn internal() {\n        let result = internal_adder(2, 2);\n        assert_eq!(result, 4);\n    }\n}\n \n// here internal_adder is private function but we\n// can use it in test module because they are in same \n// file i.e. parent child relation\nIntegration test are added to a separate tests folder in root directory:\nadder\n‚îú‚îÄ‚îÄ Cargo.lock\n‚îú‚îÄ‚îÄ Cargo.toml\n‚îú‚îÄ‚îÄ src\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ lib.rs\n‚îî‚îÄ‚îÄ tests\n    ‚îî‚îÄ‚îÄ integration_test.rs\n// integration_test.rs\nuse adder::add_two;\n \n#[test]\nfn it_adds_two() {\n    let result = add_two(2);\n    assert_eq!(result, 4);\n}\nif we want to just run integration test: cargo test --test integration_test\nSubmodules in Integration test:\n‚îú‚îÄ‚îÄ Cargo.lock\n‚îú‚îÄ‚îÄ Cargo.toml\n‚îú‚îÄ‚îÄ src\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ lib.rs\n‚îî‚îÄ‚îÄ tests\n    ‚îú‚îÄ‚îÄ common\n    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ mod.rs\n    ‚îî‚îÄ‚îÄ integration_test.rs\nnow we can use the functions defined in mod.rs as helper functions in other integration test and mod.rs won‚Äôt be treated as integration test.\nClosures\nClosures, a anonymous function-like construct you can store in a variable\nClosures are useful in:\n\nShort-Lived, Inline Behavior\nCapturing Environment Variables\nHigher-Order Functions (Passing Functions as Arguments)\nLazy Execution‚Äîexecuting code only when needed.\n\nRust‚Äôs closures are anonymous functions you can save in a variable or pass as arguments to other functions. Unlike functions, closures can capture values from the scope in which they‚Äôre defined.\nlet query = Query::new(&amp;args).unwrap_or_else(|err|{\n        eprintln!(&quot;Error while parsing arguments: {}&quot;, err);\n        process::exit(1);\n    });\nClosure Type Inference and Annotation:\n// v1 is a function \nfn  add_one_v1   (x: u32) -&gt; u32 { x + 1 }\n \n// v2, v3, v4 are all closures \n// v2 have fixed return type of x\n// but v3 and v4 infers type from the value passed to \n// it on it&#039;s first call\nlet add_one_v2 = |x: u32| -&gt; u32 { x + 1 };\nlet add_one_v3 = |x|             { x + 1 };\nlet add_one_v4 = |x|               x + 1  ;\n// Error: mismatched types\nlet example_closure = |x| x;\nlet s = example_closure(String::from(&quot;hello&quot;));\nlet n = example_closure(5);\n \n// here as a `String` is passed first, parameter `x`\n// compiler infers the type of x as String\n// so when on second call a number is passed \n// compiler throws an mismatched types Error\nCapturing environment variables:\nClosures can capture values from their environment in three ways, which directly map to the three ways a function can take a parameter: borrowing immutably, borrowing mutably, and taking ownership. The closure will decide which of these to use based on what the body of the function does with the captured values.\n// we define a closure that captures an immutable\n// reference to the vector named `list` because it only\n// needs an immutable reference to print the value:\n \nfn main() {\n    let list = vec![1, 2, 3];\n    println!(&quot;Before defining closure: {list:?}&quot;);\n    \n    let only_borrows = || println!(&quot;From closure: {list:?}&quot;);\n    \n    println!(&quot;Before calling closure: {list:?}&quot;);\n    only_borrows();\n    println!(&quot;After calling closure: {list:?}&quot;);\n}\nfn main() {\n    let mut list = vec![1, 2, 3];\n    println!(&quot;Before defining closure: {list:?}&quot;);\n\t\n    let mut borrows_mutably = || list.push(7);\n\t\n    borrows_mutably();\n    println!(&quot;After calling closure: {list:?}&quot;);\n}\n\nIf you want to force the closure to take ownership of the values it uses in the environment even though the body of the closure doesn‚Äôt strictly need ownership, you can use the move keyword before the parameter list.\nThis causes closure to take FnOnce Trait\n\nuse std::thread;\n \nfn main() {\n    let list = vec![1, 2, 3];\n    println!(&quot;Before defining closure: {list:?}&quot;);\n\t\n    thread::spawn(move || println!(&quot;From thread: {list:?}&quot;))\n        .join()\n        .unwrap();\n}\nFn Traits:\n\nFnOnce Trait  ‚áí  closure takes ownership of parameters passed to it and therefore can only be called once.\nFnMut Trait  ‚áí  closure borrows the parameters mutably\nFn Trait  ‚áí  closure borrows the parameters immutably\n\nimpl&lt;T&gt; Option&lt;T&gt; {\n    pub fn unwrap_or_else&lt;F&gt;(self, f: F) -&gt; T\n    where\n        F: FnOnce() -&gt; T\n    {\n        match self {\n            Some(x) =&gt; x,\n            None =&gt; f(),\n        }\n    }\n}\nIterators\nIterators allow you to iterate over sequence of elements regardless of how sequence is stored (HashMap, Array, Vector, custom types that implement IntoIterator Trait etc.)\nWe can iterate over:\n\nVec&lt;T&gt;\nVecDeque&lt;T&gt;\nLinkedList&lt;T&gt;\nHashMap&lt;K, V&gt;\nBTreeMap&lt;K, V&gt;\nHashSet&lt;T&gt;\nBTreeSet&lt;T&gt;\nBinaryHeap&lt;T&gt;\nArray&lt;T, N&gt;\nString\n&amp;str\n\n\nNote: In Rust iterators are lazy, so till it‚Äôs called, it won‚Äôt execute, unlike functions that are compiled as they are defined\n\nCrates\nrand:\nuse rand::Rng;\n \nfn main() {\n\tlet mut rng = rand::rng();\n\t// generates a random integer number from [1, 2, 3, 4, 5, 6]\n\t// =6 means 6 is inclusive\n\tprintln!(&quot;Dice roll: {}&quot;, rng.random_range(1..=6));\n\t\n\t// generates a random integer number from [1, 2, 3, 4, .. 9] \n\t// i.e. 10 is exclusive\n\tprintln!(&quot;Number from 0 to 9: {}&quot;, rng.random_range(0..10));\n\t\n\t// generates a random double number from 0 to 10, 10 is exclusive\n\tprintln!(&quot;Number from 0 to 9: {}&quot;, rng.random_range(0.0..10.0));\n}"},"Startups":{"slug":"Startups","filePath":"Startups.md","title":"Startups","links":["/"],"tags":[],"content":"Home\nIdeas:\n\nGeneral purpose open source GPU programming framework\n\nRight now Nvidia have monopoly on how chips are made and used. Nvidia chips have CUDA framework for their GPU programming, they don‚Äôt need to follow standards so that it is compatible and editable by others\n\n\nLog Ingestor (its a bit common still not generalized as it‚Äôs hard to create a general ingestor)\n\n\nVC / Startup programs:\n\nwww.sequoiacap.com/\nwww.ycombinator.com/\na16z.com/\n"},"System-Design/index":{"slug":"System-Design/index","filePath":"System Design/index.md","title":"System Design","links":["/"],"tags":[],"content":"Home\nSystem Design concepts: (Quastor, DEV Community, Medium, Archive - ByteByteGo Newsletter, system-design-primer)\ndonnemartin/system-design-primer: Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards. (github.com)\nSingleton Method Design Pattern - GeeksforGeeks\nReddit Architecture"},"Tech-Articles--and--Videos":{"slug":"Tech-Articles--and--Videos","filePath":"Tech Articles & Videos.md","title":"Tech Articles & Videos","links":["/","System-Design/"],"tags":[],"content":"Home\nArchitecture (for concepts)\n\nHow Hotstar Application Scaled 25 Million Concurrent Users | Performance Testing | Load Testing: www.youtube.com/watch\nHow CloudFlare Processes a Million Logs per Second (quastor.org)\nReddit Architecture\n\nWeb Dev\n\nHow to Manipulate the DOM in JavaScript ‚Äì Most Commonly Used Techniques (freecodecamp.org)\n51 CSS Animations on Scroll Your Visitors Will Love (sliderrevolution.com)\nJWT - authentication used in WebDev\n\nAI-ML\n\nDeep Learning (Chat GPT) Prompt Engineering: learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction\n"},"UI-UX":{"slug":"UI-UX","filePath":"UI-UX.md","title":"UI-UX","links":["/"],"tags":[],"content":"Home\n\nLaws of UX\nthetoolbox.art/\n"},"Web-Dev/DBMS":{"slug":"Web-Dev/DBMS","filePath":"Web Dev/DBMS.md","title":"DBMS","links":["Web-Dev/"],"tags":[],"content":"index\nACID explained in fun way :\nwww.instagram.com/reel/C2j8YlvsX4c/\nLog Sampling :\nwww.instagram.com/reel/C5_T3RToueG/\nCAP Theorem\nIn distributed systems, you can only guarantee two out of three properties:\n\nConsistency: All nodes see the same data at the same time.\nAvailability: Every request gets a response, even if some nodes fail.\nPartition Tolerance: System continues to function despite of network partitions (network failure splits the system into isolated subsets of nodes that cannot communicate with each other).\n\nACID\nwww.youtube.com/watch\n\nAtomicity ‚áí All or nothing (transactions, if fails rollback all)\nConsistency ‚áí Database should enforce consistency among data in all nodes and enforce all rules and properties defined for data\nIsolation ‚áí Concurrent transactions should be isolated\nDurability ‚áí Once a transaction is completed it must permanent even id database loose power / crashes etc.\n\nlogging and replicating data are methods to achieve this\n\n\n\nMutex and Semaphore\n\nMutex ‚áí Mutual Exclusion ‚áí single thread access ‚áí lock is binary\nSemaphore ‚áí multiple (but limited) threads can access ‚áí lock is a count ‚áí it‚Äôs like ;load balancing if all servers are busy then queue the request\n"},"Web-Dev/DevOps":{"slug":"Web-Dev/DevOps","filePath":"Web Dev/DevOps.md","title":"DevOps","links":["Web-Dev/"],"tags":[],"content":"index\nCI/CD\n\n\nContinuous Integration and Delivery - CircleCI\nJenkins\nGitHub Actions documentation - GitHub Docs\n\nDocker\nyour-dockerhub-username == namespace\n1) Make a Dockerfile with example contents as follows:\nFROM node:20\n \n# specify where whole project will install inside /usr/src\nWORKDIR /usr/src/name_of_app \n \nCOPY . .\n \nRUN npm install\n \n# change to where your server.js/index.js/app.js\nWORKDIR /usr/src/name_of_app/src\n \nEXPOSE 3000\n \nCMD [&quot;node&quot;, &quot;server.js&quot;]\n2) Make a .dockerignore file with example contents as follows:\nDockerfile\n \n.gitignore\nnode_modules\n.env \n \ndevlogs.txt\n3) Make a docker-compose.yml file with example contents as follows:\n\nthis file contains where to locate for environment variables while local development.\n\nversion: &#039;3.8&#039;\n \nservices:\n¬† app:\n¬† ¬† image: namespace/image_name\n¬† ¬† build: .\n¬† ¬† ports:\n¬† ¬† ¬† - &#039;3000:3000&#039;\n¬† ¬† env_file:\n¬† ¬† ¬† - .env\n4) Build an image:\n\ndocker build . -t namespace/image_name ‚áí run this command where you have your docker files\n\n5) Push image to DockerHub:\n\ndocker push namespace/image_name\n\n6) Pull images from DockerHub:\n\ndocker pull namespace/image_name\n\n\nRun an image locally (without env variables):\n\nYou typically specify the image (app) and additional flags (e.g., -p for port mapping, -v for volumes).\nExample: docker run -p 3000:3000 app.\nAbove examples tells that port 3000 of machine is mapped to port 3000 of container, so docker run -p machine_port:container_port image_name.\n\nRun an image locally (with env variables):\ndocker run --env-file ./path/to/.env -p 3000:3000 namespace/image_name:latest"},"Web-Dev/Frontend":{"slug":"Web-Dev/Frontend","filePath":"Web Dev/Frontend.md","title":"Frontend","links":["Web-Dev/"],"tags":[],"content":"index\n\nAdvice :\n\nCAUTION : Don‚Äôt waste much time in HTML and CSS as you will learn them along the way, focus more on the basics of JavaScript. \nADVICE : You will definitely always feel underconfident about HTML CSS JS but after making some basic projects move on to React.js as you will learn them along the way,\nAnimation/Components libraries:\n\ntransitions between your website‚Äôs pages - barba.js.org/\nAnimations: animejs.com/\nAnimations: gsap.com/\nComponents: ui.shadcn.com/\nComponents:  www.8bitcn.com/\nComponents: magicui.design/\nComponents: uiverse.io/\nComponents: ui.aceternity.com/components\nComponents: component.gallery/\nComponents: reactbits.dev/get-started/introduction\n\n\n\nResources :\n\n\n\nVite + Typescript : www.youtube.com/watch\n\n\nNext + Typescript : www.youtube.com/watch\n\n\nVite + Typescript + ShadcnUI :\nDocs: Vite - shadcn/ui\n\nStep 1 :\nRun below command to initialize and configure components.json\ngo for defaults in options ‚Üí\n\nnpx shadcn-ui@latest init\n\nStep 2 :\nResolve import paths for library :\n\n\nNOTE : We have to resolve path for all vite, tailwind and typescript\n\n// tailwind.config.js ::\n \ncontent: [\n¬† ¬† &quot;./index.html&quot;,\n¬† ¬† &#039;./pages/**/*.{ts,tsx}&#039;,\n¬† ¬† &#039;./@/components/**/*.{ts,tsx}&#039;,\n¬† ¬† &#039;./app/**/*.{ts,tsx}&#039;,\n¬† ¬† &#039;./src/**/*.{ts,tsx}&#039;,\n¬† ],\n\n// tsconfig.app.json ::\n \n/*Paths for ShadcnUI*/\n¬† ¬† &quot;baseUrl&quot;: &quot;.&quot;,\n¬† ¬† &quot;paths&quot;: {\n¬† ¬† ¬† &quot;@/*&quot;: [\n¬† ¬† ¬† ¬† &quot;./@/*&quot;\n¬† ¬† ¬† ]\n¬† ¬† }\n¬† },\n¬† &quot;include&quot;: [&quot;src&quot;, &quot;@&quot;]\n\n// vite.config.ts ::\n \nimport path from &quot;path&quot;\nimport { defineConfig } from &#039;vite&#039;\nimport react from &#039;@vitejs/plugin-react&#039;\n \n// vitejs.dev/config/\n \nexport default defineConfig({\n¬† plugins: [react()],\n¬† resolve: {\n¬† ¬† alias: {\n¬† ¬† ¬† &quot;@&quot;: path.resolve(__dirname, &quot;./@&quot;),\n¬† ¬† },\n¬† },\n})\n\nStep 3 :\nInstall components\n\nnpx shadcn-ui@latest add [component]\nWhich components would you like to add? ‚Ä∫ Space to select. A to toggle all.Enter to submit.\n‚óØ accordion\n‚óØ alert\n‚óØ alert-dialog\n‚óØ aspect-ratio\n‚óØ avatar\n‚óØ badge\n‚óØ button\n‚óØ calendar\n‚óØ card\n‚óØ checkbox\n\nStep 4 :\n\nimport { useState } from &#039;react&#039;;\nimport { Button } from &quot;@/components/ui/button&quot;\n \nimport { Person } from &#039;./components/Person.tsx&#039;;\n \nfunction App() {\n¬† const [value, setValue] = useState&lt;boolean&gt;(true);\n¬† \n¬† const toggleInfo = () =&gt; {\n¬† ¬† setValue((prev) =&gt; !prev)\n¬† }\n \n¬† return (\n¬† ¬† &lt;&gt;\n¬† ¬† ¬† &lt;div className=&#039;&#039;&gt;\n¬† ¬† ¬† ¬† &lt;Person value={value} /&gt;\n¬† ¬† ¬† &lt;/div&gt;\n¬† ¬† ¬† &lt;Button onClick={toggleInfo}&gt;Toggle value&lt;/Button&gt;\n¬† ¬† &lt;/&gt;\n¬† )\n}\n \nexport default App\n\n\n\nAnimation in CSS :\n\n\n\nanimation-fill-mode:\n\nThe animation-fill-mode property determines the styles applied to an element before and after the animation.\nIt can take the following values:\n\nnone: The default value. The element will not retain any styles from the animation before or after it runs.\nforwards: The element will retain the styles of the last keyframe after the animation completes. This is useful if you want the final state of the animation to persist.\nbackwards: The element will apply the styles of the first keyframe before the animation starts. This can be useful if you want the initial state of the animation to be applied even before the animation begins.\nboth: Equivalent to setting both forwards and backwards. The element will retain styles from the first keyframe before the animation starts and from the last keyframe after it completes.\n\n\n\n\n\nanimation-direction:\n\nThe animation-direction property determines the direction of the animation sequence, whether it proceeds forward, backward, or alternates between forward and backward.\nIt can take the following values:\n\nnormal: The animation runs forward from the beginning to the end.\nreverse: The animation runs backward from the end to the beginning.\nalternate: The animation alternates between running forward and backward. If the iteration count is even, it runs forward, and if it‚Äôs odd, it runs backward.\nalternate-reverse: Similar to alternate, but it starts by running backward.\n\n\n\n\n\nMotion Graphic Design &amp; Animation Principles Website - Zajno Digital Studio\nLocomotive Scroll\n\nHarkirat Roadmap for Full-Stack Development :\n\nBasics ‚áí\n\n\nFoundation\n\nFoundation Javascript, async nature of JS\nNode.js and its runtime\nDatabases (NoSQL/SQL)\nMongo and Postgres deep dive\nTypescript beginner to advance\n\n\n\nBackend\n\nBackend communication protocols\nExpress basic to advance\nORMS\nMiddlewares, routes, status codes, global catches\nZod\nHusky\nMonoRepos, turborepo\nServerless Backends\nOpenAPI Spec\nAutogenerated clients\nAuthentication using external libraries\nScaling Node.js, performance benchmarks\nDeploying npm packages\n\n\n\nFrontend\n\nReconcilers and Frontend frameworks\nReact beginner to advance\nInternals of state, Context API\nState management using recoil\nCSS you need to know of, Flexbox, basic styling\nFrontend UI frameworks, Deep dive into Tailwind\nContainerization, Docker\nNext.js\nCustom hooks\nIn house auth using next auth\n\n\n\nBasic Devops\n\nDocker end to end\nDeploying to AWS servers\nNewer clouds like fly/Remix\nNginx and reverse proxies\n\n\n\nProjects\n\nGSOC Project setting up and issue solving\nBuilding Paytm/Wallet End to End\n\n\n\nAdvance ‚áí\n\n\nAdvanced Backend, System Design\n\nAdvanced backend communication\nMessage queues and PubSubs\nProxies, Load balancers\nRedis Deep dive\nKafka Deep dive\nCommon Design Patterns in JS\nAdvanced DB concepts (Indexing, normalization)\nRate limiting\nCaptchas and DDoS protection\nSharding, Replication, Resiliency\nHorizontal and vertical scaling\nPolling and websockets\nGrpc\nCapacity Estimation Load Balancers\nCAP Theorem\nTesting Node.js Apps in 2023\nReal time communication, basics of WebRTC\n\n\n\nAdvanced DevOps\n\nDocker Deep dive\nContainer orchestration, Docker Swarm\nKubernetes\nCI/CD\nMonitoring systems basics to advance\nPromhetheus, Grafana\nNewrelic as a paid service\nServerless Deep dive\nAWS Constructs (EC2, S3, CDNs, LB, EKS)\n\n\n\nProjects\n\nZerodha end to end\nZapier end to end\nReal world open source projects\n\n\n\nTOOLS/WEBSITES:\n\nFree for Developers (free-for.dev)\nMotion Graphic Design &amp; Animation Principles Website - Zajno Digital Studio\nlist of new tools to use in websites\nNo-code Animations\nWEB Free Fonts for Windows and Mac / Font free Download - OnlineWebFonts.COM\nFree Font Downloads\nAnimated logos &amp; stickers\nDribbble\nCHEATSHEATS\nCHEATSHEATS\nLogo Maker\nIllustrations\nIllustrations\nIllustrations and assests\n3D Illustrations\nFFFuel\nPatternPad - Create beautiful patterns for presentations, social media or branding.\nSimple Backgrounds\nCreate images of your code\nColor Palettes\nColor Palettes\nIcons SVG\nIcons\nTo create shadows Neumorphism\nFree Assests\nFree Images\nFree Texture\nArchive Images\nFree Mockups\nDesign Inspo\nHTML Templates\nCSS jokes\n\nArticles:\n\n51 CSS Animations on Scroll Your Visitors Will Love (sliderrevolution.com)\nHow To Use Preload and Prefetch in HTML to Load Assets\nuseLayoutEffect and useEffect.\nWorker script and generator function in JavaScript.\nSuspense in react\n\nDeployment of vite + react app :\n\nDeploying Vite App to GitHub Pages - DEV Community\nReact to Vercel: Deployment Made Easy. - DEV Community\nChanging the input and output directory in Vite - Stack Overflow\n\nFor Ideas:\n\ntympanus\nNo-code Animations\n"},"Web-Dev/MongoDB":{"slug":"Web-Dev/MongoDB","filePath":"Web Dev/MongoDB.md","title":"MongoDB","links":["Web-Dev/"],"tags":[],"content":"index\nIn Node.js :\n\n.find() returns a cursor so use .find().forEach()\n\nMONGOOSE :\n         --&gt; Collection C1 --&gt; { Documnets ==&gt; D1 , D2 , D3 }\nDataBase --&gt; Collection C2 --&gt; { Documnets ==&gt; D1 , D2 , D3 }\n         --&gt; Collection C3 --&gt; { Documnets ==&gt; D1 , D2 , D3 }\n\nEvery Collection on MongoDB ==&gt; Every Model in Mongoose \nSchema in Mongoose define schema of documents on MongoDB\n\nConnecting to Mongo By Mongoose :\nconst mongoose = require(&#039;mongoose&#039;);\n \nconst MONGO_URL = &quot;mongodb+srv:// something ....&quot;;\n \nawait mongoose.connect(MONGO_URL,{})\n.catch(err =&gt; console.log(err))\n.then(() =&gt; console.log(&quot;connected to DB&quot;));\nconsole.log(&quot;after connection&quot;);\n \n// Below is code add event listener :\nmongoose.connection.on(&#039;error&#039;, err =&gt; {\n\tconsole.error(err);\n});\nSchema and Model in Mongoose :\nrefer : Mongoose v8.3.3: Schemas (mongoosejs.com)\nconst mongoose = require(&#039;mongoose&#039;);\n \nconst planetSchema = new mongoose.Schema({\n¬† ¬†kepler_name : {\n¬† ¬† ¬† ¬† type : String,\n¬† ¬† ¬† ¬† required: true\n¬† ¬†}\n})\n \nmodule.exports = mongoose.model(&#039;Planet&#039;, planetSchema);\n// so here instead of Planet name as collection planets\n// will be added to mongodb\nManipulating Data in Docs :\n\nNote : UPSERT (Update if found, Insert new doc if not found)\n\n\nupdateOne() function also add $setOnInsert property which can reveal that we are using MongoDB upsert, to avoid this use findOneAndUpdate() function.\n\nawait planets.updateOne(\n\t{find_by_field : old_data} ,\n\t{field_to_be_changed : new_data} ,\n\t{upsert: true}\n);\n \n// UPSERT ==&gt; Update + Insert\n// Update if found, Insert new doc if not found\n\nNote : __v value is added by Mongoose\n\n// (A document in MongoDB)\n{\n\t&quot;_id&quot;: ObjectId(&#039;6638dc913b33276166ad43b4&#039;),\n\t&quot;field&quot;:&quot;data&quot;,\n\t&quot;__v&quot;: 0\n}\nhere __v is version key ==&gt; version of document we created\nif we change schema and want old and new data to persist then \nwe can increase __v value differentiating new docs.\n\nMongoDB Queries :\nManipulating Docs of Collection :\n\ndb.collection_name.insertOne({ something in json format }) to insert a single json object in form of document\n\n\nNOTE :: MongoDB automatically adds an ObjectId to each document\n\n\ndb.collection_name.insertMany([{ something in json format } ,{ something in json format } ,{ something in json format } ,{ something in json format } .....]) to insert a single json object in form of document\ndb.collection_name.find() to grab all documents\ndb.collection_name.find( {field1 : &quot;value&quot; , field2 : &quot;value&quot;} ) to grab filtered documents according to given field/s and its value/s\n\n\nNOTE :  let numbers1: [{1} ,{2} ,{3}] and numbers2: {1}\nthen .find({numbers: &quot;1&quot; }) will return numbers1 and numbers2 documents but if we do query such as .find( {numbers : [&quot;1&quot;] } ) returns numbers2 document only\n\n\ndb.collection_name.find( {field1 : &quot;value&quot; , field2 : &quot;value&quot;} , {field_required1 : 1 , field_required2 : 1} ) to grab filtered documents according to given field/s and its value/s and to show only field_required field of each filtered document\ndb.collection_name.find( {field1 : &quot;value&quot;} ).count() to grab filtered documents according to given field/s and its value/s and return only number of such documents\ndb.collection_name.find( {field1 : &quot;value&quot;}).limit(n) to grab filtered documents according to given field/s and its value/s and to show only first ‚Äún‚Äù documents\ndb.collection_name.find().sort( {field : 1} ) to grab documents in ascending sorted form according to given field\ndb.collection_name.find().sort( {field : -1} ) to grab documents in descending sorted form according to given field\n\nQuery Operators :\n\nto load query such as greater than gt , greater than equal to gte use dollar sign and always use a query inside curly brackets\n\n\nGreater or lesser operator\n\n\ndb.collection_name.find( {rating: {$gt:7} } ) query for greater than 7\ndb.collection_name.find( {rating: {$lt:7} } ) query for lesser than 7\ndb.collection_name.find( {rating: {$gte:7} } ) query for greater than or equal to 7\ndb.collection_name.find( {rating: {$gte:7} } ) query for lesser than or equal to 7\n\n\nOR operator\n\n\ndb.collection_name.find( {$or: [{rating:7} , {rating:9}] ) query for rating: 7 or rating: 9\n\n\nIN operator and NOT IN operator (for range of value)\n\n\ndb.collection_name.find( {rating: {$in: [7,8,9] }} ) query for rating: 7 or rating:8 or rating: 9\ndb.collection_name.find( {rating: {$nin: [7,8,9] }} ) query for documents which don‚Äôt have rating: 7 or rating:8 or rating: 9\n\n\nALL operator\n\n\nlet numbers1: [{1} ,{2} ,{3}] and numbers2: {1}\nthen .find({numbers: {$all: [&quot;1&quot;,&quot;2&quot;]} }) will return numbers1 , it checks if the given field atleast contains the given values\n\nNested Documents :\n\nlet details:{ name:&quot;XYZ&quot; , email:&quot;xyz@gmail.com&quot; , age :&quot;30&quot;}\nthen to find name XYZ use .find({ &quot;details.name&quot; : &quot;XYZ&quot; })\n\nDeleting Docs of Collection :\n\ndb.collection_name.deleteOne({ field: &quot;value&quot; }) to delete a single json object in form of document\ndb.collection_name.deleteMany({ field: &quot;value&quot; }) to delete multiple documents according to field\n\nUpdate Docs of Collection :\n\ndb.collection_name.updateOne({ field_to_find: &quot;value&quot; } , {$set: {field_1_to_be_updated : &quot;new_value_1&quot; , field_2_to_be_updated : &quot;new_value_2&quot;}}) to update a document which contain ‚Äúfield_to_find‚Äù field with value  = value and set ‚Äúfield_to_be_updated‚Äù field to its new value\ndb.collection_name.updateMany({ field_to_find: &quot;value&quot; } , {$set: {field_1_to_be_updated : &quot;new_value_1&quot; , field_2_to_be_updated : &quot;new_value_2&quot;}}) to update all document which contain ‚Äúfield_to_find‚Äù field with value  = value and set ‚Äúfield_to_be_updated‚Äù field to its new value\n\n\nNote : UPSERT (Update if found, Insert new doc if not found)\n\nawait planets.updateOne(\n\t{kepler_name : data.kepler_name} ,\n\t{kepler_name : data.kepler_name} ,\n\t{upsert: true}\n);\n \n// UPSERT ==&gt; Update + Insert\n// Update if found, Insert new doc if not found\nExtra bits :\n\nINC (increment) operator\ninc: n to increment or inc: -n to decrement\n\n\ndb.collection_name.updateOne({ field_to_find: &quot;value&quot; } , {$inc: {field_to_be_updated : n }) to increment a value by n in a document which contain ‚Äúfield_to_find‚Äù field with value  = value and set ‚Äúfield_to_be_updated‚Äù field to its new value\n\n\nPULL (to remove an element from array)\n\n\ndb.collection_name.updateOne({ field_to_find: &quot;value&quot; } , {$pull: {array : &quot;element_to_be_removed&quot; }) to remove element_to_be_removed from an array where there is a ‚Äúfield_to_find‚Äù field with value = value\n\n\nPUSH (to add an element from array)\n\n\ndb.collection_name.updateOne({ field_to_find: &quot;value&quot; } , {$push: {array : &quot;element_to_be_added&quot; }) to add element_to_be_added to an array where there is a ‚Äúfield_to_find‚Äù field with value  = value\n\n\nEACH (add or remove multiple elements of an array)\n\n\ndb.collection_name.updateOne({ field_to_find: &quot;value&quot; } , {$push: {array : {$each: [&quot;element1&quot;,&quot;element2&quot;,&quot;element3&quot;]} }) to add element1 2 3 to an array where there is a ‚Äúfield_to_find‚Äù field with value  = value\n\nIN TERMINAL :\nStart terminal :\nType mongosh to enter mongodb shell\nBasic commands :\n\ncls to clear terminal\nshow dbs to see all databases\ndb to show all collections of database you are in\nhelp for help\nexit to exit\nuse database_name to move to database_name database\nuse database_name  then db.collection_name to move to collection_name collection\n"},"Web-Dev/NextAuth-+-Prisma-+-Supabase":{"slug":"Web-Dev/NextAuth-+-Prisma-+-Supabase","filePath":"Web Dev/NextAuth + Prisma + Supabase.md","title":"NextAuth + Prisma + Supabase","links":["/"],"tags":[],"content":"index\nOAuth response:\n{\n  user: {\n    id: &#039;a_number&#039;,\n    name: &#039;name&#039;,\n    email: &#039;email.com&#039;,\n    image: undefined\n  },\n  account: {\n    provider: &#039;google&#039;,\n    type: &#039;oauth&#039;,\n    providerAccountId: &#039;a_number&#039;,\n    access_token: &#039;string&#039;,\n    expires_at: 1758458065,\n    scope: &#039;www.googleapis.com/auth/userinfo.email www.googleapis.com/auth/userinfo.profile openid&#039;,\n    token_type: &#039;Bearer&#039;,\n    id_token: &#039;very_long_string&#039;\n  },\n  profile: {\n    id: &#039;a_number&#039;,\n    name: &#039;name&#039;,\n    email: &#039;email.com&#039;,\n    image: undefined\n  },\n  isNewUser: undefined\n}"},"Web-Dev/Node.js":{"slug":"Web-Dev/Node.js","filePath":"Web Dev/Node.js.md","title":"Node.js","links":["Web-Dev/"],"tags":[],"content":"index\n\nFROM ZTM COURSE AND CODEVOLUTION (youtube (to learn imp concepts))\n\nAdvance node.js concepts\nCode Keen (advancebackend.com)\nCode evolution playlists\nbackups, scaling, and advanced topics like Python ORMs, CAP theorem, and ACID compliance.\nNode REPL = read evaluate print loop\nJavaScript is synchronous / single threaded but in Web V8 engine is run in Web API‚Äôs which make it asynchronous.\nNode(V8) has some reserved token so it separates them from words which it can‚Äôt understand and pass them to Node.js APIs which then use libuv to interact with OS or Threads init.\nEvent Loop\nNode runs an EVENT LOOP for asynchronous operations by making Threads (from a Thread pool of 4(default) Threads) or use our OS to run operations in it‚Äôs own call-stack (FIFO). This call-stack is called EVENT QUEUES.\n\n\nNow EVENT LOOP has many Phases (here are only main Phases):\n\n\nTimer                 - setTimeout , setInterval\nI/O callbacks      - network and file operations and anything that doesn‚Äôt fit in other phases\nsetImmediate     - runs immediately after all I/O operations are done\nClose callbacks   - closing files networks\n\n\nNode.js is an Events-driven which follows an Observer pattern.\n\nconst EventEmitter = require(&#039;node:events&#039;);\n \nconst MyEmitter = new EventEmitter();\nMyEmitter.on(&#039;event&#039; , ()=&gt;{\n\tconsole.log(&#039;event occured&#039;);\n})\n \n// passing event to MyEmitter\nMyEmitter.emit(&#039;event&#039;);\n \n// ==============================================\n// OUTPUT : event occured\n// ==============================================\n\nProcess which is an event emitter :\n\nIN TERMINAL :\nnode name_of_file.js something\nIN name_of_file.js :\nprocess.argv.forEach((val , index)=&gt;{\n\tconsole.log(&#039;${index}: ${val}&#039;);\n});\n \n// OUTPUT : \n// 0: node \n// 1: name_of_file.js\n// 2: something\nprocess.argv is an array that has elements as follows :\nprocess.argv = [ process.execPath , name_of_js_file , arguments‚Ä¶ ]\nSo process.on is also an observer like MyEmitter.on (in above example) :\nprocess.on(&#039;exit&#039; , (code)=&gt;{\n\tconsole.log(&#039;Process exit event with an code: &#039;, code);\n})\n \n// ====================================================\n// OUTPUT : Process exit event with an code: 0\n// ====================================================\n// ========================================================\n// Method 1 : To securely only receive data (get end() automatically)\nconst { get } = require(&#039;https&#039;);\n \nget(&#039;www.google.com&#039; ,(res)=&gt;{\n\tres.on(&#039;data&#039; ,(chunk)=&gt;{\n\t\tconsole.log(`Data chunk: ${chunk}`);\n\t});\n\tres.on(&#039;end&#039; , ()=&gt;{\n\t\tconsole.log(&#039;NO more data&#039;);\n\t});\n});\n \n// ==========================================================\n// Method 2 : To securely receive and send data\nconst { request } = require(&#039;https&#039;);\nconst req = request(&#039;www.google.com&#039; ,(res)=&gt;{\n\tres.on(&#039;data&#039; ,(chunk)=&gt;{\n\t\tconsole.log(`Data chunk: ${chunk}`);\n\t});\n\tres.on(&#039;end&#039; , ()=&gt;{\n\t\tconsole.log(&#039;NO more data&#039;);\n\t});\n})\nreq.end();\n \n// ==========================================================\n// Method 3 : To receive and send data\nconst { request } = require(&#039;http&#039;);\nconst req = request(&#039;www.google.com&#039; ,(res)=&gt;{\n\tres.on(&#039;data&#039; ,(chunk)=&gt;{\n\t\tconsole.log(`Data chunk: ${chunk}`);\n\t});\n\tres.on(&#039;end&#039; , ()=&gt;{\n\t\tconsole.log(&#039;NO more data&#039;);\n\t});\n})\nreq.end();\n\nWhen we import using require in a program the file/module is executed and then store in require.cache .\nSo if we do ‚Äòrequire‚Äô multiple time it returns the function which is exported and does not rerun it.\n\n\nif we try to ‚Äòrequire‚Äô a folder, node automatically exports any file with name ‚Äù index.js ‚Äú.\n\nAXIOS :\nconst axios = require(&#039;axios&#039;);\n \naxios.get(&#039;www.google.com&#039;)\n\t.then((res)=&gt;{\n\t\tconsole.log(res);\n\t})\n\t.catch((err)=&gt;{\n\t\tconsole.log(err);\n\t});\nStream and Buffers :\nStream is to wait for a minimum chunk of data (data received before minimum data is reached is stored in a BUFFER) and load it when reached and then wait for another chunk of data to load.\nconst buffer = new Buffer.from(&#039;dhruv&#039;);\n \nbuffer.write(&#039;codevolution&#039;);\nconsole.log(buffer.toString());\nconsole.log(buffer);\nconsole.log(buffer.toJSON());\n \n// ======================================================\n// OUTPUT : \n// codev\n// &lt;Buffer 63 6f 64 65 76&gt;\n// { type: &#039;Buffer&#039;, data: [ 99, 111, 100, 101, 118 ] }\n// ======================================================\n \n// &lt;Buffer 63 6f 64 65 76&gt; : this is in hexadecimals\n// { type: &#039;Buffer&#039;, data: [ 99, 111, 100, 101, 118 ] } : are UNICODE/ASCII code\n \nConnect Streams :\n\nfs.createReadStream(&#039;kepler-data.csv&#039;)\n¬† ¬† .pipe(parser)\nLike above, after reading a chunk of data received from a fs stream it is piped to csv parser to parse the data from csv to objects/json.\nMVC (Model - View - Controller) pattern :\n\nROUTER :\nRouters are used to bundle a group of controllers who have same base endpoint . So this isolates this bundle from others and we can make router folder like controllers.\nFor Example :\n// =======================================================\n// Here friendsController is an js file in controllers file \n// from which post and get friend fuction are exported.\n// =======================================================\n \n// without routes\napp.post(&#039;/friends&#039; , friendsController.postFriend);\napp.get(&#039;/friends&#039; , friendsController.getFriend);\napp.get(&#039;/friends/:friendId&#039; , friendsController.getFriend);\n \n// =======================================================\n \n// with routes\nconst friendRouter = express.Router();\napp.use(&#039;/friends&#039; , friendsRouter);\n \nfriendRouter.post(&#039;/&#039; , friendsController.postFriend);\nfriendRouter.get(&#039;/&#039; , friendsController.getFriends);\nfriendRouter.get(&#039;/:friendId&#039; , friendsController.getFriendById);\n \n\nwe can know IP address of each request by req.ip\n\n\nNOTE : In LINUX and MAC path to a folder is /folder/file but in Windows path is \\folder\\file\nTherefore use path\n\nconst path = require(&#039;path&#039;);\n \npath.join(__dirname , &#039;..&#039; , public , &#039;file-name&#039;);\n \nTo share files/pdf/images :\n// ===========================================================\n// To send a file for example .jpg use sendFile\n \nres.sendFile( path.join(__dirname , &#039;..&#039; , public , &#039;file-name.jpg&#039;) );\nTo send some static files like html css js we can use express.static() middleware.\napp.use(express.static(path.join(__dirname , &#039;public&#039;)));Gr\nTEMPLATE ENGINES :\nTemplate engines are used to render dynamic pages which changes as values which are passed are changed.\nWe will use Handlebars as our Template engine but , first we have to let node know that we are going to use which template engine.\n// app.set() includes all settings in node.js so we can set values according to our choice. \napp.set(&#039;view engine&#039; , &#039;hbs&#039;);\napp.set(&#039;views&#039; , path.join(__dirname , &#039;views&#039;));\nPROMISES :\nconst promise1 = new Promise((resolve,reject)=&gt;{\n\t// Calculations\n\tresolve(answer);\n})\n \n// result == answer\npromise1.then((result)=&gt;{\n\tconsole.log(result);\n})\n// OR\nconst result = await promise1;\nTESTING ( JEST ):\n\nTest runner  : find test files (jest) .\nTest fixtures : test fixture are functions which run test of respective modules (describe()).\nAssertions   : function telling what we expect ( expect(output).toBe(expected_value) ).\nMocking     : where operations doesn‚Äôt change our data in database permanently.\n\ndescribe(&#039;test group name&#039;, ()=&gt;{\n \n\ttest(&#039;name of 1st test&#039;, ()=&gt;{\n\t\tconst response = 200;\n\t\texpect(response).toBe(200);\n\t});\n\t\n\ttest(&#039;name of 2nd test&#039;, ()=&gt;{\n\t\t// next test\n\t});\n \n\t// other tests\n})\n\nNOTE :\n\n&quot;test&quot;: &quot;jest&quot;,\n// npm run test ==&gt; check only once\n&quot;test-watch&quot;: &quot;jest --watch&quot;\n// npm run test-watch ==&gt; check once and if respective modules/test is upated \nSUPERTEST (for making a test request to our endpoints) :\nconst request = require(&#039;supertest&#039;);\nconst path = require(&#039;path&#039;);\nconst { app } = require(path.join(&#039;..&#039;, &#039;..&#039;, &#039;app.js&#039;));\n \ndescribe(&#039;Test launches&#039;, () =&gt; {\n \n¬† ¬† const testlaunch = {\n¬† ¬† ¬† ¬† mission: &quot;MSI 1&quot;,\n¬† ¬† ¬† ¬† rocket: &quot;ISE 1&quot;,\n¬† ¬† ¬† ¬† launchDate: &quot;January 17, 2030&quot;,\n¬† ¬† ¬† ¬† target: &quot;Kepler-1410 b&quot;\n¬† ¬† };\n \n¬† ¬† test(&#039;GET/launches&#039;, async () =&gt; {\n¬† ¬† \n¬† ¬† ¬† ¬† const response = await request(app)\n¬† ¬† ¬† ¬† ¬† ¬† .get(&#039;/launches&#039;)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(&#039;Content-Type&#039;, /json/)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(200);\n¬† ¬† });\n \n  \n \n¬† ¬† test(&#039;POST/launches 201 creation test&#039;, async () =&gt; {\n \n¬† ¬† ¬† ¬† const response = await request(app)\n¬† ¬† ¬† ¬† ¬† ¬† .post(&#039;/launches&#039;)\n¬† ¬† ¬† ¬† ¬† ¬† .send(testlaunch)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(&#039;Content-Type&#039;, /json/)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(201);\n¬† ¬† ¬† ¬† ¬† ¬† \n¬† ¬† ¬† ¬† const responseDate = new Date(response.body.launchDate).valueOf();\n¬† ¬† ¬† ¬† const ogDate = new Date(testlaunch.launchDate).valueOf();\n¬† ¬† ¬† ¬† \n¬† ¬† ¬† ¬† expect(responseDate).toBe(ogDate);\n¬† ¬† ¬† ¬† expect(response.body).toMatchObject({\n¬† ¬† ¬† ¬† ¬† ¬† mission: &quot;MSI 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† rocket: &quot;ISE 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† target: &quot;Kepler-1410 b&quot;\n¬† ¬† ¬† ¬† })\n¬† ¬† });\n \n  \n \n¬† ¬† test(&#039;POST/launches 400 catch missing properties error&#039;, async () =&gt; {\n \n¬† ¬† ¬† ¬† const testlaunch = {\n¬† ¬† ¬† ¬† ¬† ¬† mission: &quot;MSI 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† rocket: &quot;ISE 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† target: &quot;Kepler-1410 b&quot;\n¬† ¬† ¬† ¬† };\n¬† ¬† ¬† ¬† const response = await request(app)\n¬† ¬† ¬† ¬† ¬† ¬† .post(&#039;/launches&#039;)\n¬† ¬† ¬† ¬† ¬† ¬† .send(testlaunch)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(&#039;Content-Type&#039;, /json/)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(400);\n¬† ¬† ¬† ¬† expect(response.body).toStrictEqual({error: &#039;Insufficient data&#039;})\n \n¬† ¬† });\n \n  \n \n¬† ¬† test(&#039;POST/launches 400 catch invalid Date error&#039;, async () =&gt; {\n \n¬† ¬† ¬† ¬† const testlaunch = {\n¬† ¬† ¬† ¬† ¬† ¬† mission: &quot;MSI 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† rocket: &quot;ISE 1&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† target: &quot;Kepler-1410 b&quot;,\n¬† ¬† ¬† ¬† ¬† ¬† launchDate: &quot;adfasd&quot;,\n¬† ¬† ¬† ¬† };\n \n¬† ¬† ¬† ¬† const response = await request(app)\n¬† ¬† ¬† ¬† ¬† ¬† .post(&#039;/launches&#039;)\n¬† ¬† ¬† ¬† ¬† ¬† .send(testlaunch)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(&#039;Content-Type&#039;, /json/)\n¬† ¬† ¬† ¬† ¬† ¬† .expect(400);\n¬† ¬† ¬† ¬† expect(response.body).toBe(&#039;Wrong Date&#039;)\n¬† ¬† ¬† ¬† \n¬† ¬† });\n \n})\nPERFORMANCE  OPTIMISATION :\nNode default Async process ‚áí FILE IO process , NETWORK process (like requesting or sending data over network) ,\nNode default Sync process  ‚áí LOOPS , SORT , JSON.stringify(), JSON.parse(), Cyptro functions (some key derivation functions which means they are used to make hash keys like -  crypto.pbkdf2() and crypto.scrypt() functions) .\n*Example : if every JSON.stringify() or JSON.parse() takes 10ms and run on Sync Event loop thread then many request can pile up the delay.\nCLUSTER (round-robin method):\nnode server.js --&gt; master --&gt; fork() worker\n\t\t\t\t\t\t  --&gt; fork() worker\n\t\t\t\t\t\t  ....\n\nround-robin method ‚áí first request goes to first worker, second request to second worker, and so on till end and then again to first worker.\nPM2 (comes with build in clustering and is used to manage processes) :\n\npm2 with using node.js build in cluster module\n\nconst express = require(&#039;express&#039;);\nconst app = express();\n  \nconst os = require(&#039;os&#039;);\nconst cluster = require(&#039;cluster&#039;);\n  \napp.get(&#039;/&#039;,(req,res)=&gt;{\n¬† ¬† res.send(`Performance example ${process.pid}`);\n});\n  \napp.get(&#039;/timer&#039;, (req,res)=&gt;{\n¬† ¬† const starTime = Date.now();\n¬† ¬† while(Date.now() - starTime &lt; 9000){\n¬† ¬† }\n¬† ¬† res.send(`delayed ${process.pid}`);\n})\n \nconsole.log(&#039;Running server.js&#039;);\nif(cluster.isPrimary){\n¬† ¬† console.log(&#039;Master ...&#039;);\n¬† ¬† const NUM_WORKER = os.cpus().length; // returns number of CPUS\n¬† ¬† for(let i=0; i&lt;NUM_WORKER; i++){\n¬† ¬† ¬† ¬† cluster.fork();\n¬† ¬† }\n}\nelse{\n¬† ¬† console.log(&#039;Worker ...&#039;);\n¬† ¬† app.listen(3000);\n}\n\npm2 start server.js --&gt; starts cluster mode in server.js \n\t\t\t\t\t--&gt; make worker process as defined in server.js\n\npm2 stop server.js / id --&gt; obviously stops the process but \n\t\t\t\t\t\t\tdoes not delete cluster from pm2 \n\npm2 delete server.js --&gt; stops and delete server.js cluster from \n\t\t\t\t\t\t pm2\n\npm2 list / pm2 staus --&gt; print current online or stopped clusters\n\npm2 restart server.js --&gt;  Restarts the server after it is stopped\n\n\n\npm2 logs --&gt; list all logs\n\npm2 logs --lines --&gt; prints &quot;lines&quot; number of lines of logs. \n\npm2 start server.js -l logs.txt --&gt; store logs in logs.txt\n\n\nusing pm2\n\nconst express = require(&#039;express&#039;);\nconst app = express();\n \napp.get(&#039;/&#039;,(req,res)=&gt;{\n¬† ¬† res.send(`Performance example ${process.pid}`);\n});\n \napp.get(&#039;/timer&#039;, (req,res)=&gt;{\n¬† ¬† const starTime = Date.now();\n¬† ¬† while(Date.now() - starTime &lt; 9000){\n¬† ¬† }\n¬† ¬† res.send(`delayed ${process.pid}`);\n})\n \nconsole.log(&#039;Running server.js&#039;);\nconsole.log(&#039;Worker ...&#039;);\napp.listen(3000);\n\nBut why we define cluster in server.js when pm2 can do it for us\nSo remove all thing about cluster form server.js\n\npm2 start server.js -i number_of_worker \n--&gt; starts instances(-i) / worker according to number of given\n\npm2 start server.js -i max\n--&gt; to start maximum number of processes\n\n\npm2 show id_of_worker --&gt; shows all data about that id worker.\n\npm2 monit --&gt; opens a live monitor for all processes.\n\nZero Down Time approach :\nIf we want to change some code in production and if all servers are restarted by pm2 restart server then for sometime no request will be processed so to handle this Zero Down Time approach is used pm2 reload server where , workers are restarted one by one.\nCluster vs Web Workers :\nClusters works in single process and have build-in method to pass request to different worker but all worker don‚Äôt share any data among them as each worker work on different thread on CPU cores.\ncluster module allows us to create child processes that all share server ports.\nIn web worker all worker thread work independently and can share data among them.\nProcess vs Thread (ByteByteGo)\nCluster --&gt; distribute work among processes (running on each core)\nworker thread --&gt; distribute work among thread in a process.\n\n\nWORKER THREADS\nconst {isMainThread , Worker} = require(&#039;worker_threads&#039;);\n \n// Syntax : new Worker(filename, [options])\n// Syntax : new Worker(path to file which will work this worker thread)\n \nnew Worker(__filename); \n// ==&gt; this will make infinite number of worker threads as each thread will make new thread inshort it will f*ck up system at the end.\n \n// so like Cluster we will make Worker only if it is main thread\n \nif(isMainThread){\n\tnew Worker(__filename);\n\tnew Worker(__filename);\n}\nelse{\n\tconsole.log(&#039;Worker&#039;);\n}\n\nconst {isMainThread , workerData, Worker} = require(&#039;worker_threads&#039;);\n \nif(isMainThread){\n¬† ¬† new Worker(__filename, {\n¬† ¬† ¬† ¬† workerData : [1,3,123,9,70]\n¬† ¬† });\n¬† ¬† new Worker(__filename, {\n¬† ¬† ¬† ¬† workerData : [45,2,12,0,-8]\n¬† ¬† });\n¬† ¬† console.log(`Main ${process.pid}`);\n}\n \nelse{\n¬† ¬† console.log(`Worker ${process.pid}`);\n¬† ¬† console.log(`${workerData} sorted is : ${workerData.sort((a, b) =&gt; a - b)}`);\n}\nOUTPUT :\nMain 17316\nWorker 17316\n1,3,123,9,70 sorted is : 1,3,9,70,123\nWorker 17316\n45,2,12,0,-8 sorted is : -8,0,2,12,45\n\nHELMET.js (Helmet.js)\n\nHelmet helps secure Express apps by setting HTTP response headers.\nOAuth 2.0 code flow :\n\nWe can restrict an specific endpoint by passing a middleware for that endpoint\nfunction checkLoggedIn(req, res, next){\n\t// necessary checks\n}\n \nfunction checkPermissions(req, res, next){\n\t// necessary checks\n}\n \napp.get(&#039;/secret&#039;, checkLoggedIn, checkPermissions, (req, res) =&gt; {\n\t// return back user data if logged in and has necessary permissions\n});\n \napp.get(&#039;/&#039;, (req, res)=&gt;{\n\tres.sendFile(path.join(__dirname , &#039;public&#039;));\n});\n \n// Here &#039;/secret&#039; path is only accessible after necessary checks while &#039;/&#039; path is accessible by all users.\nJWT\nJWT (JSON Web Token) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed.\nA JSON Web Token consists of three parts:\n\nHeader\nPayload\nSignature\nThese parts are separated by dots (.) and are represented as header.payload.signature.\n\nExample Flow\n\nUser Logs In: User provides credentials (username and password).\nServer Verifies Credentials: Server verifies the credentials and, if valid, creates a JWT.\nToken Sent to User: The JWT is sent back to the client.\nClient Stores Token: The client stores the token (e.g., in localStorage or cookies).\nSubsequent Requests: The client includes the token in the Authorization header of future requests.\nServer Verifies Token: The server verifies the token and processes the request.\n\n\nGenerate random secret key for digital signing (run in bash) :\nopenssl rand -base64 32\nSockets :\n\nLearn Socket.io In 30 Minutes (youtube.com)\nEverything You Need To Know About Socket.IO - DEV Community\n\nNote : server.use()/io.use() middleware runs before every socket connection but socket.use() middleware runs before every packet is received.\ntherefore do authentication inside server.use()/io.use().\n\nHow to send recieve cookies over socket :\n\nServer Side :\n\napp.use(cors({\n¬† origin:&#039;http://localhost:5173&#039;, // as &#039;Access-Control-Allow-Origin&#039; header in the response must not be the wildcard &#039;*&#039; when the request&#039;s credentials mode is &#039;include&#039;.\n¬† credentials: true, // enable credentials\n}));\n \n \n \n// socket connection :\n \nconst io = new Server(server, {\n    cors: {\n        origin: [&#039;http://localhost:5173&#039;, &#039;admin.socket.io/&#039;, &#039;admin.socket.io/#/&#039;],\n        credentials: true, // enable credentials\n    }\n});\n \nio.use((socket, next)=&gt;{\n    console.log(socket.request.headers.cookie);\n    // verify the cookie here \n    next();\n})\n\nClient Side :\n\nasync function httpSignup(signupdetails: signupdetails) {\n¬† ¬† try {\n¬† ¬† ¬† ¬† const request = await fetch(`${APT_URL}/signup`, {\n¬† ¬† ¬† ¬† ¬† ¬† method: &#039;post&#039;,\n¬† ¬† ¬† ¬† ¬† ¬† credentials: &#039;include&#039;, // to get the cookies in Response Header\n¬† ¬† ¬† ¬† ¬† ¬† headers: {\n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† &#039;Content-Type&#039;: &#039;application/json&#039;,\n¬† ¬† ¬† ¬† ¬† ¬† },\n¬† ¬† ¬† ¬† ¬† ¬† body: JSON.stringify(signupdetails),\n¬† ¬† ¬† ¬† });\n \n¬† ¬† ¬† ¬† const response = await request.json();\n¬† ¬† ¬† ¬† response.ok = true;\n¬† ¬† ¬† ¬† return response;\n¬† ¬† }\n \n¬† ¬† catch (err) {\n¬† ¬† ¬† ¬† return { error : &quot;Server Error&quot;, ok: false }\n¬† ¬† }\n}\n \n \n \n// socket connetion :\n \nconst createSocketConnection = () =&gt; {\n    socket = io(&#039;http://localhost:3000&#039;, {\n\t    withCredentials: true // to pass cookies to socket\n    });\n}\nCircular dependencies :\n\nWhen 2 modules depends somehow on each other.\n\n\nKNIP\n(Find unused files, dependencies and exports in JavaScript and TypeScript projects) :\nNOTE : Knip is a static analysis tool and so can‚Äôt recognize dynamic imports that use the path module or alias path\nTherefore don‚Äôt use knip in frontend (as UI libraries like shadcn use alias or *(all) import)\n// when you import using path module knip can&#039;t recognize the import \n//  --------------** WRONG **--------------&gt;\nconst path = require(&#039;path&#039;); \nconst mongoServices = require(path.join(__dirname, &#039;mongo.js&#039;)); \nconst socketServices = require(path.join(__dirname, &#039;socket.js&#039;)); \n \n// but when you use relative path knip recognize it\n//  --------------** RIGHT **--------------&gt;\nconst mongoServices = require(&#039;./mongo.js&#039;); \nconst socketServices = require(&#039;./socket.js&#039;);\nTo setup knip :\n\nRun npm init @knip/config in terminal\nmake a file knip.config.js\n\n// knip.config.js :\n \nexport default {\n¬† ¬† &quot;entry&quot;: [&quot;src/{server,app}.js&quot;, &quot;src/config/index.js&quot;, &quot;src/utils/index.js&quot;],\n¬† ¬† &quot;project&quot;: [&quot;src/**/*.js&quot;]\n}\nNOTE : all files in backend code folder with default export must be listed in entry field of knip config file\nCaching :\nFetching data is ùòÄùóπùóºùòÑ. Caching speeds things up by storing frequently accessed data for quick reads. But how do you populate and update the cache? That‚Äôs where strategies come in.\nüîç Read Strategies:\nùóñùóÆùó∞ùóµùó≤ ùóîùòÄùó∂ùó±ùó≤ (Lazy Loading)\n\nHow it works: Tries cache first, then fetches from DB on cache miss\nUsage: When cache misses are rare or the latency of a cache miss + DB read is acceptable\n\nùó•ùó≤ùóÆùó± ùóßùóµùóøùóºùòÇùó¥ùóµ\n\nHow it works: Cache handles DB reads, transparently fetching missing data on cache miss\nUsage: Abstracts DB logic from app code. Keeps cache consistently populated by handling misses automatically\n\nüìù Write Strategies:\nùó™ùóøùó∂ùòÅùó≤ ùóîùóøùóºùòÇùóªùó±\n\nHow it works: Writes bypass the cache and go directly to the DB\nUsage: When written data won‚Äôt immediately be read back from cache\n\nùó™ùóøùó∂ùòÅùó≤ ùóïùóÆùó∞ùó∏ (Delayed Write)\n\nHow it works: Writes to cache first, async write to DB later\nUsage: In write-heavy environments where slight data loss is tolerable\n\nùó™ùóøùó∂ùòÅùó≤ ùóßùóµùóøùóºùòÇùó¥ùóµ\n\nHow it works: Immediate write to both cache and DB\nUsage: When data consistency is critical\n\nüöÄ Real-Life Usage:\nùóñùóÆùó∞ùóµùó≤ ùóîùòÄùó∂ùó±ùó≤ + ùó™ùóøùó∂ùòÅùó≤ ùóßùóµùóøùóºùòÇùó¥ùóµ\nThis ensures consistent cache/DB sync while allowing fine-grained cache population control during reads. Immediate database writes might strain the DB.\nùó•ùó≤ùóÆùó± ùóßùóµùóøùóºùòÇùó¥ùóµ + ùó™ùóøùó∂ùòÅùó≤ ùóïùóÆùó∞ùó∏\nThis abstracts the DB and handles bursting write traffic well by delaying sync. However, it risks larger data loss if the cache goes down before syncing the buffered writes to the database.\n\n\n\nImportant points :\nconst requestData = { \n\t[req.body.field]: req.body.value \n};\n\nIn this code, we use square brackets [] around req.body.field to create a dynamic key based on the value of req.body.field, and then assign req.body.value as the value associated with that key. This will create a JSON object with the structure you desire.\n\n\nThe optional chaining operator ?. allows you to safely access properties or call methods on possibly null or undefined values without causing an error. If the value before ?. is null or undefined, the entire expression evaluates to undefined without attempting to access the property or call the method after ?..\nIn the code snippet you provided, launches?.filter(...) is using optional chaining to ensure that the filter method is only called if launches is not null or undefined. If launches is null or undefined, the expression evaluates to undefined, and the subsequent map method call will not be executed, preventing a TypeError.\n\n\nJavascript Hidden Classes and Inline Caching in V8 (richardartoul.github.io)\n\n\nOptimization killers ¬∑ petkaantonov/bluebird Wiki (github.com)\n\n\nStyling console.log() in the terminal - DEV Community\n"},"Web-Dev/Redis":{"slug":"Web-Dev/Redis","filePath":"Web Dev/Redis.md","title":"Redis","links":["Web-Dev/"],"tags":[],"content":"index\nLearning :\nRedis for Beginners - Net Ninja\nRedis Crash Course - Web Dev Simplified\nRedis is like Map in JS, KEY = VALUE and VALUE is usually/default stored as string\nTerminal Commands :\n\nOpen WSL :                               wsl\nStart Redis server :                    redis-server\nOpen Redis server :                   redis-cli\nQuit CLI :                                   quit\nSET pair :                                   SET KEY VALUE\nGET VALUE :                              GET KEY\nDELETE VALUE :                         DEL KEY\nCHECK IF KEY EXIST :                 EXISTS KEY\nLIST ALL KEYS :                           KEYS *\nDELETE WHOLE REDIS DATA :   flushall\n\n\nExpiration (time limit) of a key :\n\n\nttl KEY === -1 then key exist but don‚Äôt have expiration time\nttl KEY === -2 then key don‚Äôt exist\nttl KEY === positive integer is seconds left.\nto set expiration time of stored KEY ‚áí expire KEY 10 here 10 is 10sec\nto set expiration time of NEW KEY   ‚áí setex KEY 10 VALUE\n\n\nList (doubly queue) :\n\n\nlpush KEY VALUE ‚áí make an array of name KEY(if not exist) and push VALUE at the START of array.\nrpush KEY VALUE ‚áí make an array of name KEY(if not exist) and push VALUE at the END of array.\nlrange KEY 0 -1 ‚áí list all values in array.\nLPOP KEY ‚áí pops out first element.\nRPOP KEY ‚áí pops out last element.\n\n\nSets (like maths sets allow only unique values) :\n\n\nSADD KEY VALUE ‚áí creates set KEY if not exist and then add VALUE\nSMEMBERS KEY ‚áí list all values in set KEY.\nSREM KEY VALUE ‚áí removes VALUE from KEY set.\n\n\nHashes (key value pairs inside a key value pair (but hashes can‚Äôt be nested))\n\n\nHSET KEY KEY VALUE === KEY = { KEY: VALUE }\nExample : HSET person name kyle === person = { name: kyle }\nHGET person name outputs kyle.\nHSET person age 26\nHGETALL person outputs :\n\n&quot;name&quot;\n&quot;kyle&quot;\n&quot;age&quot;\n&quot;26&quot;\n\nHDEL person age  ‚áí deletes age from person.\nHEXIST person age ‚áí (checks if age exist) outputs 0 as age is deleted.\n"},"Web-Dev/Three.js":{"slug":"Web-Dev/Three.js","filePath":"Web Dev/Three.js.md","title":"Three.js","links":["Web-Dev/"],"tags":[],"content":"index\nZTM Three.js\nRobot Bobby - YouTube\nWael Yasmina - YouTube\nBreathe of the Wild Style grass in Three.js\nBasics:\n import * as THREE from &#039;three&#039;;\n \n¬† componentDidMount() {\n¬†\n¬†   // LOAD SECENE\n¬†   \n¬† ¬† const canvas = document.getElementsByClassName(&quot;webgl&quot;)[0];\n¬† ¬† const scene = new THREE.Scene();\n¬† ¬† \n¬† ¬† // --OBJECT\n¬† ¬† \n¬† ¬† const geometry = new THREE.BoxGeometry(1, 1, 1);\n¬† ¬† const material = new THREE.MeshBasicMaterial({ color: &quot;red&quot; })\n¬† ¬† const cube = new THREE.Mesh(geometry, material);\n¬† ¬† scene.add(cube);\n¬† ¬†\n¬† ¬† // --CAMERA\n¬† ¬†  ¬†const sizes = {\n¬† ¬†  ¬† width: 800,\n¬† ¬† ¬†  height: 600\n¬† ¬† ¬†  }\n \n    // THREE.PerspectiveCamera( fieldview [in degree] ,aspect value [= width of render / height of render]);\n   \n¬† ¬† const camera = new THREE.PerspectiveCamera(75, (sizes.width / sizes.height));\n¬† ¬† camera.position.z = 3;\n¬† ¬† camera.position.y = 1;\n¬† ¬† camera.position.x = 1;\n¬† ¬† scene.add(camera);\n¬† ¬† \n¬† ¬† \n¬† ¬† // --RENDERER\n¬† ¬† \n¬† ¬† // console.log(canvas);\n¬† ¬† const renderer = new THREE.WebGLRenderer({\n¬† ¬† ¬† canvas: canvas\n¬† ¬† })\n¬† ¬† renderer.setSize(sizes.width, sizes.height);\n¬† ¬† renderer.render(scene, camera);\n¬† }\n \n¬† render() {\n¬† ¬† return(\n \n¬† ¬† ¬† &lt;div&gt;\n¬† ¬† ¬† ¬† &lt;canvas className=&quot;webgl&quot;&gt;&lt;/canvas&gt;\n¬† ¬† ¬† &lt;/div&gt;\n¬† ¬† )\n¬† }\nexport default App\nTRANSFORM:\n\nposition\nscale\nrotation\nquaternion\n\n\nNOTE : rotation and quaternion both are used for rotation and if any of them is changed then both changes.\n\n\nPOSITION :\n\n\ny ‚áíup , down\nz ‚áí backward , forward\nx ‚áí right , left\n\nposition is a vector in 3D\n   // This outputs the length of vector from origin to object\n   console.log( mesh.position.length() );\n   \n   // This outputs distance between 0,1,2 vector and mesh\n   console.log( mesh.position.distanceTo(new THREE.Vector3(0,1,2)) );\n \n   // This outputs distance between mesh and camera\n   console.log( mesh.position.distanceTo(camera.postion));\n \n   // directly make all positions = 1\n¬† ¬†mesh.position.normalize();\n \n \n   camera.position.x = 1;\n   camera.position.y = 2;\n   camera.position.z = 3;\n   // position can be set by ::\n   camera.position.set(1,2,3);\n \n\nAXES HELPER :\n\n    // --AXES HELPER\n¬† ¬† // THREE.AxesHelper( length of all axis );\n \n¬† ¬† const axeshelper = new THREE.AxesHelper(2);\n¬† ¬† scene.add(axeshelper);\n\nSCALE :\n\n\t// mesh.scale.x = length ;\n\tmesh.scale.x = 2 ;\n\t// This extends the object in x by 2 so that it is of 2 units \n \n\t// we can also use set to set all\n\tmesh.scale.set(2,1,1); // same as mesh.scale.x = 2;\n\nROTATION :\n\n\t// rotation of x,y,z is Euler\n\t// angles are measured in PI = 3.1459\n\tmesh.rotation.x = (Math.PI/4);\n\nNOTE : When one axis is rotated then all axis are affected therefore, sometimes it might happen where you can‚Äôt rotate your axis anymore, THIS IS CALLED GIMBAL LOCK\n\nto solve this we can use :\n\n\n\tobject.rotation.reorder(&quot;yxz&quot;);\n\nEuler is therefore problematic therefore we use QUATERNION\n\n\nQUATERNION : Visualizing quaternions (4d numbers) with stereographic projection - YouTube\n\nLOOK AT THIS !\n\t// lookAt() is used to look at something\n\tcamera.lookAt( new THREE.Vector3(0,0,0) );\n\tcamera.lookAt( mesh.position );\nANIMATIONS :\n\t// requestAnimationFrame function calls tick function at a rate of frame of second according to computer.\n\t// like 60 frame/sec will cal this function 60 times in one sec.\n\tconst animate =()=&gt;{\n¬† ¬† ¬† cubegroup.rotation.y += 0.01;\n¬† ¬† ¬† renderer.render(scene, camera);\n¬† ¬† ¬† window.requestAnimationFrame(animate);\n¬† ¬† }\n¬† ¬† animate();\n¬† ¬† \n¬† ¬† //This method depends on each computer frame per second\n \n\t// TO overcome above this issue we use ::\n\tlet time = Date.now();\n\t\n¬† ¬† const animate =()=&gt;{\n¬† ¬† ¬† const currentTime = Date.now();\n¬† ¬† ¬† const deltaTime = currentTime - time;\n¬† ¬† ¬† time = currentTime;\n  \n¬† ¬† ¬† cubegroup.rotation.y += 0.001*deltaTime;\n¬† ¬† ¬† renderer.render(scene, camera);\n¬† ¬† ¬† window.requestAnimationFrame(animate);\n¬† ¬† }\n¬† ¬† animate();\n \n \n \n\t//OR we can use CLOCK OF THREE.js\n \n \n¬† ¬† const clock = new THREE.Clock();\n¬† ¬† \n¬† ¬† const animate =()=&gt;{\n¬† ¬† ¬† ¬† const elapsedTime = clock.getElapsedTime();\n¬† ¬† ¬† ¬† cubegroup.rotation.y = elapsedTime * (Math.PI*2);\n¬† ¬† ¬† ¬† \n¬† ¬† ¬† ¬† // To make 1 revolution per second\n \n¬† ¬† ¬† ¬† renderer.render(scene, camera);\n¬† ¬† ¬† ¬† window.requestAnimationFrame(animate);\n¬† ¬† ¬† }\n¬† ¬† ¬† animate();\n \n \nCAMERA :\n\nArray Camera : to make an array of cameras on same scene like how two players on same scene see differently.\nStereo Camera : for VR effects , its like seeing from both eyes.\nCube Camera : six cameras are placed like six faces of cube around the scene.\nOrthographic Camera : camera without perspective (size of object remain same irrespective of how far camera is) .\nPerspective Camera : size of objects changes according to camera.\n\n// ====================================================================\n// ===                        Perspective Camera                    ===\n// ====================================================================\n \n// THREE.PerspectiveCamera( fieldview [in degree] ,aspect value [= width of render / height of render] , near , far¬†);\n// here near and far are max and min values of view range. Anything going outside that is not rendered\n \n// try changing far to 2 or 3 to check limits here.\nconst camera = new THREE.PerspectiveCamera(75,(size.width / size.height), 1, 100);\n \ncamera.position.z = 2;\ncamera.position.y = 1;\ncamera.position.x = 2;\nscene.add(camera);\ncamera.lookAt(mesh.position);\n \n// z-fighting ==&gt; If we assign near and far 0.000...01 and 9999...9 then it becomes harder for GPU to render two very close mesh so NEVER DO THAT. \n \n// ====================================================================\n// ===                       Orthographic Camera                    ===\n// ====================================================================\n// const camera = new THREE.OrthographicCamera( left, right, top, bottom, near, far );\n// orthographic camera renders a cuboid having parallel axes on left , right, top, bottom\n// BUT as it forms cuboid acc. to the size of renderer frame so when we form a cuboid it is with respect to size so to fix this we can multiply left and top with aspect ratios adjust the size of mesh(cube formed).\n \nconst aspectRatio = size.width/size.height;\nconst camera = new THREE.OrthographicCamera(\n  -1*aspectRatio,\n  1*aspectRatio,\n  1,\n  -1,\n  1,\n  100\n);\nCustom Controls for Camera :\n\nCustom Controls for Camera using mouse :\n\nconst cursor ={\n  x:0,\n  y:0\n}\n \n// below we converted mouse position into a range of (-0.5, 0.5) value\ncanvas.addEventListener(&#039;mousemove&#039;, (event)=&gt;{\n  cursor.x = -(event.clientX/size.width - 0.5);\n  cursor.y = event.clientY/size.height - 0.5;\n})\n \nconst camera = new THREE.PerspectiveCamera(75,(size.width / size.height), 1, 100);\n// we wont assign x and y position of camera as they depends on mouse now.\n// assign z other wise it wont have any reference\ncamera.position.z = 4;\nscene.add(camera);\n \n// we only want to circulary move camera on &#039;x&#039; and &#039;z&#039; axis\nconst animate =()=&gt;{\n  camera.position.x = Math.sin(cursor.x*Math.PI*2)*4;\n  camera.position.z = Math.cos(cursor.x*Math.PI*2)*4;\n  camera.position.y = cursor.y*6;\n  camera.lookAt(mesh.position);\n  \n  renderer.render(scene,camera);\n  window.requestAnimationFrame(animate);\n}\nanimate();\n\nBuilt-in Controls for Camera :\n\n// ====================================================================\n// ===                        Orbit Controls                        ===\n// ====================================================================\n \n// We have to explicity import Orbit Controls from examples as they are not available in THREE object.\n \n// Orbit controls ==&gt; \n// Left mouse drag to change &#039;camera&#039; position\n// Right mouse drag to change &#039;axis&#039; or &#039;(0,0,0) coordinates&#039; postion\n// Scroll to zoom in and out.\n \nimport { OrbitControls } from &#039;three/examples/jsm/controls/OrbitControls.js&#039;\n \nconst camera = new THREE.PerspectiveCamera(75,(size.width / size.height), 1, 100);\n// camera inital position\ncamera.position.z = 4;\ncamera.position.y = 1;\ncamera.position.x = 2;\nscene.add(camera);\n// you can remove lookAt on camera here as we would be using Orbit Controls and in Orbit Controls lookAt wont work\n// camera.lookAt(mesh.position);\n \n// --Controls\nconst controls = new OrbitControls(camera, canvas);\n// [IMP] We can set reference point or &#039;axis&#039; or &#039;(0,0,0) coordinates&#039; postion of camera by controls.target\n// if we set target to mesh.position it somewhat same as lookAt, just play around them to adjust your need\n// [Note] By setting target as mesh.positon we basically fixed the mesh and therefore right mouse drag wont change the mesh BUT would change the axis.\n// comment below target\ncontrols.target = mesh.position;\n \n// Damping gives a smooth transition of camera postion making it more realistic.\ncontrols.enableDamping = true;\n \n \nconst animate =()=&gt;{\n \n  // [IMP] its important to update the controls on every frame\n  controls.update();\n \n  renderer.render(scene,camera);\n  window.requestAnimationFrame(animate);\n}\nanimate();\nFull-Screen and Resizing of Canvas :\n#root, body, html {\n¬† margin: 0;\n¬† padding: 0;\n¬† overflow: hidden;\n}\n \n#webgl{\n¬† position: fixed;\n¬† left: 0;\n¬† top: 0;\n¬† outline: none;\n}\n\n// ====================================================================\n// ===                        Full Screen                           ===\n// ====================================================================\n \nwindow.addEventListener(&#039;dblclick&#039;, ()=&gt;{\n  const fullScreenElement = document.fullscreenElement || document.webkitFullscreenElement;\n¬† ¬† ¬† \n  if(!fullScreenElement){\n\tif(canvas.requestFullscreen) canvas.requestFullscreen();\n\telse if(canvas.webkitRequestFullscreen) canvas.webkitRequestFullscreen();\n  } else {\n\tif(document.exitFullscreen) document.exitFullscreen();\n\telse if(document.webkitExitFullscreen) document.webkitExitFullscreen();\n  }\n \n})\n \n \n \n// ====================================================================\n// ===                      Resizing Screen                         ===\n// ====================================================================\n \nconst size = {\n  width: window.innerWidth,\n  height: window.innerHeight\n}\n \nwindow.addEventListener(&#039;resize&#039;,()=&gt;{\n \n  // Update sizes\n  size.width = window.innerWidth;\n  size.height = window.innerHeight;\n \n  // Update camera\n  camera.aspect = size.width/size.height;\n  camera.updateProjectionMatrix();\n \n  // Update Renderer\n  renderer.setSize(size.width, size.height);\n \n \n  // Adjust the pixel ratio to avoid blurry output on high DPI screens\n  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));\n})\nGEOMETRY :\n\nGeometry is composed of vertices (point coordinates in 3D space) and faces (triangles that join those vertices to create a surface)\ncan be used for meshes but also for particles (in particles each vertex acts as particle)\ncan store more data than the positions (UV coordinates, position, normals, colors, size or anything we want)\n\n\nBuilt-in Geometry (inherit from BufferGeometry class) :\n\n\n\nBox\n\n\nPlane\n\n\nCircle\n\n\nCone\n\n\nCylinder\n\n\nRing\n\n\nTorus (donut)\n\n\nTorus Knot\n\n\nDodecahedron\n\n\nOctahedron\n\n\nTetrahedron\n\n\nIcosahedron\n\n\nSphere\n\n\nShape (based on curves)\n\n\nTube\n\n\nExtrude\n\n\nLathe\n\n\nText\n\n\nBox Geometry :\nwidth ‚Äî Width; that is, the length of the edges parallel to the X axis. Optional; defaults to¬†1.\nheight ‚Äî Height; that is, the length of the edges parallel to the Y axis. Optional; defaults to¬†1.\ndepth ‚Äî Depth; that is, the length of the edges parallel to the Z axis. Optional; defaults to¬†1.\nwidthSegments ‚Äî Number of segmented rectangular faces along the width of the sides. Optional; defaults to¬†1.\nheightSegments ‚Äî Number of segmented rectangular faces along the height of the sides. Optional; defaults to¬†1.\ndepthSegments ‚Äî Number of segmented rectangular faces along the depth of the sides. Optional; defaults to¬†1.\n\n\n\nWireframe: shows a wired frame of mesh\n\nconst mesh = new THREE.Mesh(\n  new THREE.BoxGeometry(1,1,1),\n  new THREE.MeshBasicMaterial({color : &#039;red&#039;, wireframe: true})\n);\n\nBuilt-in Geometries :\n\nconst geometry = new THREE.SphereGeometry(1,32,32);\nconst geometry = new THREE.ConeGeometry(1,1,32);\nconst geometry = new THREE.TorusGeometry(1,0.4,32,100);\nconst geometry = new THREE.TorusKnotGeometry(1,0.4,32,100);\n\nCreate Custom BufferGeometry :\n\nconst geometry = new THREE.BufferGeometry()\nconst positionArray = new Float32Array([\n\t0,0,0, // First Vertex\n\t0,1,0, // Second Vertex\n\t1,0,0  // Third Vertex\n]);\nconst positionAttribute = new THREE.BufferAttribute(positionArray, 3);\n// &#039;position&#039; below is a Three.js default shader\ngeometry.setAttribute(&#039;position&#039;, positionAttribute);\n \nconst mesh = new THREE.Mesh(\n  geometry,\n  new THREE.MeshBasicMaterial({color : &#039;red&#039;, wireframe: true})\n);\nscene.add(mesh);\n\nconst geometry = new THREE.BufferGeometry()\nconst count = 50; // Number of faces\n \nconst positionArray = new Float32Array(count*3*3); // each face have 3 vertices and each vertex have 3 coordinates (x,y,z)\n \nfor(let i=0; i&lt;count*3*3; i++){\n  positionArray[i] = Math.random() * 4;\n}\n \nconst positionAttribute = new THREE.BufferAttribute(positionArray, 3);\ngeometry.setAttribute(&#039;position&#039;, positionAttribute);\n \nconst mesh = new THREE.Mesh(\n  geometry,\n  new THREE.MeshBasicMaterial({color : &#039;red&#039;, wireframe: true})\n);\nscene.add(mesh);\nDebug UI for JavaScript (lil-gui) :\nimport gsap from &quot;gsap&quot;;\nimport GUI from &#039;lil-gui&#039;;\n \n//==================Debug===================\nconst gui = new GUI();\nwindow.addEventListener(&#039;keydown&#039;, (event)=&gt;{\n  if(event.key === &#039;h&#039;){\n\tif(gui._hidden) gui.show();\n\telse gui.hide();\n  }\n});\nconst parameters = {\n  faces:50,   // Number of faces\n  spin: ()=&gt;{\n\tgsap.to(mesh.rotation, {duration: 1, y: mesh.rotation.y + Math.PI/2})\n  }\n}; \n \ngui.add(parameters, &#039;faces&#039;, 1, 500, 1);\ngui.add(parameters, &#039;spin&#039;);\ngui.add(material, &#039;wireframe&#039;);\ngui.addColor(material, &#039;color&#039;);\n//==========================================\nTEXTURES :\nyoutu.be/T2K6WXdifGA\nTextures are images that will cover the surface of geometries\nTexture follow PBR (Physically Based Rendering) that uses real-life algorithms, articles: (Physically-Based Rendering, And You Can Too! | Marmoset, Basic Theory of Physically-Based Rendering | Marmoset)\n\nTextures are of many types each of different effects :\n\n\nColor (Albedo) : applied on geometries\nAlpha : grayscale image,\n\nwhite part is visible part,\nblack part is invisible part of image\n\n\nHeight (Displacement) : grayscale image,\n\nwhite means max height,\nblack means min height,\nmove the vertices,\nneed enough subdivisions to move height.\n\n\nNormal : purple/bluish image,\n\nadd details mostly regarding lights, reflection refraction according to vectors\nnormal vector directing outside of the face\ndon‚Äôt need subdivisions\n\n\nAmbient Occlusion : grayscale image,\n\nadd fake shadows in cervices\nnot physically accurate\n\n\nMetalness : grayscale image,\n\nwhite is metallic\nblack is non metalic\nmostly for reflection\n\n\nRoughness : grayscale image,\n\nwhite is rough\nblack is smooth\nmostly for light dissipation\nmostly used with metalness\n\n\n\n\nHow to load Textures (TextureLoader) :\n\nconst loadingManager = new THREE.LoadingManager();\n \nloadingManager.onStart = ()=&gt;{\n  console.log(&#039;onStart&#039;);\n}\nloadingManager.onLoad = ()=&gt;{\n  console.log(&#039;onLoad&#039;);\n}\nloadingManager.onProgress = ()=&gt;{\n  console.log(&#039;onProgress&#039;);\n}\nloadingManager.onError = ()=&gt;{\n  console.log(&#039;onError&#039;);\n}\n \nconst textureLoader = new THREE.TextureLoader(loadingManager);\n \nconst colorTexture = textureLoader.load(&#039;/static/textures/door/color.jpg&#039;);\nconst metalnessTexture = textureLoader.load(&#039;/static/textures/door/metalness.jpg&#039;);\nconst roughnessTexture = textureLoader.load(&#039;/static/textures/door/roughness.jpg&#039;);\n \nconst material = new THREE.MeshBasicMaterial({\n  map : colorTexture,\n})\n\nUV Unwrapping :\n\nTexture is being stretched and squeezed in different ways to cover different geometries, this is called UV Unwrapping. It‚Äôs like unwrapping an origami, like how a cube can be unwrapped into a ‚Äô+‚Äô symbol.\nconsole.log(geometry.attributes.uv);\nCustom geometry would require custom uv unwrapping.\n\nTransform textures :\n\n\nrepeat : a Vector2 with x &amp; y values\ncolorTexture.repeat.x = 2; // texture cover 1/2 of the x\ncolorTexture.repeat.y = 3; // texture cover 1/3 of the y\n// by default the rest part is stretcted\n// but we can change it by :\ncolorTexture.wrapS = THREE.RepeatWrapping;\ncolorTexture.wrapT = THREE.RepeatWrapping;\n// we can alternate (mirror) this wrapping by : \ncolorTexture.wrapS = THREE.MirroredRepeatWrapping;\ncolorTexture.wrapT = THREE.MirroredRepeatWrapping;\n\nrotation : rotate by radians\ncolorTexture.rotation = Math.PI / 4;\n\noffset : defines the position of the texture on the surface.\ncolorTexture.offset.x = 0.5;\ncolorTexture.offset.y = 0.5;\n\ncenter : sets the pivot point for transformations (like rotation or scaling).\ncolorTexture.center.x = 0.5;\ncolorTexture.center.y = 0.5;\n\n\n\nMip Mapping (Expensive) (done by Three.js) : A technic that consist of creating half a smaller version of textures again and again till it forms a 1x1 form of texture. All those versions of textures are sent to GPU and then GPU decides which texture to use according to lighting distance angle etc..\nAlgorithms used in Mip Mapping are :\n\n\nMinification filter : When texture is too big for the surface, example when we zoom out then we use minified version created in Mip Mapping.\ncolorTexture.minFilter = THREE.NearestFilter;\n\nMagnification filter : When texture is too big for the surface, example when we zoom out then we use minified version created in Mip Mapping.\ncolorTexture.magFilter = THREE.NearestFilter;\n\n\n\nusing NearestFilter is better than default as results are better and Mip Maps are not formed in this filter. Therefore when using NearestFilter disable the mipmapping generation :\n\ncolorTexture.generateMipmaps = false;\n\nTexture Formats and Optimization :\n\n\nweight : users will have to download the textures. TinyPNG for compression\n\n.jpg : compression therefore lighter and better\n.png : no compression therefore heavier\nbasis : very high compression good for GPU‚Äôs\n\n\nsize : images dimensions should be of power of 2, as we generate mip maps\ndata : normal, alpha and color carry a lot of important details that affect the texture so we normally use .png format for them as it is lossless.\n\n\nWebsites to find Texture :\n\n\nPoliigon - PBR Textures, Models and HDRIs\n3D TEXTURES | Free seamless PBR textures and Stylized textures with Color, Normal, Displacement, Occlusion and Roughness Maps.\nArroway Textures - Professional Textures\nedify-3d Model by Shutterstock | NVIDIA NIM\n\nMATERIALS :\nMaterials are used to put color on each visible pixel of geometries. The algorithm used to put color are written in program called Shaders.\n\n\nMeshBasicMaterial :\n// ==&gt; map property of MeshBasicMaterial:\nconst material = new THREE.MeshBasicMaterial({\n  map : minecraftTexture,\n})\n// this can also be written as :\nconst material = new THREE.MeshBasicMaterial();\nmaterial.map = minecraftTexture;\n \n \n// ==&gt; color property of MeshBasicMaterial:\nconst material = new THREE.MeshBasicMaterial({color : &#039;red&#039;})\n// this can also be written as :\nconst material = new THREE.MeshBasicMaterial();\nmaterial.color = new THREE.Color(&#039;hex OR rgb(...) OR text&#039;);\n// we can combine map and color\n \n \n// ==&gt; wireframe property of material:\nconst material = new THREE.MeshBasicMaterial();\nmaterial.wireframe = true;\n \n \n// ==&gt; opacity property of material:\nmaterial.transparent = true;\nmaterial.opacity = 0.5;\n \n \n// ==&gt; alphaMap property of MeshBasicMaterial:\nconst material = new THREE.MeshBasicMaterial();\nmaterial.map = colorTexture;\nmaterial.transparent = true;\nmaterial.alphaMap = alphaTexture;\n \n// ==&gt; side property of material:\n// decides which side is visible\n// THREE.FrontSide (default)\n// THREE.BackSide\n// THREE.DoubleSide (more calculations therefore expensive for GPU)\nmaterial.side = THREE.DoubleSide;\n\n\nMeshNormalMaterial :\nconst material = new THREE.MeshNormalMaterial();\n// wireframe, transparent, opacity, side works as in MeshBasicMaterial\n// obviously map, alphaMap, color don&#039;t work.\n \n// ==&gt; flatShading property of MeshNormalMaterial\n// it flatten the faces, meaning the normals won&#039;t be \n// interpolated between the vertices\nmaterial.flatShading = true;\n\n\nMeshMatcapMaterial :\nconst material = new THREE.MeshMatcapMaterial()\n// displays a color by using normals with respect to camera as reference to pick the right color on a texture\nmaterial.matcap = matcapTexture; \nWhere to find matcap materials : nidorx/matcaps: Huge library of matcap PNG textures organized by color\n\n\nMeshDepthMaterial :\nconst material = new THREE.MeshDepthMaterial();\n// color geometries white if they are close to near of camera and black if its close to far of camera\n\n\nMeshLambertMaterial :\nreacts with light therefore we need lights for this material\n// ====================== Lights =======================\n¬† ¬† const ambientLight = new THREE.AmbientLight(new THREE.Color(&#039;white&#039;), 0.5);\n¬† ¬† scene.add(ambientLight);\n \n¬† ¬† const pointLight = new THREE.PointLight(0xffffff , 100);\n¬† ¬† pointLight.position.x = 5;\n¬† ¬† pointLight.position.y = 5;\n¬† ¬† pointLight.position.z = 5;\n¬† ¬† scene.add(pointLight);\n// =====================================================\n \nconst material = new THREE.MeshLambertMaterial();\n// doesn&#039;t have reflection of light\n\n\nMeshPhongMaterial :\nreacts with light therefore we need lights for this material\n// ====================== Lights =======================\n¬† ¬† const ambientLight = new THREE.AmbientLight(new THREE.Color(&#039;white&#039;), 0.5);\n¬† ¬† scene.add(ambientLight);\n \n¬† ¬† const pointLight = new THREE.PointLight(0xffffff , 100);\n¬† ¬† pointLight.position.x = 5;\n¬† ¬† pointLight.position.y = 5;\n¬† ¬† pointLight.position.z = 5;\n¬† ¬† scene.add(pointLight);\n// =====================================================\n \nconst material = new THREE.MeshPhongMaterial();\n// have reflection of light\n// We can control light reflection with shininess and color of reflection with specular\nmaterial.shininess = 500;\nmaterial.specular = new THREE.Color(&#039;blue&#039;);\n\n\nMeshToonMaterial :\nreacts with light therefore we need lights for this material\n// ====================== Lights =======================\n¬† ¬† const ambientLight = new THREE.AmbientLight(new THREE.Color(&#039;white&#039;), 0.5);\n¬† ¬† scene.add(ambientLight);\n \n¬† ¬† const pointLight = new THREE.PointLight(0xffffff , 100);\n¬† ¬† pointLight.position.x = 5;\n¬† ¬† pointLight.position.y = 5;\n¬† ¬† pointLight.position.z = 5;\n¬† ¬† scene.add(pointLight);\n// =====================================================\n \nconst material = new THREE.MeshToonMaterial();\n// cartoonist reflection\n// we can add a gradient to the lighting on the surface of geometries\nmaterial.gradientMap = gradientTexture;\n// if we apply gradientMap we would loose our cartoonist effect and would have a uniform gradient(like in MeshLambertMaterial) because gradient is too small so the default magFilter i.e Linear take smaller versions of gradient texture and try to fix it therefore set magFilter to NearestFilter\nmaterial.generateMipmaps = false;\ngradientTexture.magFilter = THREE.NearestFilter;\ngradientTexture.minFilter = THREE.NearestFilter;\n\n\n(Important) MeshStandardMaterial :\nreacts with light therefore we need lights for this material\n// ====================== Lights =======================\n¬† ¬† const ambientLight = new THREE.AmbientLight(new THREE.Color(&#039;white&#039;), 0.5);\n¬† ¬† scene.add(ambientLight);\n \n¬† ¬† const pointLight = new THREE.PointLight(0xffffff , 100);\n¬† ¬† pointLight.position.x = 5;\n¬† ¬† pointLight.position.y = 5;\n¬† ¬† pointLight.position.z = 5;\n¬† ¬† scene.add(pointLight);\n// =====================================================\n \nconst material = new THREE.MeshStandardMaterial();\n// uses PBR principals to render realistic lights\n// supports metalness and roughness\nmaterial.metalness = 0.5;\nmaterial.roughness = 0.2;\n//supports maps, colors etc..\nmaterial.map = colorTexture;\nmaterial.transparent = true;\nmaterial.alphaMap = alphaTexture;\n \n// supports Ambient Occlusion maps (aoMap) which will add shadow where the texture is dark BUT we must first add uv coordinates of those dark areas\n// add a second set of UV named uv2\nplane.geometry.setAttribute(\n  &#039;uv2&#039;,\n  new THREE.BufferAttribute(plane.geometry.attributes.uv.array, 2)\n);\nmaterial.aoMap = ambientOcclusionTexture;\nmaterial.aoMapIntensity = 1.5;\n \n// supports displacementMap\nmaterial.displacementMap = heightTexture;\n// BUT here as plane has not enough vertices it won&#039;t be affected and sphere and torus etc.. with more vertices will change but as height map is not for them we get a weird shape\n// increase subdivisons on each geometry\nconst sphere = new THREE.Mesh(\n  new THREE.SphereGeometry(0.5,64,64),\n  material\n);\n \nconst plane = new THREE.Mesh(\n  new THREE.PlaneGeometry(1,1,100,100),\n  material\n);\n \nconst torus = new THREE.Mesh(\n  new THREE.TorusGeometry(0.3,0.2,64,128),\n  material\n);\n \n// now the displacement intensity is too strong so reduce it by :\nmaterial.displacementScale = 0.06;\n \n// metalness and roughness map\nmaterial.metalnessMap = metalnessTexture;\nmaterial.roughnessMap = roughnessTexture;\n \n// normal map to add how light interact reflect and refraction from a  surface of geometies\nmaterial.normalMap = normalTexture;\nmaterial.normalScale.set(1,1);\n\n\nMeshPhysicalMaterial :\nsimilar as MeshStandardMaterial but with more realistic and clear coat effect\n\n\nPointsMaterial :\n\n\nShaderMaterial and RawShaderMaterial :\ncreate out own Materials\n\n\n\nEnvironment Maps\n\n// to load a cube texture environment we need CubeTextureLoader\nconst cubeTextureLoader = new THREE.CubeTextureLoader(loadingManager);\n \n// the order in which the pngs are loaded is important\nconst environmentMapTexture = cubeTextureLoader.load([\n  &#039;/static/textures/environmentMap/0/px.png&#039;,\n  &#039;/static/textures/environmentMap/0/nx.png&#039;,\n  &#039;/static/textures/environmentMap/0/py.png&#039;,\n  &#039;/static/textures/environmentMap/0/ny.png&#039;,\n  &#039;/static/textures/environmentMap/0/pz.png&#039;,\n  &#039;/static/textures/environmentMap/0/nz.png&#039;,\n]);\n \nconst material = new THREE.MeshStandardMaterial();\nmaterial.metalness = 0.7;\nmaterial.roughness = 0.2;\nmaterial.envMap = environmentMapTexture;\n\nTo get more Environment Maps\n\nHDRIs ‚Ä¢ Poly Haven download a hdri file of map\nHDRI to CubeMap convert hdri to images\n\n"},"Web-Dev/index":{"slug":"Web-Dev/index","filePath":"Web Dev/index.md","title":"Web Development","links":["/"],"tags":[],"content":"Home"},"index":{"slug":"index","filePath":"index.md","title":"Dhruv Jain's PKMS","links":["what_im_learning"],"tags":[],"content":"\nThis knowledge base contains random methods and resources which I discovered and found worth notice. Some of them may be too basic and some may be too difficult so just bear with it and read along.\nI have tried my best to keep all this in simpliest and easiest form.\n‚ÄùStorms in my head ruin the garden that my heart holds‚Äù.\n\nFor my current leanings visit : what_im_learning"},"what_im_learning":{"slug":"what_im_learning","filePath":"what_im_learning.md","title":"what_im_learning","links":["/","Tech-Articles--and--Videos"],"tags":[],"content":"Home\nTech Articles &amp; Videos\nwhat_im_learning\n\n\n\nIdeas\n\nQualitative ESG rating project MSCI dataset\n‚ÄúPerformance Matters‚Äù by Emery Berger\nSharing a state between windows without a server - DEV Community\nHow to Create Your Own Google Chrome Extension (freecodecamp.org)\ncreate my own language: craftinginterpreters.com/5\n"}}